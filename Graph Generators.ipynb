{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator: variable supercell size, next nearest neighbor and PBC, 0 node features, xyz edge attributes\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define the tolerance delta for nearest neighbors\n",
    "delta = 0.1  # Adjust as needed\n",
    "\n",
    "# Define the perturbation size\n",
    "perturbation_size = 0.05  # Adjust as needed\n",
    "\n",
    "# Function to compute edge_index based on positions and delta, considering PBCs\n",
    "def compute_edge_index(atoms, delta):\n",
    "    positions = atoms.get_positions()\n",
    "    num_atoms = len(positions)\n",
    "\n",
    "    # Compute distance matrix considering PBCs\n",
    "    dist_matrix = atoms.get_all_distances(mic=True)\n",
    "    edge_index = set()  # Use a set to avoid duplicate edges\n",
    "\n",
    "    # For each node, find its nearest neighbors and next-nearest neighbors\n",
    "    for i in range(num_atoms):\n",
    "        # Exclude self-distance by setting diagonal to infinity\n",
    "        dist_matrix[i, i] = np.inf\n",
    "\n",
    "        # Get distances and sort them along with indices\n",
    "        distances = dist_matrix[i]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        sorted_distances = distances[sorted_indices]\n",
    "\n",
    "        # Nearest neighbor distance\n",
    "        d1 = sorted_distances[0]\n",
    "        nn_cutoff = d1 + delta\n",
    "\n",
    "        # Indices of nearest neighbors within d1 + delta\n",
    "        nn_indices = sorted_indices[sorted_distances <= nn_cutoff]\n",
    "\n",
    "        # Add edges from nearest neighbors to i\n",
    "        for j in nn_indices:\n",
    "            edge_index.add((j, i))\n",
    "\n",
    "        # Exclude nearest neighbors from consideration for next-nearest neighbors\n",
    "        remaining_indices = sorted_indices[sorted_distances > nn_cutoff]\n",
    "        remaining_distances = sorted_distances[sorted_distances > nn_cutoff]\n",
    "\n",
    "        if len(remaining_distances) > 0:\n",
    "            # Next-nearest neighbor distance\n",
    "            d2 = remaining_distances[0]\n",
    "            nnn_cutoff = d2 + delta\n",
    "\n",
    "            # Indices of next-nearest neighbors within d2 + delta\n",
    "            nnn_indices = remaining_indices[remaining_distances <= nnn_cutoff]\n",
    "\n",
    "            # Add edges from next-nearest neighbors to i\n",
    "            for j in nnn_indices:\n",
    "                edge_index.add((j, i))\n",
    "\n",
    "    # Convert edge_index to a tensor\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(list(edge_index), dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "# Function to compute edge attributes as displacement vectors considering PBCs\n",
    "def compute_edge_attr(atoms, edge_index):\n",
    "    row, col = edge_index\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "\n",
    "    # Compute displacement vectors considering PBCs\n",
    "    delta_scaled = scaled_positions[row.numpy()] - scaled_positions[col.numpy()]\n",
    "    delta_scaled -= np.round(delta_scaled)  # Apply minimum image convention\n",
    "    displacement_vectors = delta_scaled @ cell  # Convert back to Cartesian coordinates\n",
    "\n",
    "    # Create edge attributes as displacement vectors\n",
    "    edge_attr = torch.tensor(displacement_vectors, dtype=torch.float)\n",
    "    return edge_attr\n",
    "\n",
    "# Function to compute node features\n",
    "def compute_node_features(atoms):\n",
    "    num_atoms = len(atoms)\n",
    "    # Create node features as a tensor of ones\n",
    "    node_features = torch.ones((num_atoms, 1), dtype=torch.float)\n",
    "    return node_features\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure\n",
    "def create_graph_from_structure(atoms, delta):\n",
    "    # Compute edge_index\n",
    "    edge_index = compute_edge_index(atoms, delta)\n",
    "\n",
    "    # Compute edge attributes\n",
    "    edge_attr = compute_edge_attr(atoms, edge_index)\n",
    "\n",
    "    # Compute node features\n",
    "    node_features = compute_node_features(atoms)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "    )\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to apply perturbations to a graph list\n",
    "def perturb_graphs(graph_list, atoms_list, perturbation_size, delta):\n",
    "    perturbed_graph_list = []\n",
    "    for graph, atoms in zip(graph_list, atoms_list):\n",
    "        # Clone the graph to avoid modifying the original\n",
    "        perturbed_graph = graph.clone()\n",
    "\n",
    "        # Get the positions of the atoms from the atoms object\n",
    "        positions = atoms.get_positions().copy()  # Original positions\n",
    "\n",
    "        # Apply random perturbation to the positions\n",
    "        if perturbation_size > 0:\n",
    "            perturbation = np.random.uniform(-perturbation_size, perturbation_size, positions.shape)\n",
    "            positions += perturbation  # Perturb the atomic positions\n",
    "\n",
    "        # Update edge attributes based on perturbed positions\n",
    "        # Since edge_index remains the same, we recompute edge_attr\n",
    "        perturbed_atoms = atoms.copy()\n",
    "        perturbed_atoms.set_positions(positions)\n",
    "        perturbed_atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Recompute edge attributes\n",
    "        perturbed_edge_attr = compute_edge_attr(perturbed_atoms, graph.edge_index)\n",
    "        perturbed_graph.edge_attr = perturbed_edge_attr\n",
    "\n",
    "        # Recompute node features based on perturbed positions\n",
    "        perturbed_node_features = compute_node_features(perturbed_atoms)\n",
    "        perturbed_graph.x = perturbed_node_features\n",
    "\n",
    "        perturbed_graph_list.append(perturbed_graph)\n",
    "\n",
    "    return perturbed_graph_list\n",
    "\n",
    "# Function to read graphs and atoms from a folder\n",
    "def read_graphs_from_folder(folder_path, delta):\n",
    "    graph_list = []\n",
    "    atoms_list = []\n",
    "    filenames = sorted([f for f in os.listdir(folder_path) if f.endswith('.xyz')])\n",
    "    for filename in filenames:\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        atoms = read(filepath)\n",
    "        atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Extract the last number from the filename\n",
    "        match = re.findall(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match[-1])  # Get the last number\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "\n",
    "        # Create graph with PBCs\n",
    "        graph = create_graph_from_structure(atoms, delta)\n",
    "        graph.label = label\n",
    "\n",
    "        # Append the graph and atoms to their respective lists\n",
    "        graph_list.append(graph)\n",
    "        atoms_list.append(atoms)\n",
    "\n",
    "        print(f\"Graph for {filename} created and added to the list with label {label}.\")\n",
    "\n",
    "    return graph_list, atoms_list\n",
    "\n",
    "# Paths to the supercell files folders\n",
    "supercell_folder_3x3 = 'supercells_flatband_3x3'\n",
    "supercell_folder_4x4 = 'supercells_flatband_4x4'\n",
    "\n",
    "# Read graphs and atoms from the 3x3 folder\n",
    "graph_list_unperturbed_3x3, atoms_list_unperturbed_3x3 = read_graphs_from_folder(supercell_folder_3x3, delta)\n",
    "print(\"Unperturbed graph list for 3x3 supercells created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# Read graphs and atoms from the 4x4 folder\n",
    "graph_list_unperturbed_4x4, atoms_list_unperturbed_4x4 = read_graphs_from_folder(supercell_folder_4x4, delta)\n",
    "print(\"Unperturbed graph list for 4x4 supercells created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# Perturb the unperturbed 3x3 graphs to create the first perturbed graph list\n",
    "graph_list_set_1 = perturb_graphs(graph_list_unperturbed_3x3, atoms_list_unperturbed_3x3, perturbation_size, delta)\n",
    "\n",
    "# Perturb the unperturbed 4x4 graphs to create the second perturbed graph list\n",
    "graph_list_set_2 = perturb_graphs(graph_list_unperturbed_4x4, atoms_list_unperturbed_4x4, perturbation_size, delta)\n",
    "\n",
    "print(\"Two perturbed graph lists created from 3x3 and 4x4 supercells respectively.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator: variable supercell size, next nearest neighbor and PBC, xyz node features, xyz edge attributes\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define the tolerance delta for nearest neighbors\n",
    "delta = 0.1  # Adjust as needed\n",
    "\n",
    "# Define the perturbation size\n",
    "perturbation_size = 0.05  # Adjust as needed\n",
    "\n",
    "# Function to compute edge_index based on positions and delta, considering PBCs\n",
    "def compute_edge_index(atoms, delta):\n",
    "    positions = atoms.get_positions()\n",
    "    num_atoms = len(positions)\n",
    "\n",
    "    # Compute distance matrix considering PBCs\n",
    "    dist_matrix = atoms.get_all_distances(mic=True)\n",
    "    edge_index = set()  # Use a set to avoid duplicate edges\n",
    "\n",
    "    # For each node, find its nearest neighbors and next-nearest neighbors\n",
    "    for i in range(num_atoms):\n",
    "        # Exclude self-distance by setting diagonal to infinity\n",
    "        dist_matrix[i, i] = np.inf\n",
    "\n",
    "        # Get distances and sort them along with indices\n",
    "        distances = dist_matrix[i]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        sorted_distances = distances[sorted_indices]\n",
    "\n",
    "        # Nearest neighbor distance\n",
    "        d1 = sorted_distances[0]\n",
    "        nn_cutoff = d1 + delta\n",
    "\n",
    "        # Indices of nearest neighbors within d1 + delta\n",
    "        nn_indices = sorted_indices[sorted_distances <= nn_cutoff]\n",
    "\n",
    "        # Add edges from nearest neighbors to i\n",
    "        for j in nn_indices:\n",
    "            edge_index.add((j, i))\n",
    "\n",
    "        # Exclude nearest neighbors from consideration for next-nearest neighbors\n",
    "        remaining_indices = sorted_indices[sorted_distances > nn_cutoff]\n",
    "        remaining_distances = sorted_distances[sorted_distances > nn_cutoff]\n",
    "\n",
    "        if len(remaining_distances) > 0:\n",
    "            # Next-nearest neighbor distance\n",
    "            d2 = remaining_distances[0]\n",
    "            nnn_cutoff = d2 + delta\n",
    "\n",
    "            # Indices of next-nearest neighbors within d2 + delta\n",
    "            nnn_indices = remaining_indices[remaining_distances <= nnn_cutoff]\n",
    "\n",
    "            # Add edges from next-nearest neighbors to i\n",
    "            for j in nnn_indices:\n",
    "                edge_index.add((j, i))\n",
    "\n",
    "    # Convert edge_index to a tensor\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(list(edge_index), dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "# Function to compute edge attributes as displacement vectors considering PBCs\n",
    "def compute_edge_attr(atoms, edge_index):\n",
    "    row, col = edge_index\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "\n",
    "    # Compute displacement vectors considering PBCs\n",
    "    delta_scaled = scaled_positions[row.numpy()] - scaled_positions[col.numpy()]\n",
    "    delta_scaled -= np.round(delta_scaled)  # Apply minimum image convention\n",
    "    displacement_vectors = delta_scaled @ cell  # Convert back to Cartesian coordinates\n",
    "\n",
    "    # Create edge attributes as displacement vectors\n",
    "    edge_attr = torch.tensor(displacement_vectors, dtype=torch.float)\n",
    "    return edge_attr\n",
    "\n",
    "# Function to compute node features (relative positions within unit cells)\n",
    "def compute_node_features(atoms, SUPERCELL_SIZE):\n",
    "    num_atoms = len(atoms)\n",
    "    N = SUPERCELL_SIZE\n",
    "    total_unit_cells = N * N  # For a 2D lattice\n",
    "\n",
    "    # Compute the number of atoms per unit cell\n",
    "    atoms_per_unit_cell = num_atoms // total_unit_cells\n",
    "\n",
    "    # Check for consistency\n",
    "    if atoms_per_unit_cell * total_unit_cells != num_atoms:\n",
    "        raise ValueError(\"Number of atoms per unit cell is not consistent with total atoms and supercell dimensions.\")\n",
    "\n",
    "    # Group atoms by unit cell based on their order in the .xyz file\n",
    "    unit_cell_indices = []\n",
    "    for i in range(0, num_atoms, atoms_per_unit_cell):\n",
    "        group = list(range(i, i + atoms_per_unit_cell))\n",
    "        unit_cell_indices.append(group)\n",
    "\n",
    "    # Compute relative positions\n",
    "    positions = atoms.get_positions()\n",
    "    relative_positions = np.zeros_like(positions)\n",
    "\n",
    "    for group in unit_cell_indices:\n",
    "        indices = group\n",
    "        positions_in_cell = positions[indices]\n",
    "        reference_position = positions_in_cell[0]  # First atom in the unit cell\n",
    "        relative_positions_in_cell = positions_in_cell - reference_position\n",
    "        relative_positions[indices] = relative_positions_in_cell\n",
    "\n",
    "    # Create node features as torch tensor\n",
    "    node_features = torch.tensor(relative_positions, dtype=torch.float)\n",
    "    return node_features\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure\n",
    "def create_graph_from_structure(atoms, delta, SUPERCELL_SIZE):\n",
    "    # Compute edge_index\n",
    "    edge_index = compute_edge_index(atoms, delta)\n",
    "\n",
    "    # Compute edge attributes\n",
    "    edge_attr = compute_edge_attr(atoms, edge_index)\n",
    "\n",
    "    # Compute node features\n",
    "    node_features = compute_node_features(atoms, SUPERCELL_SIZE)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "    )\n",
    "\n",
    "    graph.supercell_size = SUPERCELL_SIZE  # Store supercell size in graph\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to apply perturbations to a graph list\n",
    "def perturb_graphs(graph_list, atoms_list, perturbation_size, delta, SUPERCELL_SIZE):\n",
    "    perturbed_graph_list = []\n",
    "    for graph, atoms in zip(graph_list, atoms_list):\n",
    "        # Clone the graph to avoid modifying the original\n",
    "        perturbed_graph = graph.clone()\n",
    "\n",
    "        # Get the positions of the atoms from the atoms object\n",
    "        positions = atoms.get_positions().copy()  # Original positions\n",
    "\n",
    "        # Apply random perturbation to the positions\n",
    "        if perturbation_size > 0:\n",
    "            perturbation = np.random.uniform(-perturbation_size, perturbation_size, positions.shape)\n",
    "            positions += perturbation  # Perturb the atomic positions\n",
    "\n",
    "        # Update edge attributes based on perturbed positions\n",
    "        # Since edge_index remains the same, we recompute edge_attr\n",
    "        perturbed_atoms = atoms.copy()\n",
    "        perturbed_atoms.set_positions(positions)\n",
    "        perturbed_atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Recompute edge attributes\n",
    "        perturbed_edge_attr = compute_edge_attr(perturbed_atoms, graph.edge_index)\n",
    "        perturbed_graph.edge_attr = perturbed_edge_attr\n",
    "\n",
    "        # Recompute node features based on perturbed positions\n",
    "        perturbed_node_features = compute_node_features(perturbed_atoms, SUPERCELL_SIZE)\n",
    "        perturbed_graph.x = perturbed_node_features\n",
    "\n",
    "        perturbed_graph_list.append(perturbed_graph)\n",
    "\n",
    "    return perturbed_graph_list\n",
    "\n",
    "# Function to read graphs and atoms from a folder\n",
    "def read_graphs_from_folder(folder_path, delta, SUPERCELL_SIZE):\n",
    "    graph_list = []\n",
    "    atoms_list = []\n",
    "    filenames = sorted([f for f in os.listdir(folder_path) if f.endswith('.xyz')])\n",
    "    for filename in filenames:\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        atoms = read(filepath)\n",
    "        atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Extract the last number from the filename\n",
    "        match = re.findall(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match[-1])  # Get the last number\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "\n",
    "        # Create graph with PBCs\n",
    "        graph = create_graph_from_structure(atoms, delta, SUPERCELL_SIZE)\n",
    "        graph.label = label\n",
    "\n",
    "        # Append the graph and atoms to their respective lists\n",
    "        graph_list.append(graph)\n",
    "        atoms_list.append(atoms)\n",
    "\n",
    "        print(f\"Graph for {filename} created and added to the list with label {label}.\")\n",
    "\n",
    "    return graph_list, atoms_list\n",
    "\n",
    "# Paths to the supercell files folders\n",
    "supercell_folder_1 = 'supercells_flatband_rotated_shifted_3x3'\n",
    "supercell_folder_2 = 'supercells_flatband_rotated_shifted_4x4'\n",
    "\n",
    "# Read graphs and atoms from the 3x3 folder\n",
    "graph_list_unperturbed_1, atoms_list_unperturbed_1 = read_graphs_from_folder(\n",
    "    supercell_folder_1, delta, SUPERCELL_SIZE_1\n",
    ")\n",
    "print(\"Unperturbed graph list for 3x3 supercells created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# Read graphs and atoms from the 4x4 folder\n",
    "graph_list_unperturbed_2, atoms_list_unperturbed_2 = read_graphs_from_folder(\n",
    "    supercell_folder_2, delta, SUPERCELL_SIZE_2\n",
    ")\n",
    "print(\"Unperturbed graph list for 4x4 supercells created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# Perturb the unperturbed 3x3 graphs to create the first perturbed graph list\n",
    "graph_list_set_1 = perturb_graphs(\n",
    "    graph_list_unperturbed_1, atoms_list_unperturbed_1, perturbation_size, delta, SUPERCELL_SIZE_1\n",
    ")\n",
    "\n",
    "# Perturb the unperturbed 4x4 graphs to create the second perturbed graph list\n",
    "graph_list_set_2 = perturb_graphs(\n",
    "    graph_list_unperturbed_2, atoms_list_unperturbed_2, perturbation_size, delta, SUPERCELL_SIZE_2\n",
    ")\n",
    "\n",
    "print(\"Two perturbed graph lists created from 3x3 and 4x4 supercells respectively.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator: variable supercell size, connnected graphs, next nearest neighbor and PBC, xyz node features, xyz edge attributes\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "\n",
    "delta = 0.1 #Defines the tolerance delta for nearest neighbors\n",
    "\n",
    "perturbation_size = 0.05 #Define the perturbation size\n",
    "\n",
    "# Function to compute edge_index based on positions and delta, considering PBCs\n",
    "def compute_edge_index(atoms, delta):\n",
    "    positions = atoms.get_positions()\n",
    "    num_atoms = len(positions)\n",
    "\n",
    "    # Compute distance matrix considering PBCs\n",
    "    dist_matrix = atoms.get_all_distances(mic=True)\n",
    "    edge_index = set()  # Use a set to avoid duplicate edges\n",
    "\n",
    "    # For each node, find its nearest neighbors and next-nearest neighbors\n",
    "    for i in range(num_atoms):\n",
    "        # Exclude self-distance by setting diagonal to infinity\n",
    "        dist_matrix[i, i] = np.inf\n",
    "\n",
    "        # Get distances and sort them along with indices\n",
    "        distances = dist_matrix[i]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        sorted_distances = distances[sorted_indices]\n",
    "\n",
    "        # Nearest neighbor distance\n",
    "        d1 = sorted_distances[0]\n",
    "        nn_cutoff = d1 + delta\n",
    "\n",
    "        # Indices of nearest neighbors within d1 + delta\n",
    "        nn_indices = sorted_indices[sorted_distances <= nn_cutoff]\n",
    "\n",
    "        # Add edges from nearest neighbors to i\n",
    "        for j in nn_indices:\n",
    "            edge_index.add((j, i))\n",
    "\n",
    "        # Exclude nearest neighbors from consideration for next-nearest neighbors\n",
    "        remaining_indices = sorted_indices[sorted_distances > nn_cutoff]\n",
    "        remaining_distances = sorted_distances[sorted_distances > nn_cutoff]\n",
    "\n",
    "        if len(remaining_distances) > 0:\n",
    "            # Next-nearest neighbor distance\n",
    "            d2 = remaining_distances[0]\n",
    "            nnn_cutoff = d2 + delta\n",
    "\n",
    "            # Indices of next-nearest neighbors within d2 + delta\n",
    "            nnn_indices = remaining_indices[remaining_distances <= nnn_cutoff]\n",
    "\n",
    "            # Add edges from next-nearest neighbors to i\n",
    "            for j in nnn_indices:\n",
    "                edge_index.add((j, i))\n",
    "\n",
    "    # Convert edge_index to a tensor\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(list(edge_index), dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "# Function to compute edge attributes as displacement vectors considering PBCs\n",
    "def compute_edge_attr(atoms, edge_index):\n",
    "    row, col = edge_index\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "\n",
    "    # Compute displacement vectors considering PBCs\n",
    "    delta_scaled = scaled_positions[row.numpy()] - scaled_positions[col.numpy()]\n",
    "    delta_scaled -= np.round(delta_scaled)  # Apply minimum image convention\n",
    "    displacement_vectors = delta_scaled @ cell  # Convert back to Cartesian coordinates\n",
    "\n",
    "    # Create edge attributes as displacement vectors\n",
    "    edge_attr = torch.tensor(displacement_vectors, dtype=torch.float)\n",
    "    return edge_attr\n",
    "\n",
    "# Function to compute node features (relative positions within unit cells)\n",
    "def compute_node_features(atoms, SUPERCELL_SIZE):\n",
    "    num_atoms = len(atoms)\n",
    "    N = SUPERCELL_SIZE\n",
    "    total_unit_cells = N * N  # For a 2D lattice\n",
    "\n",
    "    # Compute the number of atoms per unit cell\n",
    "    atoms_per_unit_cell = num_atoms // total_unit_cells\n",
    "\n",
    "    # Check for consistency\n",
    "    if atoms_per_unit_cell * total_unit_cells != num_atoms:\n",
    "        raise ValueError(\"Number of atoms per unit cell is not consistent with total atoms and supercell dimensions.\")\n",
    "\n",
    "    # Group atoms by unit cell based on their order in the .xyz file\n",
    "    unit_cell_indices = []\n",
    "    for i in range(0, num_atoms, atoms_per_unit_cell):\n",
    "        group = list(range(i, i + atoms_per_unit_cell))\n",
    "        unit_cell_indices.append(group)\n",
    "\n",
    "    # Compute relative positions\n",
    "    positions = atoms.get_positions()\n",
    "    relative_positions = np.zeros_like(positions)\n",
    "\n",
    "    for group in unit_cell_indices:\n",
    "        indices = group\n",
    "        positions_in_cell = positions[indices]\n",
    "        reference_position = positions_in_cell[0]  # First atom in the unit cell\n",
    "        relative_positions_in_cell = positions_in_cell - reference_position\n",
    "        relative_positions[indices] = relative_positions_in_cell\n",
    "\n",
    "    # Create node features as torch tensor\n",
    "    node_features = torch.tensor(relative_positions, dtype=torch.float)\n",
    "    return node_features\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure\n",
    "def create_graph_from_structure(atoms, delta, SUPERCELL_SIZE, label):\n",
    "    # Compute edge_index\n",
    "    edge_index = compute_edge_index(atoms, delta)\n",
    "\n",
    "    # Compute edge attributes\n",
    "    edge_attr = compute_edge_attr(atoms, edge_index)\n",
    "\n",
    "    # Compute node features\n",
    "    node_features = compute_node_features(atoms, SUPERCELL_SIZE)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "    )\n",
    "\n",
    "    graph.supercell_size = SUPERCELL_SIZE  # Store supercell size in graph\n",
    "    graph.label = label  # Store the label in the graph\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to apply perturbations to a graph list\n",
    "def perturb_graphs(graph_list, atoms_list, perturbation_size, delta, SUPERCELL_SIZE):\n",
    "    perturbed_graph_list = []\n",
    "    for graph, atoms in zip(graph_list, atoms_list):\n",
    "        # Clone the graph to avoid modifying the original\n",
    "        perturbed_graph = graph.clone()\n",
    "\n",
    "        # Get the positions of the atoms from the atoms object\n",
    "        positions = atoms.get_positions().copy()  # Original positions\n",
    "\n",
    "        # Apply random perturbation to the positions\n",
    "        if perturbation_size > 0:\n",
    "            perturbation = np.random.uniform(-perturbation_size, perturbation_size, positions.shape)\n",
    "            positions += perturbation  # Perturb the atomic positions\n",
    "\n",
    "        # Update edge attributes based on perturbed positions\n",
    "        # Since edge_index remains the same, we recompute edge_attr\n",
    "        perturbed_atoms = atoms.copy()\n",
    "        perturbed_atoms.set_positions(positions)\n",
    "        perturbed_atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Recompute edge attributes\n",
    "        perturbed_edge_attr = compute_edge_attr(perturbed_atoms, graph.edge_index)\n",
    "        perturbed_graph.edge_attr = perturbed_edge_attr\n",
    "\n",
    "        # Recompute node features based on perturbed positions\n",
    "        perturbed_node_features = compute_node_features(perturbed_atoms, SUPERCELL_SIZE)\n",
    "        perturbed_graph.x = perturbed_node_features\n",
    "\n",
    "        perturbed_graph_list.append(perturbed_graph)\n",
    "\n",
    "    return perturbed_graph_list\n",
    "\n",
    "# Function to read graphs and atoms from a folder\n",
    "def read_graphs_from_folder(folder_path, delta, SUPERCELL_SIZE):\n",
    "    graph_list = []\n",
    "    atoms_list = []\n",
    "    filenames = sorted([f for f in os.listdir(folder_path) if f.endswith('.xyz')])\n",
    "    for filename in filenames:\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        atoms = read(filepath)\n",
    "        atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Extract the last number from the filename\n",
    "        match = re.findall(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match[-1])  # Get the last number\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "\n",
    "        # Create graph with PBCs\n",
    "        graph = create_graph_from_structure(atoms, delta, SUPERCELL_SIZE, label)\n",
    "\n",
    "        # Append the graph and atoms to their respective lists\n",
    "        graph_list.append(graph)\n",
    "        atoms_list.append(atoms)\n",
    "\n",
    "        print(f\"Graph for {filename} created and added to the list with label {label}.\")\n",
    "\n",
    "    return graph_list, atoms_list\n",
    "\n",
    "# Function to check connectivity and separate graphs along with their corresponding atoms\n",
    "def separate_connected_disconnected(graph_list, atoms_list):\n",
    "    connected_graphs = []\n",
    "    connected_atoms = []\n",
    "    disconnected_graphs = []\n",
    "    disconnected_atoms = []\n",
    "\n",
    "    for graph, atoms in zip(graph_list, atoms_list):\n",
    "        # Convert PyG graph to NetworkX graph\n",
    "        G = to_networkx(graph, to_undirected=True)\n",
    "\n",
    "        if nx.is_connected(G):\n",
    "            connected_graphs.append(graph)\n",
    "            connected_atoms.append(atoms)\n",
    "        else:\n",
    "            disconnected_graphs.append(graph)\n",
    "            disconnected_atoms.append(atoms)\n",
    "\n",
    "    return connected_graphs, connected_atoms, disconnected_graphs, disconnected_atoms\n",
    "\n",
    "# Paths to the supercell files folders\n",
    "supercell_folder_1 = 'Supercells/supercells_flatband_rotated_shifted_aligned_3x3'\n",
    "supercell_folder_2 = 'Supercells/supercells_flatband_rotated_shifted_aligned_4x4'\n",
    "\n",
    "# Read graphs and atoms from the 3x3 folder\n",
    "graph_list_unperturbed_1, atoms_list_unperturbed_1 = read_graphs_from_folder(\n",
    "    supercell_folder_1, delta, SUPERCELL_SIZE_1\n",
    ")\n",
    "print(\"Unperturbed graph list for 3x3 supercells created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# Separate connected and disconnected graphs for 3x3 supercells\n",
    "connected_graphs_unperturbed_1, connected_atoms_unperturbed_1, disconnected_graphs_unperturbed_1, disconnected_atoms_unperturbed_1 = separate_connected_disconnected(\n",
    "    graph_list_unperturbed_1, atoms_list_unperturbed_1\n",
    ")\n",
    "print(f\"Total graphs in 3x3: {len(graph_list_unperturbed_1)}\")\n",
    "print(f\"Connected graphs in 3x3: {len(connected_graphs_unperturbed_1)}\")\n",
    "print(f\"Disconnected graphs in 3x3: {len(disconnected_graphs_unperturbed_1)}\")\n",
    "\n",
    "# Read graphs and atoms from the 4x4 folder\n",
    "graph_list_unperturbed_2, atoms_list_unperturbed_2 = read_graphs_from_folder(\n",
    "    supercell_folder_2, delta, SUPERCELL_SIZE_2\n",
    ")\n",
    "print(\"Unperturbed graph list for 4x4 supercells created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# Separate connected and disconnected graphs for 4x4 supercells\n",
    "connected_graphs_unperturbed_2, connected_atoms_unperturbed_2, disconnected_graphs_unperturbed_2, disconnected_atoms_unperturbed_2 = separate_connected_disconnected(\n",
    "    graph_list_unperturbed_2, atoms_list_unperturbed_2\n",
    ")\n",
    "print(f\"Total graphs in 4x4: {len(graph_list_unperturbed_2)}\")\n",
    "print(f\"Connected graphs in 4x4: {len(connected_graphs_unperturbed_2)}\")\n",
    "print(f\"Disconnected graphs in 4x4: {len(disconnected_graphs_unperturbed_2)}\")\n",
    "\n",
    "# Extract labels of connected graphs\n",
    "labels_connected_1 = set(graph.label for graph in connected_graphs_unperturbed_1)\n",
    "labels_connected_2 = set(graph.label for graph in connected_graphs_unperturbed_2)\n",
    "\n",
    "# Find common labels\n",
    "common_labels = labels_connected_1.intersection(labels_connected_2)\n",
    "print(f\"Number of common connected graphs: {len(common_labels)}\")\n",
    "\n",
    "# Filter connected graphs and atoms to only keep those with labels in common_labels\n",
    "filtered_connected_graphs_unperturbed_1 = []\n",
    "filtered_connected_atoms_unperturbed_1 = []\n",
    "for graph, atoms in zip(connected_graphs_unperturbed_1, connected_atoms_unperturbed_1):\n",
    "    if graph.label in common_labels:\n",
    "        filtered_connected_graphs_unperturbed_1.append(graph)\n",
    "        filtered_connected_atoms_unperturbed_1.append(atoms)\n",
    "\n",
    "filtered_connected_graphs_unperturbed_2 = []\n",
    "filtered_connected_atoms_unperturbed_2 = []\n",
    "for graph, atoms in zip(connected_graphs_unperturbed_2, connected_atoms_unperturbed_2):\n",
    "    if graph.label in common_labels:\n",
    "        filtered_connected_graphs_unperturbed_2.append(graph)\n",
    "        filtered_connected_atoms_unperturbed_2.append(atoms)\n",
    "\n",
    "print(f\"Filtered connected graphs in 3x3: {len(filtered_connected_graphs_unperturbed_1)}\")\n",
    "print(f\"Filtered connected graphs in 4x4: {len(filtered_connected_graphs_unperturbed_2)}\")\n",
    "\n",
    "# Perturb the filtered connected 3x3 graphs to create the first perturbed graph list\n",
    "graph_list_set_1 = perturb_graphs(\n",
    "    filtered_connected_graphs_unperturbed_1, filtered_connected_atoms_unperturbed_1, perturbation_size, delta, SUPERCELL_SIZE_1\n",
    ")\n",
    "\n",
    "# Perturb the filtered connected 4x4 graphs to create the second perturbed graph list\n",
    "graph_list_set_2 = perturb_graphs(\n",
    "    filtered_connected_graphs_unperturbed_2, filtered_connected_atoms_unperturbed_2, perturbation_size, delta, SUPERCELL_SIZE_2\n",
    ")\n",
    "\n",
    "graph_list_unperturbed = filtered_connected_graphs_unperturbed_1\n",
    "print(\"Two perturbed graph lists created from common connected graphs in 3x3 and 4x4 supercells respectively.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator: hyperedge, variable supercell size, next nearest neighbor and PBC, xyz node features, xyz edge attributes\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define the tolerance delta for nearest neighbors\n",
    "delta = 0.1  # Adjust as needed\n",
    "\n",
    "# Define the perturbation size\n",
    "perturbation_size = 0.05  # Adjust as needed\n",
    "\n",
    "# Function to compute edge_index based on positions and delta, considering PBCs\n",
    "def compute_edge_index(atoms, delta):\n",
    "    positions = atoms.get_positions()\n",
    "    num_atoms = len(positions)\n",
    "\n",
    "    # Compute distance matrix considering PBCs\n",
    "    dist_matrix = atoms.get_all_distances(mic=True)\n",
    "    edge_index_set = set()  # Use a set to avoid duplicate edges\n",
    "\n",
    "    # For each node, find its nearest neighbors and next-nearest neighbors\n",
    "    for i in range(num_atoms):\n",
    "        # Exclude self-distance by setting diagonal to infinity\n",
    "        dist_matrix[i, i] = np.inf\n",
    "\n",
    "        # Get distances and sort them along with indices\n",
    "        distances = dist_matrix[i]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        sorted_distances = distances[sorted_indices]\n",
    "\n",
    "        # Nearest neighbor distance\n",
    "        d1 = sorted_distances[0]\n",
    "        nn_cutoff = d1 + delta\n",
    "\n",
    "        # Indices of nearest neighbors within d1 + delta\n",
    "        nn_indices = sorted_indices[sorted_distances <= nn_cutoff]\n",
    "\n",
    "        # Add edges from i to nearest neighbors\n",
    "        for j in nn_indices:\n",
    "            edge_index_set.add((i, j))\n",
    "\n",
    "        # Exclude nearest neighbors from consideration for next-nearest neighbors\n",
    "        remaining_indices = sorted_indices[sorted_distances > nn_cutoff]\n",
    "        remaining_distances = sorted_distances[sorted_distances > nn_cutoff]\n",
    "\n",
    "        if len(remaining_distances) > 0:\n",
    "            # Next-nearest neighbor distance\n",
    "            d2 = remaining_distances[0]\n",
    "            nnn_cutoff = d2 + delta\n",
    "\n",
    "            # Indices of next-nearest neighbors within d2 + delta\n",
    "            nnn_indices = remaining_indices[remaining_distances <= nnn_cutoff]\n",
    "\n",
    "            # Add edges from i to next-nearest neighbors\n",
    "            for j in nnn_indices:\n",
    "                edge_index_set.add((i, j))\n",
    "\n",
    "    # Convert edge_index_set to a tensor\n",
    "    if len(edge_index_set) > 0:\n",
    "        edge_index = torch.tensor(list(edge_index_set), dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    # Make edges undirected by adding reverse edges\n",
    "    edge_index_rev = edge_index.flip(0)\n",
    "    edge_index = torch.cat([edge_index, edge_index_rev], dim=1)\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "# Function to compute edge attributes as displacement vectors considering PBCs\n",
    "def compute_edge_attr(atoms, edge_index):\n",
    "    row, col = edge_index\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "\n",
    "    # Compute displacement vectors considering PBCs\n",
    "    delta_scaled = scaled_positions[row.numpy()] - scaled_positions[col.numpy()]\n",
    "    delta_scaled -= np.round(delta_scaled)  # Apply minimum image convention\n",
    "    displacement_vectors = delta_scaled @ cell  # Convert back to Cartesian coordinates\n",
    "\n",
    "    # Create edge attributes as displacement vectors\n",
    "    edge_attr = torch.tensor(displacement_vectors, dtype=torch.float)\n",
    "    return edge_attr\n",
    "\n",
    "# Function to compute node features (relative positions within unit cells)\n",
    "def compute_node_features(atoms, SUPERCELL_SIZE):\n",
    "    num_atoms = len(atoms)\n",
    "    N = SUPERCELL_SIZE\n",
    "    total_unit_cells = N * N  # For a 2D lattice\n",
    "\n",
    "    # Compute the number of atoms per unit cell\n",
    "    atoms_per_unit_cell = num_atoms // total_unit_cells\n",
    "\n",
    "    # Check for consistency\n",
    "    if atoms_per_unit_cell * total_unit_cells != num_atoms:\n",
    "        raise ValueError(\"Number of atoms per unit cell is not consistent with total atoms and supercell dimensions.\")\n",
    "\n",
    "    # Group atoms by unit cell based on their order in the .xyz file\n",
    "    unit_cell_indices = []\n",
    "    for i in range(0, num_atoms, atoms_per_unit_cell):\n",
    "        group = list(range(i, i + atoms_per_unit_cell))\n",
    "        unit_cell_indices.append(group)\n",
    "\n",
    "    # Compute relative positions\n",
    "    positions = atoms.get_positions()\n",
    "    relative_positions = np.zeros_like(positions)\n",
    "\n",
    "    for group in unit_cell_indices:\n",
    "        indices = group\n",
    "        positions_in_cell = positions[indices]\n",
    "        reference_position = positions_in_cell[0]  # First atom in the unit cell\n",
    "        relative_positions_in_cell = positions_in_cell - reference_position\n",
    "        relative_positions[indices] = relative_positions_in_cell\n",
    "\n",
    "    # Create node features as torch tensor\n",
    "    node_features = torch.tensor(relative_positions, dtype=torch.float)\n",
    "    return node_features\n",
    "\n",
    "# Function to compute hyperedges based on existing edges\n",
    "def compute_hyperedges(edge_index, num_nodes):\n",
    "    # Build adjacency list\n",
    "    adj_list = [[] for _ in range(num_nodes)]\n",
    "    for idx in range(edge_index.size(1)):\n",
    "        src = edge_index[0, idx].item()\n",
    "        tgt = edge_index[1, idx].item()\n",
    "        adj_list[src].append(tgt)\n",
    "\n",
    "    # Remove duplicates in adjacency lists\n",
    "    for neighbors in adj_list:\n",
    "        neighbors[:] = list(set(neighbors))\n",
    "\n",
    "    # Create hyperedges\n",
    "    hyperedges = []\n",
    "    for j in range(num_nodes):\n",
    "        neighbors = adj_list[j]\n",
    "        # For all pairs of neighbors of node j\n",
    "        for idx1 in range(len(neighbors)):\n",
    "            for idx2 in range(idx1 + 1, len(neighbors)):\n",
    "                i = neighbors[idx1]\n",
    "                k = neighbors[idx2]\n",
    "                hyperedges.append([i, j, k])\n",
    "\n",
    "    if len(hyperedges) > 0:\n",
    "        hyperedge_index = torch.tensor(hyperedges, dtype=torch.long).t().contiguous()  # Shape [3, num_hyperedges]\n",
    "    else:\n",
    "        hyperedge_index = torch.empty((3, 0), dtype=torch.long)\n",
    "\n",
    "    return hyperedge_index\n",
    "\n",
    "# Function to compute hyperedge attributes (angles between edges)\n",
    "def compute_hyperedge_attr(atoms, hyperedge_index):\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "    num_hyperedges = hyperedge_index.size(1)\n",
    "    hyperedge_attr = []\n",
    "\n",
    "    for idx in range(num_hyperedges):\n",
    "        i = hyperedge_index[0, idx].item()\n",
    "        j = hyperedge_index[1, idx].item()\n",
    "        k = hyperedge_index[2, idx].item()\n",
    "\n",
    "        # Scaled positions\n",
    "        pos_i = scaled_positions[i]\n",
    "        pos_j = scaled_positions[j]\n",
    "        pos_k = scaled_positions[k]\n",
    "\n",
    "        # Displacement vectors considering PBCs\n",
    "        delta_ji_scaled = pos_i - pos_j\n",
    "        delta_ji_scaled -= np.round(delta_ji_scaled)\n",
    "        d_ji = delta_ji_scaled @ cell\n",
    "\n",
    "        delta_jk_scaled = pos_k - pos_j\n",
    "        delta_jk_scaled -= np.round(delta_jk_scaled)\n",
    "        d_jk = delta_jk_scaled @ cell\n",
    "\n",
    "        # Compute angle between d_ji and d_jk\n",
    "        cos_theta = np.dot(d_ji, d_jk) / (np.linalg.norm(d_ji) * np.linalg.norm(d_jk) + 1e-8)\n",
    "        angle = np.arccos(np.clip(cos_theta, -1.0, 1.0))  # Angle in radians\n",
    "\n",
    "        hyperedge_attr.append([angle])\n",
    "\n",
    "    hyperedge_attr = torch.tensor(hyperedge_attr, dtype=torch.float)  # Shape [num_hyperedges, 1]\n",
    "    return hyperedge_attr\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure\n",
    "def create_graph_from_structure(atoms, delta, SUPERCELL_SIZE):\n",
    "    num_atoms = len(atoms)\n",
    "\n",
    "    # Compute edge_index\n",
    "    edge_index = compute_edge_index(atoms, delta)\n",
    "\n",
    "    # Compute edge attributes\n",
    "    edge_attr = compute_edge_attr(atoms, edge_index)\n",
    "\n",
    "    # Compute node features\n",
    "    node_features = compute_node_features(atoms, SUPERCELL_SIZE)\n",
    "\n",
    "    # Compute hyperedges\n",
    "    hyperedge_index = compute_hyperedges(edge_index, num_atoms)\n",
    "\n",
    "    # Compute hyperedge attributes\n",
    "    hyperedge_attr = compute_hyperedge_attr(atoms, hyperedge_index)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "        hyperedge_index=hyperedge_index,\n",
    "        hyperedge_attr=hyperedge_attr,\n",
    "    )\n",
    "\n",
    "    graph.supercell_size = SUPERCELL_SIZE  # Store supercell size in graph\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to apply perturbations to a graph list\n",
    "def perturb_graphs(graph_list, atoms_list, perturbation_size, delta):\n",
    "    perturbed_graph_list = []\n",
    "    for graph, atoms in zip(graph_list, atoms_list):\n",
    "        # Clone the graph to avoid modifying the original\n",
    "        perturbed_graph = graph.clone()\n",
    "\n",
    "        # Get the positions of the atoms from the atoms object\n",
    "        positions = atoms.get_positions().copy()  # Original positions\n",
    "\n",
    "        # Apply random perturbation to the positions\n",
    "        if perturbation_size > 0:\n",
    "            perturbation = np.random.uniform(-perturbation_size, perturbation_size, positions.shape)\n",
    "            positions += perturbation  # Perturb the atomic positions\n",
    "\n",
    "        # Update atoms object with perturbed positions\n",
    "        perturbed_atoms = atoms.copy()\n",
    "        perturbed_atoms.set_positions(positions)\n",
    "        perturbed_atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Recompute edge_index (optional if edges remain the same)\n",
    "        # If you expect the perturbation to change the connectivity, recompute edge_index\n",
    "        # For this example, we'll keep the same edge_index\n",
    "        edge_index = graph.edge_index\n",
    "\n",
    "        # Recompute edge attributes\n",
    "        perturbed_edge_attr = compute_edge_attr(perturbed_atoms, edge_index)\n",
    "        perturbed_graph.edge_attr = perturbed_edge_attr\n",
    "\n",
    "        # Recompute node features based on perturbed positions\n",
    "        perturbed_node_features = compute_node_features(perturbed_atoms, graph.supercell_size)\n",
    "        perturbed_graph.x = perturbed_node_features\n",
    "\n",
    "        # Recompute hyperedge attributes based on perturbed positions\n",
    "        hyperedge_index = graph.hyperedge_index\n",
    "        perturbed_hyperedge_attr = compute_hyperedge_attr(perturbed_atoms, hyperedge_index)\n",
    "        perturbed_graph.hyperedge_attr = perturbed_hyperedge_attr\n",
    "\n",
    "        perturbed_graph_list.append(perturbed_graph)\n",
    "\n",
    "    return perturbed_graph_list\n",
    "\n",
    "# Function to read graphs and atoms from a folder\n",
    "def read_graphs_from_folder(folder_path, delta, SUPERCELL_SIZE):\n",
    "    graph_list = []\n",
    "    atoms_list = []\n",
    "    filenames = sorted([f for f in os.listdir(folder_path) if f.endswith('.xyz')])\n",
    "    for filename in filenames:\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        atoms = read(filepath)\n",
    "        atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Extract the last number from the filename\n",
    "        match = re.findall(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match[-1])  # Get the last number\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "\n",
    "        # Create graph with PBCs\n",
    "        graph = create_graph_from_structure(atoms, delta, SUPERCELL_SIZE)\n",
    "        graph.label = label\n",
    "\n",
    "        # Append the graph and atoms to their respective lists\n",
    "        graph_list.append(graph)\n",
    "        atoms_list.append(atoms)\n",
    "\n",
    "        print(f\"Graph for {filename} created and added to the list with label {label}.\")\n",
    "\n",
    "    return graph_list, atoms_list\n",
    "\n",
    "# Paths to the supercell files folders\n",
    "supercell_folder_1 = 'Supercells/supercells_flatband_rotated_shifted_aligned_3x3'\n",
    "supercell_folder_2 = 'Supercells/supercells_flatband_rotated_shifted_aligned_4x4'\n",
    "\n",
    "SUPERCELL_SIZE_1 = 3  # Adjust as needed\n",
    "SUPERCELL_SIZE_2 = 4  # Adjust as needed\n",
    "\n",
    "# Read graphs and atoms from the 3x3 folder\n",
    "graph_list_unperturbed_1, atoms_list_unperturbed_1 = read_graphs_from_folder(\n",
    "    supercell_folder_1, delta, SUPERCELL_SIZE_1\n",
    ")\n",
    "print(\"Unperturbed graph list for 3x3 supercells created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# Read graphs and atoms from the 4x4 folder\n",
    "graph_list_unperturbed_2, atoms_list_unperturbed_2 = read_graphs_from_folder(\n",
    "    supercell_folder_2, delta, SUPERCELL_SIZE_2\n",
    ")\n",
    "print(\"Unperturbed graph list for 4x4 supercells created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# Perturb the unperturbed 3x3 graphs to create the first perturbed graph list\n",
    "graph_list_set_1 = perturb_graphs(\n",
    "    graph_list_unperturbed_1, atoms_list_unperturbed_1, perturbation_size, delta\n",
    ")\n",
    "\n",
    "# Perturb the unperturbed 4x4 graphs to create the second perturbed graph list\n",
    "graph_list_set_2 = perturb_graphs(\n",
    "    graph_list_unperturbed_2, atoms_list_unperturbed_2, perturbation_size, delta\n",
    ")\n",
    "\n",
    "print(\"Two perturbed graph lists created from 3x3 and 4x4 supercells respectively.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator: hyperedge, variable supercell size, next nearest neighbor and PBC, xyz node features, x edge attributes\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define the tolerance delta for nearest neighbors\n",
    "delta = 0.1  # Adjust as needed\n",
    "\n",
    "# Define the perturbation size\n",
    "perturbation_size = 0.05  # Adjust as needed\n",
    "\n",
    "# Function to compute edge_index based on positions and delta, considering PBCs\n",
    "def compute_edge_index(atoms, delta):\n",
    "    positions = atoms.get_positions()\n",
    "    num_atoms = len(positions)\n",
    "\n",
    "    # Compute distance matrix considering PBCs\n",
    "    dist_matrix = atoms.get_all_distances(mic=True)\n",
    "    edge_index_set = set()  # Use a set to avoid duplicate edges\n",
    "\n",
    "    # For each node, find its nearest neighbors and next-nearest neighbors\n",
    "    for i in range(num_atoms):\n",
    "        # Exclude self-distance by setting diagonal to infinity\n",
    "        dist_matrix[i, i] = np.inf\n",
    "\n",
    "        # Get distances and sort them along with indices\n",
    "        distances = dist_matrix[i]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        sorted_distances = distances[sorted_indices]\n",
    "\n",
    "        # Nearest neighbor distance\n",
    "        d1 = sorted_distances[0]\n",
    "        nn_cutoff = d1 + delta\n",
    "\n",
    "        # Indices of nearest neighbors within d1 + delta\n",
    "        nn_indices = sorted_indices[sorted_distances <= nn_cutoff]\n",
    "\n",
    "        # Add edges from i to nearest neighbors\n",
    "        for j in nn_indices:\n",
    "            edge_index_set.add((i, j))\n",
    "\n",
    "        # Exclude nearest neighbors from consideration for next-nearest neighbors\n",
    "        remaining_indices = sorted_indices[sorted_distances > nn_cutoff]\n",
    "        remaining_distances = sorted_distances[sorted_distances > nn_cutoff]\n",
    "\n",
    "        if len(remaining_distances) > 0:\n",
    "            # Next-nearest neighbor distance\n",
    "            d2 = remaining_distances[0]\n",
    "            nnn_cutoff = d2 + delta\n",
    "\n",
    "            # Indices of next-nearest neighbors within d2 + delta\n",
    "            nnn_indices = remaining_indices[remaining_distances <= nnn_cutoff]\n",
    "\n",
    "            # Add edges from i to next-nearest neighbors\n",
    "            for j in nnn_indices:\n",
    "                edge_index_set.add((i, j))\n",
    "\n",
    "    # Convert edge_index_set to a tensor\n",
    "    if len(edge_index_set) > 0:\n",
    "        edge_index = torch.tensor(list(edge_index_set), dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    # Make edges undirected by adding reverse edges\n",
    "    edge_index_rev = edge_index.flip(0)\n",
    "    edge_index = torch.cat([edge_index, edge_index_rev], dim=1)\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "# Function to compute edge attributes based on positions and edge_index, considering PBCs\n",
    "def compute_edge_attr(atoms, edge_index):\n",
    "    row, col = edge_index\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "    # Compute displacement vectors considering PBCs\n",
    "    delta_scaled = scaled_positions[row.numpy()] - scaled_positions[col.numpy()]\n",
    "    delta_scaled -= np.round(delta_scaled)\n",
    "    displacement_vectors = delta_scaled @ cell\n",
    "    edge_distances = np.linalg.norm(displacement_vectors, axis=1)\n",
    "    edge_attr = torch.tensor(edge_distances, dtype=torch.float).unsqueeze(1)\n",
    "    return edge_attr\n",
    "\n",
    "# Function to compute node features (relative positions within unit cells)\n",
    "def compute_node_features(atoms, SUPERCELL_SIZE):\n",
    "    num_atoms = len(atoms)\n",
    "    N = SUPERCELL_SIZE\n",
    "    total_unit_cells = N * N  # For a 2D lattice\n",
    "\n",
    "    # Compute the number of atoms per unit cell\n",
    "    atoms_per_unit_cell = num_atoms // total_unit_cells\n",
    "\n",
    "    # Check for consistency\n",
    "    if atoms_per_unit_cell * total_unit_cells != num_atoms:\n",
    "        raise ValueError(\"Number of atoms per unit cell is not consistent with total atoms and supercell dimensions.\")\n",
    "\n",
    "    # Group atoms by unit cell based on their order in the .xyz file\n",
    "    unit_cell_indices = []\n",
    "    for i in range(0, num_atoms, atoms_per_unit_cell):\n",
    "        group = list(range(i, i + atoms_per_unit_cell))\n",
    "        unit_cell_indices.append(group)\n",
    "\n",
    "    # Compute relative positions\n",
    "    positions = atoms.get_positions()\n",
    "    relative_positions = np.zeros_like(positions)\n",
    "\n",
    "    for group in unit_cell_indices:\n",
    "        indices = group\n",
    "        positions_in_cell = positions[indices]\n",
    "        reference_position = positions_in_cell[0]  # First atom in the unit cell\n",
    "        relative_positions_in_cell = positions_in_cell - reference_position\n",
    "        relative_positions[indices] = relative_positions_in_cell\n",
    "\n",
    "    # Create node features as torch tensor\n",
    "    node_features = torch.tensor(relative_positions, dtype=torch.float)\n",
    "    return node_features\n",
    "\n",
    "# Function to compute hyperedges based on existing edges\n",
    "def compute_hyperedges(edge_index, num_nodes):\n",
    "    # Build adjacency list\n",
    "    adj_list = [[] for _ in range(num_nodes)]\n",
    "    for idx in range(edge_index.size(1)):\n",
    "        src = edge_index[0, idx].item()\n",
    "        tgt = edge_index[1, idx].item()\n",
    "        adj_list[src].append(tgt)\n",
    "\n",
    "    # Remove duplicates in adjacency lists\n",
    "    for neighbors in adj_list:\n",
    "        neighbors[:] = list(set(neighbors))\n",
    "\n",
    "    # Create hyperedges\n",
    "    hyperedges = []\n",
    "    for j in range(num_nodes):\n",
    "        neighbors = adj_list[j]\n",
    "        # For all pairs of neighbors of node j\n",
    "        for idx1 in range(len(neighbors)):\n",
    "            for idx2 in range(idx1 + 1, len(neighbors)):\n",
    "                i = neighbors[idx1]\n",
    "                k = neighbors[idx2]\n",
    "                hyperedges.append([i, j, k])\n",
    "\n",
    "    if len(hyperedges) > 0:\n",
    "        hyperedge_index = torch.tensor(hyperedges, dtype=torch.long).t().contiguous()  # Shape [3, num_hyperedges]\n",
    "    else:\n",
    "        hyperedge_index = torch.empty((3, 0), dtype=torch.long)\n",
    "\n",
    "    return hyperedge_index\n",
    "\n",
    "# Function to compute hyperedge attributes (angles between edges)\n",
    "def compute_hyperedge_attr(atoms, hyperedge_index):\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "    num_hyperedges = hyperedge_index.size(1)\n",
    "    hyperedge_attr = []\n",
    "\n",
    "    for idx in range(num_hyperedges):\n",
    "        i = hyperedge_index[0, idx].item()\n",
    "        j = hyperedge_index[1, idx].item()\n",
    "        k = hyperedge_index[2, idx].item()\n",
    "\n",
    "        # Scaled positions\n",
    "        pos_i = scaled_positions[i]\n",
    "        pos_j = scaled_positions[j]\n",
    "        pos_k = scaled_positions[k]\n",
    "\n",
    "        # Displacement vectors considering PBCs\n",
    "        delta_ji_scaled = pos_i - pos_j\n",
    "        delta_ji_scaled -= np.round(delta_ji_scaled)\n",
    "        d_ji = delta_ji_scaled @ cell\n",
    "\n",
    "        delta_jk_scaled = pos_k - pos_j\n",
    "        delta_jk_scaled -= np.round(delta_jk_scaled)\n",
    "        d_jk = delta_jk_scaled @ cell\n",
    "\n",
    "        # Compute angle between d_ji and d_jk\n",
    "        cos_theta = np.dot(d_ji, d_jk) / (np.linalg.norm(d_ji) * np.linalg.norm(d_jk) + 1e-8)\n",
    "        angle = np.arccos(np.clip(cos_theta, -1.0, 1.0))  # Angle in radians\n",
    "\n",
    "        hyperedge_attr.append([angle])\n",
    "\n",
    "    hyperedge_attr = torch.tensor(hyperedge_attr, dtype=torch.float)  # Shape [num_hyperedges, 1]\n",
    "    return hyperedge_attr\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure\n",
    "def create_graph_from_structure(atoms, delta, SUPERCELL_SIZE):\n",
    "    num_atoms = len(atoms)\n",
    "\n",
    "    # Compute edge_index\n",
    "    edge_index = compute_edge_index(atoms, delta)\n",
    "\n",
    "    # Compute edge attributes\n",
    "    edge_attr = compute_edge_attr(atoms, edge_index)\n",
    "\n",
    "    # Compute node features\n",
    "    node_features = compute_node_features(atoms, SUPERCELL_SIZE)\n",
    "\n",
    "    # Compute hyperedges\n",
    "    hyperedge_index = compute_hyperedges(edge_index, num_atoms)\n",
    "\n",
    "    # Compute hyperedge attributes\n",
    "    hyperedge_attr = compute_hyperedge_attr(atoms, hyperedge_index)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "        hyperedge_index=hyperedge_index,\n",
    "        hyperedge_attr=hyperedge_attr,\n",
    "    )\n",
    "\n",
    "    graph.supercell_size = SUPERCELL_SIZE  # Store supercell size in graph\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to apply perturbations to a graph list\n",
    "def perturb_graphs(graph_list, atoms_list, perturbation_size, delta):\n",
    "    perturbed_graph_list = []\n",
    "    for graph, atoms in zip(graph_list, atoms_list):\n",
    "        # Clone the graph to avoid modifying the original\n",
    "        perturbed_graph = graph.clone()\n",
    "\n",
    "        # Get the positions of the atoms from the atoms object\n",
    "        positions = atoms.get_positions().copy()  # Original positions\n",
    "\n",
    "        # Apply random perturbation to the positions\n",
    "        if perturbation_size > 0:\n",
    "            perturbation = np.random.uniform(-perturbation_size, perturbation_size, positions.shape)\n",
    "            positions += perturbation  # Perturb the atomic positions\n",
    "\n",
    "        # Update atoms object with perturbed positions\n",
    "        perturbed_atoms = atoms.copy()\n",
    "        perturbed_atoms.set_positions(positions)\n",
    "        perturbed_atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Recompute edge_index (optional if edges remain the same)\n",
    "        # If you expect the perturbation to change the connectivity, recompute edge_index\n",
    "        # For this example, we'll keep the same edge_index\n",
    "        edge_index = graph.edge_index\n",
    "\n",
    "        # Recompute edge attributes\n",
    "        perturbed_edge_attr = compute_edge_attr(perturbed_atoms, edge_index)\n",
    "        perturbed_graph.edge_attr = perturbed_edge_attr\n",
    "\n",
    "        # Recompute node features based on perturbed positions\n",
    "        perturbed_node_features = compute_node_features(perturbed_atoms, graph.supercell_size)\n",
    "        perturbed_graph.x = perturbed_node_features\n",
    "\n",
    "        # Recompute hyperedge attributes based on perturbed positions\n",
    "        hyperedge_index = graph.hyperedge_index\n",
    "        perturbed_hyperedge_attr = compute_hyperedge_attr(perturbed_atoms, hyperedge_index)\n",
    "        perturbed_graph.hyperedge_attr = perturbed_hyperedge_attr\n",
    "\n",
    "        perturbed_graph_list.append(perturbed_graph)\n",
    "\n",
    "    return perturbed_graph_list\n",
    "\n",
    "# Function to read graphs and atoms from a folder\n",
    "def read_graphs_from_folder(folder_path, delta, SUPERCELL_SIZE):\n",
    "    graph_list = []\n",
    "    atoms_list = []\n",
    "    filenames = sorted([f for f in os.listdir(folder_path) if f.endswith('.xyz')])\n",
    "    for filename in filenames:\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        atoms = read(filepath)\n",
    "        atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Extract the last number from the filename\n",
    "        match = re.findall(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match[-1])  # Get the last number\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "\n",
    "        # Create graph with PBCs\n",
    "        graph = create_graph_from_structure(atoms, delta, SUPERCELL_SIZE)\n",
    "        graph.label = label\n",
    "\n",
    "        # Append the graph and atoms to their respective lists\n",
    "        graph_list.append(graph)\n",
    "        atoms_list.append(atoms)\n",
    "\n",
    "        print(f\"Graph for {filename} created and added to the list with label {label}.\")\n",
    "\n",
    "    return graph_list, atoms_list\n",
    "\n",
    "# Paths to the supercell files folders\n",
    "supercell_folder_1 = 'Supercells/supercells_flatband_rotated_shifted_aligned_3x3'\n",
    "supercell_folder_2 = 'Supercells/supercells_flatband_rotated_shifted_aligned_4x4'\n",
    "\n",
    "SUPERCELL_SIZE_1 = 3  # Adjust as needed\n",
    "SUPERCELL_SIZE_2 = 4  # Adjust as needed\n",
    "\n",
    "# Read graphs and atoms from the 3x3 folder\n",
    "graph_list_unperturbed_1, atoms_list_unperturbed_1 = read_graphs_from_folder(\n",
    "    supercell_folder_1, delta, SUPERCELL_SIZE_1\n",
    ")\n",
    "print(\"Unperturbed graph list for 3x3 supercells created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# Read graphs and atoms from the 4x4 folder\n",
    "graph_list_unperturbed_2, atoms_list_unperturbed_2 = read_graphs_from_folder(\n",
    "    supercell_folder_2, delta, SUPERCELL_SIZE_2\n",
    ")\n",
    "print(\"Unperturbed graph list for 4x4 supercells created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# Perturb the unperturbed 3x3 graphs to create the first perturbed graph list\n",
    "graph_list_set_1 = perturb_graphs(\n",
    "    graph_list_unperturbed_1, atoms_list_unperturbed_1, perturbation_size, delta\n",
    ")\n",
    "\n",
    "# Perturb the unperturbed 4x4 graphs to create the second perturbed graph list\n",
    "graph_list_set_2 = perturb_graphs(\n",
    "    graph_list_unperturbed_2, atoms_list_unperturbed_2, perturbation_size, delta\n",
    ")\n",
    "\n",
    "print(\"Two perturbed graph lists created from 3x3 and 4x4 supercells respectively.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph generator: hyperedge, variable supercell size, lattice vector and intra unit cell, xyz node features, xyz edge attributes\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from torch_geometric.data import Data\n",
    "from scipy.spatial import cKDTree  # Added import for cKDTree\n",
    "\n",
    "# Define the tolerance delta for nearest neighbors\n",
    "delta = 0.1  # Adjust as needed\n",
    "\n",
    "# Define the perturbation size\n",
    "perturbation_size = 0.005  # Adjust as needed\n",
    "\n",
    "# Function to compute edge_index based on positions and delta, considering PBCs\n",
    "def compute_edge_index(atoms, delta, N):\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "    num_atoms = len(scaled_positions)\n",
    "    cell = atoms.get_cell()\n",
    "\n",
    "    # Build a KDTree of the scaled positions\n",
    "    tree = cKDTree(scaled_positions)\n",
    "\n",
    "    # Define shifts in scaled coordinates (a and b)\n",
    "    shifts_scaled = np.array([\n",
    "        [1 / N, 0, 0],\n",
    "        [-1 / N, 0, 0],\n",
    "        [0, 1 / N, 0],\n",
    "        [0, -1 / N, 0],\n",
    "    ])\n",
    "\n",
    "    edge_index = set()\n",
    "\n",
    "    # Existing lattice vector connections\n",
    "    for i in range(num_atoms):\n",
    "        s_i = scaled_positions[i]\n",
    "        for shift_scaled in shifts_scaled:\n",
    "            s_j_candidate = s_i + shift_scaled\n",
    "            s_j_candidate = np.mod(s_j_candidate, 1.0)  # Apply PBCs\n",
    "            # Query KDTree to find atoms near s_j_candidate\n",
    "            idxs = tree.query_ball_point(s_j_candidate, r=delta)\n",
    "            for idx in idxs:\n",
    "                if idx != i:  # Exclude self-loops\n",
    "                    edge_index.add((i, idx))\n",
    "                    edge_index.add((idx, i))  # Add reverse edge\n",
    "\n",
    "    # Determine the number of atoms per unit cell\n",
    "    total_unit_cells = N * N  # For a 2D lattice\n",
    "    atoms_per_unit_cell = num_atoms // total_unit_cells\n",
    "\n",
    "    # Check for consistency\n",
    "    if atoms_per_unit_cell * total_unit_cells != num_atoms:\n",
    "        raise ValueError(\"Number of atoms per unit cell is not consistent with total atoms and supercell dimensions.\")\n",
    "\n",
    "    # Group atoms by unit cell based on their order in the .xyz file\n",
    "    for i in range(0, num_atoms, atoms_per_unit_cell):\n",
    "        group = list(range(i, i + atoms_per_unit_cell))\n",
    "        # Add edges within each unit cell\n",
    "        for idx1 in group:\n",
    "            for idx2 in group:\n",
    "                if idx1 != idx2:\n",
    "                    edge_index.add((idx1, idx2))\n",
    "                    edge_index.add((idx2, idx1))  # Ensure symmetry\n",
    "\n",
    "    # Convert edge_index to tensor\n",
    "    if edge_index:\n",
    "        edge_index = torch.tensor(list(edge_index), dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "# Function to compute edge attributes based on positions and edge_index, considering PBCs\n",
    "def compute_edge_attr(atoms, edge_index):\n",
    "    row, col = edge_index\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "    # Compute displacement vectors considering PBCs\n",
    "    delta_scaled = scaled_positions[row.numpy()] - scaled_positions[col.numpy()]\n",
    "    delta_scaled -= np.round(delta_scaled)\n",
    "    displacement_vectors = delta_scaled @ cell\n",
    "    edge_distances = np.linalg.norm(displacement_vectors, axis=1)\n",
    "    edge_attr = torch.tensor(edge_distances, dtype=torch.float).unsqueeze(1)\n",
    "    return edge_attr\n",
    "\n",
    "# Function to compute node features (relative positions within unit cells)\n",
    "def compute_node_features(atoms, SUPERCELL_SIZE):\n",
    "    num_atoms = len(atoms)\n",
    "    N = SUPERCELL_SIZE\n",
    "    total_unit_cells = N * N  # For a 2D lattice\n",
    "\n",
    "    # Compute the number of atoms per unit cell\n",
    "    atoms_per_unit_cell = num_atoms // total_unit_cells\n",
    "\n",
    "    # Check for consistency\n",
    "    if atoms_per_unit_cell * total_unit_cells != num_atoms:\n",
    "        raise ValueError(\"Number of atoms per unit cell is not consistent with total atoms and supercell dimensions.\")\n",
    "\n",
    "    # Group atoms by unit cell based on their order in the .xyz file\n",
    "    unit_cell_indices = []\n",
    "    for i in range(0, num_atoms, atoms_per_unit_cell):\n",
    "        group = list(range(i, i + atoms_per_unit_cell))\n",
    "        unit_cell_indices.append(group)\n",
    "\n",
    "    # Compute relative positions\n",
    "    positions = atoms.get_positions()\n",
    "    relative_positions = np.zeros_like(positions)\n",
    "\n",
    "    for group in unit_cell_indices:\n",
    "        indices = group\n",
    "        positions_in_cell = positions[indices]\n",
    "        reference_position = positions_in_cell[0]  # First atom in the unit cell\n",
    "        relative_positions_in_cell = positions_in_cell - reference_position\n",
    "        relative_positions[indices] = relative_positions_in_cell\n",
    "\n",
    "    # Create node features as torch tensor\n",
    "    node_features = torch.tensor(relative_positions, dtype=torch.float)\n",
    "    return node_features\n",
    "\n",
    "# Function to compute hyperedges based on existing edges\n",
    "def compute_hyperedges(edge_index, num_nodes):\n",
    "    # Build adjacency list\n",
    "    adj_list = [[] for _ in range(num_nodes)]\n",
    "    for idx in range(edge_index.size(1)):\n",
    "        src = edge_index[0, idx].item()\n",
    "        tgt = edge_index[1, idx].item()\n",
    "        adj_list[src].append(tgt)\n",
    "\n",
    "    # Remove duplicates in adjacency lists\n",
    "    for neighbors in adj_list:\n",
    "        neighbors[:] = list(set(neighbors))\n",
    "\n",
    "    # Create hyperedges\n",
    "    hyperedges = []\n",
    "    for j in range(num_nodes):\n",
    "        neighbors = adj_list[j]\n",
    "        # For all pairs of neighbors of node j\n",
    "        for idx1 in range(len(neighbors)):\n",
    "            for idx2 in range(idx1 + 1, len(neighbors)):\n",
    "                i = neighbors[idx1]\n",
    "                k = neighbors[idx2]\n",
    "                hyperedges.append([i, j, k])\n",
    "\n",
    "    if len(hyperedges) > 0:\n",
    "        hyperedge_index = torch.tensor(hyperedges, dtype=torch.long).t().contiguous()  # Shape [3, num_hyperedges]\n",
    "    else:\n",
    "        hyperedge_index = torch.empty((3, 0), dtype=torch.long)\n",
    "\n",
    "    return hyperedge_index\n",
    "\n",
    "# Function to compute hyperedge attributes (angles between edges)\n",
    "def compute_hyperedge_attr(atoms, hyperedge_index):\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "    num_hyperedges = hyperedge_index.size(1)\n",
    "    hyperedge_attr = []\n",
    "\n",
    "    for idx in range(num_hyperedges):\n",
    "        i = hyperedge_index[0, idx].item()\n",
    "        j = hyperedge_index[1, idx].item()\n",
    "        k = hyperedge_index[2, idx].item()\n",
    "\n",
    "        # Scaled positions\n",
    "        pos_i = scaled_positions[i]\n",
    "        pos_j = scaled_positions[j]\n",
    "        pos_k = scaled_positions[k]\n",
    "\n",
    "        # Displacement vectors considering PBCs\n",
    "        delta_ji_scaled = pos_i - pos_j\n",
    "        delta_ji_scaled -= np.round(delta_ji_scaled)\n",
    "        d_ji = delta_ji_scaled @ cell\n",
    "\n",
    "        delta_jk_scaled = pos_k - pos_j\n",
    "        delta_jk_scaled -= np.round(delta_jk_scaled)\n",
    "        d_jk = delta_jk_scaled @ cell\n",
    "\n",
    "        # Compute angle between d_ji and d_jk\n",
    "        cos_theta = np.dot(d_ji, d_jk) / (np.linalg.norm(d_ji) * np.linalg.norm(d_jk) + 1e-8)\n",
    "        angle = np.arccos(np.clip(cos_theta, -1.0, 1.0))  # Angle in radians\n",
    "\n",
    "        hyperedge_attr.append([angle])\n",
    "\n",
    "    hyperedge_attr = torch.tensor(hyperedge_attr, dtype=torch.float)  # Shape [num_hyperedges, 1]\n",
    "    return hyperedge_attr\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure\n",
    "def create_graph_from_structure(atoms, delta, SUPERCELL_SIZE):\n",
    "    num_atoms = len(atoms)\n",
    "\n",
    "    # Compute edge_index using the new function\n",
    "    edge_index = compute_edge_index(atoms, delta, SUPERCELL_SIZE)\n",
    "\n",
    "    # Compute edge attributes\n",
    "    edge_attr = compute_edge_attr(atoms, edge_index)\n",
    "\n",
    "    # Compute node features\n",
    "    node_features = compute_node_features(atoms, SUPERCELL_SIZE)\n",
    "\n",
    "    # Compute hyperedges\n",
    "    hyperedge_index = compute_hyperedges(edge_index, num_atoms)\n",
    "\n",
    "    # Compute hyperedge attributes\n",
    "    hyperedge_attr = compute_hyperedge_attr(atoms, hyperedge_index)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "        hyperedge_index=hyperedge_index,\n",
    "        hyperedge_attr=hyperedge_attr,\n",
    "    )\n",
    "\n",
    "    graph.supercell_size = SUPERCELL_SIZE  # Store supercell size in graph\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to apply perturbations to a graph list\n",
    "def perturb_graphs(graph_list, atoms_list, perturbation_size, delta):\n",
    "    perturbed_graph_list = []\n",
    "    for graph, atoms in zip(graph_list, atoms_list):\n",
    "        # Clone the graph to avoid modifying the original\n",
    "        perturbed_graph = graph.clone()\n",
    "\n",
    "        # Get the positions of the atoms from the atoms object\n",
    "        positions = atoms.get_positions().copy()  # Original positions\n",
    "\n",
    "        # Apply random perturbation to the positions\n",
    "        if perturbation_size > 0:\n",
    "            perturbation = np.random.uniform(-perturbation_size, perturbation_size, positions.shape)\n",
    "            positions += perturbation  # Perturb the atomic positions\n",
    "\n",
    "        # Update atoms object with perturbed positions\n",
    "        perturbed_atoms = atoms.copy()\n",
    "        perturbed_atoms.set_positions(positions)\n",
    "        perturbed_atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Recompute edge attributes\n",
    "        perturbed_edge_attr = compute_edge_attr(perturbed_atoms, perturbed_graph.edge_index)\n",
    "        perturbed_graph.edge_attr = perturbed_edge_attr\n",
    "\n",
    "        # Recompute node features based on perturbed positions\n",
    "        perturbed_node_features = compute_node_features(perturbed_atoms, graph.supercell_size)\n",
    "        perturbed_graph.x = perturbed_node_features\n",
    "\n",
    "        # Recompute hyperedge attributes based on perturbed positions\n",
    "        perturbed_hyperedge_attr = compute_hyperedge_attr(perturbed_atoms, perturbed_graph.hyperedge_index)\n",
    "        perturbed_graph.hyperedge_attr = perturbed_hyperedge_attr\n",
    "\n",
    "        perturbed_graph_list.append(perturbed_graph)\n",
    "\n",
    "    return perturbed_graph_list\n",
    "\n",
    "# Function to read graphs and atoms from a folder\n",
    "def read_graphs_from_folder(folder_path, delta, SUPERCELL_SIZE):\n",
    "    graph_list = []\n",
    "    atoms_list = []\n",
    "    filenames = sorted([f for f in os.listdir(folder_path) if f.endswith('.xyz')])\n",
    "    for filename in filenames:\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        atoms = read(filepath)\n",
    "        atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Extract the last number from the filename\n",
    "        match = re.findall(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match[-1])  # Get the last number\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "\n",
    "        # Create graph with PBCs\n",
    "        graph = create_graph_from_structure(atoms, delta, SUPERCELL_SIZE)\n",
    "        graph.label = label\n",
    "\n",
    "        # Append the graph and atoms to their respective lists\n",
    "        graph_list.append(graph)\n",
    "        atoms_list.append(atoms)\n",
    "\n",
    "        print(f\"Graph for {filename} created and added to the list with label {label}.\")\n",
    "\n",
    "    return graph_list, atoms_list\n",
    "\n",
    "# Paths to the supercell files folders\n",
    "supercell_folder_1 = 'Supercells/supercells_flatband_rotated_shifted_aligned_3x3'\n",
    "supercell_folder_2 = 'Supercells/supercells_flatband_rotated_shifted_aligned_4x4'\n",
    "\n",
    "SUPERCELL_SIZE_1 = 3  # Adjust as needed\n",
    "SUPERCELL_SIZE_2 = 4  # Adjust as needed\n",
    "\n",
    "# Read graphs and atoms from the 3x3 folder\n",
    "graph_list_unperturbed_1, atoms_list_unperturbed_1 = read_graphs_from_folder(\n",
    "    supercell_folder_1, delta, SUPERCELL_SIZE_1\n",
    ")\n",
    "print(\"Unperturbed graph list for 3x3 supercells created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# Read graphs and atoms from the 4x4 folder\n",
    "graph_list_unperturbed_2, atoms_list_unperturbed_2 = read_graphs_from_folder(\n",
    "    supercell_folder_2, delta, SUPERCELL_SIZE_2\n",
    ")\n",
    "print(\"Unperturbed graph list for 4x4 supercells created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# Perturb the unperturbed 3x3 graphs to create the first perturbed graph list\n",
    "graph_list_set_1 = perturb_graphs(\n",
    "    graph_list_unperturbed_1, atoms_list_unperturbed_1, perturbation_size, delta\n",
    ")\n",
    "\n",
    "# Perturb the unperturbed 4x4 graphs to create the second perturbed graph list\n",
    "graph_list_set_2 = perturb_graphs(\n",
    "    graph_list_unperturbed_2, atoms_list_unperturbed_2, perturbation_size, delta\n",
    ")\n",
    "\n",
    "print(\"Two perturbed graph lists created from 3x3 and 4x4 supercells respectively.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator: next nearest neighbour and PBC, xyz node features and edge attributes\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define the tolerance delta for nearest neighbors\n",
    "delta = 0.1  # Adjust as needed\n",
    "\n",
    "# Define the perturbation size\n",
    "perturbation_size = 0.05  # Adjust as needed\n",
    "\n",
    "# Function to compute edge_index based on positions and delta, considering PBCs\n",
    "def compute_edge_index(atoms, delta):\n",
    "    positions = atoms.get_positions()\n",
    "    num_atoms = len(positions)\n",
    "\n",
    "    # Compute distance matrix considering PBCs\n",
    "    dist_matrix = atoms.get_all_distances(mic=True)\n",
    "    edge_index = set()  # Use a set to avoid duplicate edges\n",
    "\n",
    "    # For each node, find its nearest neighbors and next-nearest neighbors\n",
    "    for i in range(num_atoms):\n",
    "        # Exclude self-distance by setting diagonal to infinity\n",
    "        dist_matrix[i, i] = np.inf\n",
    "\n",
    "        # Get distances and sort them along with indices\n",
    "        distances = dist_matrix[i]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        sorted_distances = distances[sorted_indices]\n",
    "\n",
    "        # Nearest neighbor distance\n",
    "        d1 = sorted_distances[0]\n",
    "        nn_cutoff = d1 + delta\n",
    "\n",
    "        # Indices of nearest neighbors within d1 + delta\n",
    "        nn_indices = sorted_indices[sorted_distances <= nn_cutoff]\n",
    "\n",
    "        # Add edges from nearest neighbors to i\n",
    "        for j in nn_indices:\n",
    "            edge_index.add((j, i))\n",
    "\n",
    "        # Exclude nearest neighbors from consideration for next-nearest neighbors\n",
    "        remaining_indices = sorted_indices[sorted_distances > nn_cutoff]\n",
    "        remaining_distances = sorted_distances[sorted_distances > nn_cutoff]\n",
    "\n",
    "        if len(remaining_distances) > 0:\n",
    "            # Next nearest neighbor distance\n",
    "            d2 = remaining_distances[0]\n",
    "            nnn_cutoff = d2 + delta\n",
    "\n",
    "            # Indices of next-nearest neighbors within d2 + delta\n",
    "            nnn_indices = remaining_indices[remaining_distances <= nnn_cutoff]\n",
    "\n",
    "            # Add edges from next-nearest neighbors to i\n",
    "            for j in nnn_indices:\n",
    "                edge_index.add((j, i))\n",
    "\n",
    "    # Convert edge_index to a tensor\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(list(edge_index), dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "# Function to compute edge attributes as displacement vectors considering PBCs\n",
    "def compute_edge_attr(atoms, edge_index):\n",
    "    row, col = edge_index\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "\n",
    "    # Compute displacement vectors considering PBCs\n",
    "    delta_scaled = scaled_positions[row.numpy()] - scaled_positions[col.numpy()]\n",
    "    delta_scaled -= np.round(delta_scaled)  # Apply minimum image convention\n",
    "    displacement_vectors = delta_scaled @ cell  # Convert back to Cartesian coordinates\n",
    "\n",
    "    # Create edge attributes as displacement vectors\n",
    "    edge_attr = torch.tensor(displacement_vectors, dtype=torch.float)\n",
    "    return edge_attr\n",
    "\n",
    "# Function to compute node features (relative positions within unit cells)\n",
    "def compute_node_features(atoms, SUPERCELL_SIZE):\n",
    "    num_atoms = len(atoms)\n",
    "    N = SUPERCELL_SIZE\n",
    "    total_unit_cells = N * N  # For a 2D lattice\n",
    "\n",
    "    # Compute the number of atoms per unit cell\n",
    "    atoms_per_unit_cell = num_atoms // total_unit_cells\n",
    "\n",
    "    # Check for consistency\n",
    "    if atoms_per_unit_cell * total_unit_cells != num_atoms:\n",
    "        raise ValueError(\"Number of atoms per unit cell is not consistent with total atoms and supercell dimensions.\")\n",
    "\n",
    "    # Group atoms by unit cell based on their order in the .xyz file\n",
    "    unit_cell_indices = []\n",
    "    for i in range(0, num_atoms, atoms_per_unit_cell):\n",
    "        group = list(range(i, i + atoms_per_unit_cell))\n",
    "        unit_cell_indices.append(group)\n",
    "\n",
    "    # Compute relative positions\n",
    "    positions = atoms.get_positions()\n",
    "    relative_positions = np.zeros_like(positions)\n",
    "\n",
    "    for group in unit_cell_indices:\n",
    "        indices = group\n",
    "        positions_in_cell = positions[indices]\n",
    "        reference_position = positions_in_cell[0]  # First atom in the unit cell\n",
    "        relative_positions_in_cell = positions_in_cell - reference_position\n",
    "        relative_positions[indices] = relative_positions_in_cell\n",
    "\n",
    "    # Create node features as torch tensor\n",
    "    node_features = torch.tensor(relative_positions, dtype=torch.float)\n",
    "    return node_features\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure\n",
    "def create_graph_from_structure(atoms, delta, SUPERCELL_SIZE):\n",
    "    # Compute edge_index\n",
    "    edge_index = compute_edge_index(atoms, delta)\n",
    "\n",
    "    # Compute edge attributes\n",
    "    edge_attr = compute_edge_attr(atoms, edge_index)\n",
    "\n",
    "    # Compute node features (relative positions within unit cells)\n",
    "    node_features = compute_node_features(atoms, SUPERCELL_SIZE)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "    )\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to apply perturbations to a graph list\n",
    "def perturb_graphs(graph_list, atoms_list, perturbation_size, SUPERCELL_SIZE):\n",
    "    perturbed_graph_list = []\n",
    "    for graph, atoms in zip(graph_list, atoms_list):\n",
    "        # Clone the graph to avoid modifying the original\n",
    "        perturbed_graph = graph.clone()\n",
    "\n",
    "        # Get the positions of the atoms from the atoms object\n",
    "        positions = atoms.get_positions().copy()  # Original positions\n",
    "\n",
    "        # Apply random perturbation to the positions\n",
    "        if perturbation_size > 0:\n",
    "            perturbation = np.random.uniform(-perturbation_size, perturbation_size, positions.shape)\n",
    "            positions += perturbation  # Perturb the atomic positions\n",
    "\n",
    "        # Update positions in the atoms object\n",
    "        perturbed_atoms = atoms.copy()\n",
    "        perturbed_atoms.set_positions(positions)\n",
    "        perturbed_atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Recompute edge attributes using the same edge_index\n",
    "        perturbed_edge_attr = compute_edge_attr(perturbed_atoms, perturbed_graph.edge_index)\n",
    "        perturbed_graph.edge_attr = perturbed_edge_attr\n",
    "\n",
    "        # Recompute node features based on perturbed positions\n",
    "        perturbed_node_features = compute_node_features(perturbed_atoms, SUPERCELL_SIZE)\n",
    "        perturbed_graph.x = perturbed_node_features\n",
    "\n",
    "        perturbed_graph_list.append(perturbed_graph)\n",
    "\n",
    "    return perturbed_graph_list\n",
    "\n",
    "# Path to the supercell files folder\n",
    "supercell_folder = 'supercells_flatband_rotated_shifted_3x3'\n",
    "\n",
    "# Lists to store the graph objects and the corresponding atoms\n",
    "graph_list_unperturbed = []\n",
    "atoms_list_unperturbed = []\n",
    "\n",
    "# Iterate over all XYZ files in the supercells folder\n",
    "for filename in os.listdir(supercell_folder):\n",
    "    if filename.endswith('.xyz'):\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(supercell_folder, filename)\n",
    "        atoms = read(filepath)\n",
    "        atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Extract the last number from the filename\n",
    "        match = re.findall(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match[-1])  # Get the last number\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "\n",
    "        # Create graph with PBCs\n",
    "        graph = create_graph_from_structure(atoms, delta, SUPERCELL_SIZE)\n",
    "        graph.label = label\n",
    "\n",
    "        # Append the graph and atoms to their respective lists\n",
    "        graph_list_unperturbed.append(graph)\n",
    "        atoms_list_unperturbed.append(atoms)\n",
    "\n",
    "        print(f\"Graph for {filename} created and added to the list with label {label}.\")\n",
    "\n",
    "print(\"Unperturbed graph list created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# First perturbed graph list\n",
    "graph_list_set_1 = perturb_graphs(graph_list_unperturbed, atoms_list_unperturbed, perturbation_size, SUPERCELL_SIZE)\n",
    "\n",
    "# Second perturbed graph list\n",
    "graph_list_set_2 = perturb_graphs(graph_list_unperturbed, atoms_list_unperturbed, perturbation_size, SUPERCELL_SIZE)\n",
    "\n",
    "print(\"Three graph lists created: unperturbed, perturbed set 1, and perturbed set 2 with scaling and masking applied.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator: next nearest neighbour and PBC, xyz node features, x edges\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the tolerance delta for nearest neighbors\n",
    "delta = 0.1  # Adjust as needed\n",
    "\n",
    "# Define the perturbation size\n",
    "perturbation_size = 0.05  # Adjust as needed\n",
    "\n",
    "# Function to compute edge_index based on positions and delta, considering PBCs\n",
    "def compute_edge_index(atoms, delta):\n",
    "    positions = atoms.get_positions()\n",
    "    num_atoms = len(positions)\n",
    "\n",
    "    # Compute distance matrix considering PBCs\n",
    "    dist_matrix = atoms.get_all_distances(mic=True)\n",
    "    edge_index = set()  # Use a set to avoid duplicate edges\n",
    "\n",
    "    # For each node, find its nearest neighbors and next-nearest neighbors\n",
    "    for i in range(num_atoms):\n",
    "        # Exclude self-distance by setting diagonal to infinity\n",
    "        dist_matrix[i, i] = np.inf\n",
    "\n",
    "        # Get distances and sort them along with indices\n",
    "        distances = dist_matrix[i]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        sorted_distances = distances[sorted_indices]\n",
    "\n",
    "        # Nearest neighbor distance\n",
    "        d1 = sorted_distances[0]\n",
    "        nn_cutoff = d1 + delta\n",
    "\n",
    "        # Indices of nearest neighbors within d1 + delta\n",
    "        nn_indices = sorted_indices[sorted_distances <= nn_cutoff]\n",
    "\n",
    "        # Add edges from nearest neighbors to i\n",
    "        for j in nn_indices:\n",
    "            edge_index.add((j, i))\n",
    "\n",
    "        # Exclude nearest neighbors from consideration for next-nearest neighbors\n",
    "        remaining_indices = sorted_indices[sorted_distances > nn_cutoff]\n",
    "        remaining_distances = sorted_distances[sorted_distances > nn_cutoff]\n",
    "\n",
    "        if len(remaining_distances) > 0:\n",
    "            # Next nearest neighbor distance\n",
    "            d2 = remaining_distances[0]\n",
    "            nnn_cutoff = d2 + delta\n",
    "\n",
    "            # Indices of next-nearest neighbors within d2 + delta\n",
    "            nnn_indices = remaining_indices[remaining_distances <= nnn_cutoff]\n",
    "\n",
    "            # Add edges from next-nearest neighbors to i\n",
    "            for j in nnn_indices:\n",
    "                edge_index.add((j, i))\n",
    "\n",
    "    # Convert edge_index to a tensor\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(list(edge_index), dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "# Function to compute edge attributes based on positions and edge_index, considering PBCs\n",
    "def compute_edge_attr(atoms, edge_index):\n",
    "    row, col = edge_index\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "    # Compute displacement vectors considering PBCs\n",
    "    delta_scaled = scaled_positions[row.numpy()] - scaled_positions[col.numpy()]\n",
    "    delta_scaled -= np.round(delta_scaled)\n",
    "    displacement_vectors = delta_scaled @ cell\n",
    "    edge_distances = np.linalg.norm(displacement_vectors, axis=1)\n",
    "    edge_attr = torch.tensor(edge_distances, dtype=torch.float).unsqueeze(1)\n",
    "    return edge_attr\n",
    "\n",
    "# Function to compute node features (relative positions within unit cells)\n",
    "def compute_node_features(atoms, SUPERCELL_SIZE):\n",
    "    num_atoms = len(atoms)\n",
    "    N = SUPERCELL_SIZE\n",
    "    total_unit_cells = N * N  # For a 2D lattice\n",
    "\n",
    "    # Compute the number of atoms per unit cell\n",
    "    atoms_per_unit_cell = num_atoms // total_unit_cells\n",
    "\n",
    "    # Check for consistency\n",
    "    if atoms_per_unit_cell * total_unit_cells != num_atoms:\n",
    "        raise ValueError(\"Number of atoms per unit cell is not consistent with total atoms and supercell dimensions.\")\n",
    "\n",
    "    # Group atoms by unit cell based on their order in the .xyz file\n",
    "    unit_cell_indices = []\n",
    "    for i in range(0, num_atoms, atoms_per_unit_cell):\n",
    "        group = list(range(i, i + atoms_per_unit_cell))\n",
    "        unit_cell_indices.append(group)\n",
    "\n",
    "    # Compute relative positions\n",
    "    positions = atoms.get_positions()\n",
    "    relative_positions = np.zeros_like(positions)\n",
    "\n",
    "    for group in unit_cell_indices:\n",
    "        indices = group\n",
    "        positions_in_cell = positions[indices]\n",
    "        reference_position = positions_in_cell[0]  # First atom in the unit cell\n",
    "        relative_positions_in_cell = positions_in_cell - reference_position\n",
    "        relative_positions[indices] = relative_positions_in_cell\n",
    "\n",
    "    # Create node features as torch tensor\n",
    "    node_features = torch.tensor(relative_positions, dtype=torch.float)\n",
    "    return node_features\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure\n",
    "def create_graph_from_structure(atoms, delta, SUPERCELL_SIZE):\n",
    "    # Compute edge_index\n",
    "    edge_index = compute_edge_index(atoms, delta)\n",
    "\n",
    "    # Compute edge attributes\n",
    "    edge_attr = compute_edge_attr(atoms, edge_index)\n",
    "\n",
    "    # Compute node features (relative positions within unit cells)\n",
    "    node_features = compute_node_features(atoms, SUPERCELL_SIZE)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "    )\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to apply perturbations to a graph list\n",
    "def perturb_graphs(graph_list, atoms_list, perturbation_size, delta, SUPERCELL_SIZE):\n",
    "    perturbed_graph_list = []\n",
    "    for graph, atoms in zip(graph_list, atoms_list):\n",
    "        # Clone the graph to avoid modifying the original\n",
    "        perturbed_graph = graph.clone()\n",
    "\n",
    "        # Get the positions of the atoms from the atoms object\n",
    "        positions = atoms.get_positions().copy()  # Original positions\n",
    "\n",
    "        # Apply random perturbation to the positions\n",
    "        if perturbation_size > 0:\n",
    "            perturbation = np.random.uniform(-perturbation_size, perturbation_size, positions.shape)\n",
    "            positions += perturbation  # Perturb the atomic positions\n",
    "\n",
    "        # Update edge attributes based on perturbed positions\n",
    "        # Since edge_index remains the same, we recompute edge_attr\n",
    "        perturbed_atoms = atoms.copy()\n",
    "        perturbed_atoms.set_positions(positions)\n",
    "        perturbed_atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Recompute edge attributes\n",
    "        perturbed_edge_attr = compute_edge_attr(perturbed_atoms, graph.edge_index)\n",
    "        perturbed_graph.edge_attr = perturbed_edge_attr\n",
    "\n",
    "        # Recompute node features based on perturbed positions\n",
    "        perturbed_node_features = compute_node_features(perturbed_atoms, SUPERCELL_SIZE)\n",
    "        perturbed_graph.x = perturbed_node_features\n",
    "\n",
    "        perturbed_graph_list.append(perturbed_graph)\n",
    "\n",
    "    return perturbed_graph_list\n",
    "\n",
    "# Path to the supercell files folder\n",
    "supercell_folder = 'supercells_flatband'\n",
    "\n",
    "# Lists to store the graph objects and the corresponding atoms\n",
    "graph_list_unperturbed = []\n",
    "atoms_list_unperturbed = []\n",
    "\n",
    "# Iterate over all XYZ files in the supercells folder\n",
    "for filename in os.listdir(supercell_folder):\n",
    "    if filename.endswith('.xyz'):\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(supercell_folder, filename)\n",
    "        atoms = read(filepath)\n",
    "        atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Extract the last number from the filename\n",
    "        match = re.findall(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match[-1])  # Get the last number\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "\n",
    "        # Create graph with PBCs\n",
    "        graph = create_graph_from_structure(atoms, delta, SUPERCELL_SIZE)\n",
    "        graph.label = label\n",
    "\n",
    "        # Append the graph and atoms to their respective lists\n",
    "        graph_list_unperturbed.append(graph)\n",
    "        atoms_list_unperturbed.append(atoms)\n",
    "\n",
    "        print(f\"Graph for {filename} created and added to the list with label {label}.\")\n",
    "\n",
    "print(\"Unperturbed graph list created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# First perturbed graph list\n",
    "graph_list_set_1 = perturb_graphs(graph_list_unperturbed, atoms_list_unperturbed, perturbation_size, delta, SUPERCELL_SIZE)\n",
    "\n",
    "# Second perturbed graph list\n",
    "graph_list_set_2 = perturb_graphs(graph_list_unperturbed, atoms_list_unperturbed, perturbation_size, delta, SUPERCELL_SIZE)\n",
    "\n",
    "print(\"Three graph lists created: unperturbed, perturbed set 1, and perturbed set 2 with scaling and masking applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator: next nearest neighbour and PBC, 0 node features, xyz edge attributes\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the tolerance delta for nearest neighbors\n",
    "delta = 0.1  # Adjust as needed\n",
    "\n",
    "# Define the perturbation size\n",
    "perturbation_size = 0.05  # Adjust as needed\n",
    "\n",
    "# Function to compute edge_index based on positions and delta, considering PBCs\n",
    "def compute_edge_index(atoms, delta):\n",
    "    positions = atoms.get_positions()\n",
    "    num_atoms = len(positions)\n",
    "\n",
    "    # Compute distance matrix considering PBCs\n",
    "    dist_matrix = atoms.get_all_distances(mic=True)\n",
    "    edge_index = set()  # Use a set to avoid duplicate edges\n",
    "\n",
    "    # For each node, find its nearest neighbors and next-nearest neighbors\n",
    "    for i in range(num_atoms):\n",
    "        # Exclude self-distance by setting diagonal to infinity\n",
    "        dist_matrix[i, i] = np.inf\n",
    "\n",
    "        # Get distances and sort them along with indices\n",
    "        distances = dist_matrix[i]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        sorted_distances = distances[sorted_indices]\n",
    "\n",
    "        # Nearest neighbor distance\n",
    "        d1 = sorted_distances[0]\n",
    "        nn_cutoff = d1 + delta\n",
    "\n",
    "        # Indices of nearest neighbors within d1 + delta\n",
    "        nn_indices = sorted_indices[sorted_distances <= nn_cutoff]\n",
    "\n",
    "        # Add edges from nearest neighbors to i\n",
    "        for j in nn_indices:\n",
    "            edge_index.add((j, i))\n",
    "\n",
    "        # Exclude nearest neighbors from consideration for next-nearest neighbors\n",
    "        remaining_indices = sorted_indices[sorted_distances > nn_cutoff]\n",
    "        remaining_distances = sorted_distances[sorted_distances > nn_cutoff]\n",
    "\n",
    "        if len(remaining_distances) > 0:\n",
    "            # Next nearest neighbor distance\n",
    "            d2 = remaining_distances[0]\n",
    "            nnn_cutoff = d2 + delta\n",
    "\n",
    "            # Indices of next-nearest neighbors within d2 + delta\n",
    "            nnn_indices = remaining_indices[remaining_distances <= nnn_cutoff]\n",
    "\n",
    "            # Add edges from next-nearest neighbors to i\n",
    "            for j in nnn_indices:\n",
    "                edge_index.add((j, i))\n",
    "\n",
    "    # Convert edge_index to a tensor\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(list(edge_index), dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "# Function to compute edge attributes as displacement vectors considering PBCs\n",
    "def compute_edge_attr(atoms, edge_index):\n",
    "    row, col = edge_index\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "\n",
    "    # Compute displacement vectors considering PBCs\n",
    "    delta_scaled = scaled_positions[row.numpy()] - scaled_positions[col.numpy()]\n",
    "    delta_scaled -= np.round(delta_scaled)  # Apply minimum image convention\n",
    "    displacement_vectors = delta_scaled @ cell  # Convert back to Cartesian coordinates\n",
    "\n",
    "    # Create edge attributes as displacement vectors\n",
    "    edge_attr = torch.tensor(displacement_vectors, dtype=torch.float)\n",
    "    return edge_attr\n",
    "\n",
    "def compute_node_features(atoms, SUPERCELL_SIZE):\n",
    "    num_atoms = len(atoms)\n",
    "    # Create node features as a tensor of ones\n",
    "    node_features = torch.ones((num_atoms, 1), dtype=torch.float)\n",
    "    return node_features\n",
    "\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure\n",
    "def create_graph_from_structure(atoms, delta, SUPERCELL_SIZE):\n",
    "    # Compute edge_index\n",
    "    edge_index = compute_edge_index(atoms, delta)\n",
    "\n",
    "    # Compute edge attributes\n",
    "    edge_attr = compute_edge_attr(atoms, edge_index)\n",
    "\n",
    "    # Compute node features (relative positions within unit cells)\n",
    "    node_features = compute_node_features(atoms, SUPERCELL_SIZE)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "    )\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to apply perturbations to a graph list\n",
    "def perturb_graphs(graph_list, atoms_list, perturbation_size, delta, SUPERCELL_SIZE):\n",
    "    perturbed_graph_list = []\n",
    "    for graph, atoms in zip(graph_list, atoms_list):\n",
    "        # Clone the graph to avoid modifying the original\n",
    "        perturbed_graph = graph.clone()\n",
    "\n",
    "        # Get the positions of the atoms from the atoms object\n",
    "        positions = atoms.get_positions().copy()  # Original positions\n",
    "\n",
    "        # Apply random perturbation to the positions\n",
    "        if perturbation_size > 0:\n",
    "            perturbation = np.random.uniform(-perturbation_size, perturbation_size, positions.shape)\n",
    "            positions += perturbation  # Perturb the atomic positions\n",
    "\n",
    "        # Update edge attributes based on perturbed positions\n",
    "        # Since edge_index remains the same, we recompute edge_attr\n",
    "        perturbed_atoms = atoms.copy()\n",
    "        perturbed_atoms.set_positions(positions)\n",
    "        perturbed_atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Recompute edge attributes\n",
    "        perturbed_edge_attr = compute_edge_attr(perturbed_atoms, graph.edge_index)\n",
    "        perturbed_graph.edge_attr = perturbed_edge_attr\n",
    "\n",
    "        # Recompute node features based on perturbed positions\n",
    "        perturbed_node_features = compute_node_features(perturbed_atoms, SUPERCELL_SIZE)\n",
    "        perturbed_graph.x = perturbed_node_features\n",
    "\n",
    "        perturbed_graph_list.append(perturbed_graph)\n",
    "\n",
    "    return perturbed_graph_list\n",
    "\n",
    "# Path to the supercell files folder\n",
    "supercell_folder = 'supercells_flatband'\n",
    "\n",
    "# Lists to store the graph objects and the corresponding atoms\n",
    "graph_list_unperturbed = []\n",
    "atoms_list_unperturbed = []\n",
    "\n",
    "# Iterate over all XYZ files in the supercells folder\n",
    "for filename in os.listdir(supercell_folder):\n",
    "    if filename.endswith('.xyz'):\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(supercell_folder, filename)\n",
    "        atoms = read(filepath)\n",
    "        atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Extract the last number from the filename\n",
    "        match = re.findall(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match[-1])  # Get the last number\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "\n",
    "        # Create graph with PBCs\n",
    "        graph = create_graph_from_structure(atoms, delta, SUPERCELL_SIZE)\n",
    "        graph.label = label\n",
    "\n",
    "        # Append the graph and atoms to their respective lists\n",
    "        graph_list_unperturbed.append(graph)\n",
    "        atoms_list_unperturbed.append(atoms)\n",
    "\n",
    "        print(f\"Graph for {filename} created and added to the list with label {label}.\")\n",
    "\n",
    "print(\"Unperturbed graph list created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# First perturbed graph list\n",
    "graph_list_set_1 = perturb_graphs(graph_list_unperturbed, atoms_list_unperturbed, perturbation_size, delta, SUPERCELL_SIZE)\n",
    "\n",
    "# Second perturbed graph list\n",
    "graph_list_set_2 = perturb_graphs(graph_list_unperturbed, atoms_list_unperturbed, perturbation_size, delta, SUPERCELL_SIZE)\n",
    "\n",
    "print(\"Three graph lists created: unperturbed, perturbed set 1, and perturbed set 2 with scaling and masking applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator: next nearest neighbour and PBC, no atomic number ,perturbation after edge connection, masking and scaling applied\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from ase.geometry import find_mic\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the tolerance delta for nearest neighbors\n",
    "delta = 0.1  # Adjust as needed\n",
    "\n",
    "# Create two perturbed graph lists by applying perturbations to the unperturbed graph list\n",
    "perturbation_size = 0.05  # Adjust as needed\n",
    "\n",
    "# Function to compute edge_index based on positions and delta, considering PBCs\n",
    "def compute_edge_index(atoms, delta):\n",
    "    positions = atoms.get_positions()\n",
    "    num_atoms = len(positions)\n",
    "    cell = atoms.get_cell()\n",
    "    pbc = atoms.get_pbc()\n",
    "\n",
    "    # Compute distance matrix considering PBCs\n",
    "    dist_matrix = atoms.get_all_distances(mic=True)\n",
    "    edge_index = set()  # Use a set to avoid duplicate edges\n",
    "\n",
    "    # For each node, find its nearest neighbors and next-nearest neighbors\n",
    "    for i in range(num_atoms):\n",
    "        # Exclude self-distance by setting diagonal to infinity\n",
    "        dist_matrix[i, i] = np.inf\n",
    "\n",
    "        # Get distances and sort them along with indices\n",
    "        distances = dist_matrix[i]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        sorted_distances = distances[sorted_indices]\n",
    "\n",
    "        # Nearest neighbor distance\n",
    "        d1 = sorted_distances[0]\n",
    "        nn_cutoff = d1 + delta\n",
    "\n",
    "        # Indices of nearest neighbors within d1 + delta\n",
    "        nn_indices = sorted_indices[sorted_distances <= nn_cutoff]\n",
    "\n",
    "        # Add edges from nearest neighbors to i\n",
    "        for j in nn_indices:\n",
    "            edge_index.add((j, i))\n",
    "\n",
    "        # Exclude nearest neighbors from consideration for next-nearest neighbors\n",
    "        remaining_indices = sorted_indices[sorted_distances > nn_cutoff]\n",
    "        remaining_distances = sorted_distances[sorted_distances > nn_cutoff]\n",
    "\n",
    "        if len(remaining_distances) > 0:\n",
    "            # Next nearest neighbor distance\n",
    "            d2 = remaining_distances[0]\n",
    "            nnn_cutoff = d2 + delta\n",
    "\n",
    "            # Indices of next-nearest neighbors within d2 + delta\n",
    "            nnn_indices = remaining_indices[remaining_distances <= nnn_cutoff]\n",
    "\n",
    "            # Add edges from next-nearest neighbors to i\n",
    "            for j in nnn_indices:\n",
    "                edge_index.add((j, i))\n",
    "\n",
    "    # Convert edge_index to a tensor\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(list(edge_index), dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "# Function to compute edge attributes based on positions and edge_index, considering PBCs\n",
    "def compute_edge_attr(atoms, edge_index):\n",
    "    row, col = edge_index\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "    # Compute displacement vectors considering PBCs\n",
    "    delta_scaled = scaled_positions[row.numpy()] - scaled_positions[col.numpy()]\n",
    "    delta_scaled -= np.round(delta_scaled)\n",
    "    displacement_vectors = delta_scaled @ cell\n",
    "    edge_distances = np.linalg.norm(displacement_vectors, axis=1)\n",
    "    edge_attr = torch.tensor(edge_distances, dtype=torch.float).unsqueeze(1)\n",
    "    return edge_attr\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure\n",
    "def create_graph_from_structure(atoms, delta):\n",
    "    # Compute edge_index\n",
    "    edge_index = compute_edge_index(atoms, delta)\n",
    "\n",
    "    # Compute edge attributes\n",
    "    edge_attr = compute_edge_attr(atoms, edge_index)\n",
    "\n",
    "    # Create dummy node features (ones)\n",
    "    num_nodes = len(atoms)\n",
    "    node_features = torch.ones((num_nodes, 1), dtype=torch.float)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "    )\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to apply perturbations to a graph list\n",
    "def perturb_graphs(graph_list, atoms_list, perturbation_size):\n",
    "    perturbed_graph_list = []\n",
    "    for graph, atoms in zip(graph_list, atoms_list):\n",
    "        # Clone the graph to avoid modifying the original\n",
    "        perturbed_graph = graph.clone()\n",
    "\n",
    "        # Get the positions of the atoms from the atoms object\n",
    "        positions = atoms.get_positions().copy()  # Original positions\n",
    "\n",
    "        # Apply random perturbation to the positions\n",
    "        if perturbation_size > 0:\n",
    "            perturbation = np.random.uniform(-perturbation_size, perturbation_size, positions.shape)\n",
    "            positions += perturbation  # Perturb the atomic positions\n",
    "\n",
    "        # Update edge attributes based on perturbed positions\n",
    "        # Since edge_index remains the same, we recompute edge_attr\n",
    "        perturbed_atoms = atoms.copy()\n",
    "        perturbed_atoms.set_positions(positions)\n",
    "        perturbed_atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        perturbed_edge_attr = compute_edge_attr(perturbed_atoms, graph.edge_index)\n",
    "        perturbed_graph.edge_attr = perturbed_edge_attr\n",
    "\n",
    "        perturbed_graph_list.append(perturbed_graph)\n",
    "\n",
    "    return perturbed_graph_list\n",
    "\n",
    "# Function to scale node features and edge attributes in each graph list\n",
    "def scale_graphs(graph_list):\n",
    "    # Collect all node features and edge attributes from the graphs\n",
    "    all_node_features = []\n",
    "    all_edge_attributes = []\n",
    "\n",
    "    for graph in graph_list:\n",
    "        all_node_features.append(graph.x)\n",
    "        # Only append edge attributes if they are not empty\n",
    "        if graph.edge_attr is not None and graph.edge_attr.shape[0] > 0:\n",
    "            all_edge_attributes.append(graph.edge_attr)\n",
    "\n",
    "    # Stack all node features\n",
    "    all_node_features_stacked = torch.cat(all_node_features, dim=0).numpy()\n",
    "\n",
    "    # Initialize StandardScalers\n",
    "    node_scaler = StandardScaler()\n",
    "    node_scaler.fit(all_node_features_stacked)\n",
    "\n",
    "    # Fit edge scaler only if there are edge attributes\n",
    "    if len(all_edge_attributes) > 0:\n",
    "        all_edge_attributes_stacked = torch.cat(all_edge_attributes, dim=0).numpy()\n",
    "        edge_scaler = StandardScaler()\n",
    "        edge_scaler.fit(all_edge_attributes_stacked)\n",
    "    else:\n",
    "        edge_scaler = None  # No edges to scale\n",
    "\n",
    "    # Apply the scaling to each graph\n",
    "    for graph in graph_list:\n",
    "        # Scale node features\n",
    "        graph_node_features = graph.x.numpy()\n",
    "        graph_node_features_scaled = node_scaler.transform(graph_node_features)\n",
    "        graph.x = torch.tensor(graph_node_features_scaled, dtype=torch.float)\n",
    "\n",
    "        # Scale edge attributes if they exist\n",
    "        if graph.edge_attr is not None and graph.edge_attr.shape[0] > 0 and edge_scaler is not None:\n",
    "            graph_edge_attributes = graph.edge_attr.numpy()\n",
    "            graph_edge_attributes_scaled = edge_scaler.transform(graph_edge_attributes)\n",
    "            graph.edge_attr = torch.tensor(graph_edge_attributes_scaled, dtype=torch.float)\n",
    "        else:\n",
    "            # If there are no edges, ensure edge_attr is a tensor of appropriate shape\n",
    "            graph.edge_attr = torch.tensor([], dtype=torch.float).reshape(0, 1)\n",
    "\n",
    "# Function to mask a percentage of node features and edge attributes in each graph\n",
    "def mask_graphs(graph_list, masking_percentage=MASKING_PERCENTAGE):\n",
    "    for graph in graph_list:\n",
    "        # Mask a percentage of node features\n",
    "        num_nodes = graph.x.shape[0]\n",
    "        num_node_mask = max(1, int(np.ceil(masking_percentage * num_nodes))) if num_nodes > 0 else 0\n",
    "        if num_node_mask > 0:\n",
    "            node_mask_indices = np.random.choice(num_nodes, num_node_mask, replace=False)\n",
    "            graph.x[node_mask_indices] = 0  # Zero out the node features for the selected nodes\n",
    "\n",
    "        # Mask a percentage of edge attributes\n",
    "        num_edges = graph.edge_attr.shape[0]\n",
    "        num_edge_mask = max(1, int(np.ceil(masking_percentage * num_edges))) if num_edges > 0 else 0\n",
    "        if num_edge_mask > 0:\n",
    "            edge_mask_indices = np.random.choice(num_edges, num_edge_mask, replace=False)\n",
    "            graph.edge_attr[edge_mask_indices] = 0  # Zero out the edge attributes for the selected edges\n",
    "\n",
    "# Path to the supercell files folder\n",
    "supercell_folder = 'supercells_flatband'\n",
    "\n",
    "# Lists to store the graph objects and the corresponding atoms\n",
    "graph_list_unperturbed = []\n",
    "atoms_list_unperturbed = []\n",
    "\n",
    "# Iterate over all XYZ files in the supercells folder\n",
    "for filename in os.listdir(supercell_folder):\n",
    "    if filename.endswith('.xyz'):\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(supercell_folder, filename)\n",
    "        atoms = read(filepath)\n",
    "        atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Extract the last number from the filename\n",
    "        match = re.findall(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match[-1])  # Get the last number\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "\n",
    "\n",
    "        # Create graph with PBCs\n",
    "        graph = create_graph_from_structure(atoms, delta)\n",
    "        graph.label = label\n",
    "\n",
    "        # Append the graph and atoms to their respective lists\n",
    "        graph_list_unperturbed.append(graph)\n",
    "        atoms_list_unperturbed.append(atoms)\n",
    "\n",
    "        print(f\"Graph for {filename} created and added to the list with label {label}.\")\n",
    "\n",
    "print(\"Unperturbed graph list created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# First perturbed graph list\n",
    "graph_list_set_1 = perturb_graphs(graph_list_unperturbed, atoms_list_unperturbed, perturbation_size)\n",
    "\n",
    "# Second perturbed graph list\n",
    "graph_list_set_2 = perturb_graphs(graph_list_unperturbed, atoms_list_unperturbed, perturbation_size)\n",
    "\n",
    "# Apply scaling to each graph list\n",
    "scale_graphs(graph_list_unperturbed)\n",
    "scale_graphs(graph_list_set_1)\n",
    "scale_graphs(graph_list_set_2)\n",
    "\n",
    "# Apply masking to the perturbed graph lists\n",
    "mask_graphs(graph_list_set_1)\n",
    "mask_graphs(graph_list_set_2)\n",
    "\n",
    "print(\"Three graph lists created: unperturbed, perturbed set 1, and perturbed set 2 with scaling and masking applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator: next nearest neighbour and PBC, perturbation after edge connection, masking and scaling applied\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from ase.geometry import find_mic\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the tolerance delta for nearest neighbors\n",
    "delta = 0.1  # Adjust as needed\n",
    "\n",
    "# Create two perturbed graph lists by applying perturbations to the unperturbed graph list\n",
    "perturbation_size = 0.05  # Adjust as needed\n",
    "\n",
    "# Function to compute edge_index based on positions and delta, considering PBCs\n",
    "def compute_edge_index(atoms, delta):\n",
    "    positions = atoms.get_positions()\n",
    "    num_atoms = len(positions)\n",
    "    cell = atoms.get_cell()\n",
    "    pbc = atoms.get_pbc()\n",
    "\n",
    "    # Compute distance matrix considering PBCs\n",
    "    dist_matrix = atoms.get_all_distances(mic=True)\n",
    "    edge_index = set()  # Use a set to avoid duplicate edges\n",
    "\n",
    "    # For each node, find its nearest neighbors and next-nearest neighbors\n",
    "    for i in range(num_atoms):\n",
    "        # Exclude self-distance by setting diagonal to infinity\n",
    "        dist_matrix[i, i] = np.inf\n",
    "\n",
    "        # Get distances and sort them along with indices\n",
    "        distances = dist_matrix[i]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        sorted_distances = distances[sorted_indices]\n",
    "\n",
    "        # Nearest neighbor distance\n",
    "        d1 = sorted_distances[0]\n",
    "        nn_cutoff = d1 + delta\n",
    "\n",
    "        # Indices of nearest neighbors within d1 + delta\n",
    "        nn_indices = sorted_indices[sorted_distances <= nn_cutoff]\n",
    "\n",
    "        # Add edges from nearest neighbors to i\n",
    "        for j in nn_indices:\n",
    "            edge_index.add((j, i))\n",
    "\n",
    "        # Exclude nearest neighbors from consideration for next-nearest neighbors\n",
    "        remaining_indices = sorted_indices[sorted_distances > nn_cutoff]\n",
    "        remaining_distances = sorted_distances[sorted_distances > nn_cutoff]\n",
    "\n",
    "        if len(remaining_distances) > 0:\n",
    "            # Next nearest neighbor distance\n",
    "            d2 = remaining_distances[0]\n",
    "            nnn_cutoff = d2 + delta\n",
    "\n",
    "            # Indices of next-nearest neighbors within d2 + delta\n",
    "            nnn_indices = remaining_indices[remaining_distances <= nnn_cutoff]\n",
    "\n",
    "            # Add edges from next-nearest neighbors to i\n",
    "            for j in nnn_indices:\n",
    "                edge_index.add((j, i))\n",
    "\n",
    "    # Convert edge_index to a tensor\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(list(edge_index), dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "# Function to compute edge attributes based on positions and edge_index, considering PBCs\n",
    "def compute_edge_attr(atoms, edge_index):\n",
    "    row, col = edge_index\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "    # Compute displacement vectors considering PBCs\n",
    "    delta_scaled = scaled_positions[row.numpy()] - scaled_positions[col.numpy()]\n",
    "    delta_scaled -= np.round(delta_scaled)\n",
    "    displacement_vectors = delta_scaled @ cell\n",
    "    edge_distances = np.linalg.norm(displacement_vectors, axis=1)\n",
    "    edge_attr = torch.tensor(edge_distances, dtype=torch.float).unsqueeze(1)\n",
    "    return edge_attr\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure\n",
    "def create_graph_from_structure(atoms, delta):\n",
    "    # Compute edge_index\n",
    "    edge_index = compute_edge_index(atoms, delta)\n",
    "\n",
    "    # Compute edge attributes\n",
    "    edge_attr = compute_edge_attr(atoms, edge_index)\n",
    "\n",
    "    # Create node features: atomic number\n",
    "    node_features = torch.tensor(\n",
    "        [[atom.number] for atom in atoms], dtype=torch.float\n",
    "    )\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "    )\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to apply perturbations to a graph list\n",
    "def perturb_graphs(graph_list, atoms_list, perturbation_size):\n",
    "    perturbed_graph_list = []\n",
    "    for graph, atoms in zip(graph_list, atoms_list):\n",
    "        # Clone the graph to avoid modifying the original\n",
    "        perturbed_graph = graph.clone()\n",
    "\n",
    "        # Get the positions of the atoms from the atoms object\n",
    "        positions = atoms.get_positions().copy()  # Original positions\n",
    "\n",
    "        # Apply random perturbation to the positions\n",
    "        if perturbation_size > 0:\n",
    "            perturbation = np.random.uniform(-perturbation_size, perturbation_size, positions.shape)\n",
    "            positions += perturbation  # Perturb the atomic positions\n",
    "\n",
    "        # Update edge attributes based on perturbed positions\n",
    "        # Since edge_index remains the same, we recompute edge_attr\n",
    "        perturbed_atoms = atoms.copy()\n",
    "        perturbed_atoms.set_positions(positions)\n",
    "        perturbed_atoms.pbc = True  # Ensure PBCs are enabled\n",
    "\n",
    "        perturbed_edge_attr = compute_edge_attr(perturbed_atoms, graph.edge_index)\n",
    "        perturbed_graph.edge_attr = perturbed_edge_attr\n",
    "\n",
    "        perturbed_graph_list.append(perturbed_graph)\n",
    "\n",
    "    return perturbed_graph_list\n",
    "\n",
    "# Function to scale node features and edge attributes in each graph list\n",
    "def scale_graphs(graph_list):\n",
    "    # Collect all node features and edge attributes from the graphs\n",
    "    all_node_features = []\n",
    "    all_edge_attributes = []\n",
    "\n",
    "    for graph in graph_list:\n",
    "        all_node_features.append(graph.x)\n",
    "        # Only append edge attributes if they are not empty\n",
    "        if graph.edge_attr is not None and graph.edge_attr.shape[0] > 0:\n",
    "            all_edge_attributes.append(graph.edge_attr)\n",
    "\n",
    "    # Stack all node features\n",
    "    all_node_features_stacked = torch.cat(all_node_features, dim=0).numpy()\n",
    "\n",
    "    # Initialize StandardScalers\n",
    "    node_scaler = StandardScaler()\n",
    "    node_scaler.fit(all_node_features_stacked)\n",
    "\n",
    "    # Fit edge scaler only if there are edge attributes\n",
    "    if len(all_edge_attributes) > 0:\n",
    "        all_edge_attributes_stacked = torch.cat(all_edge_attributes, dim=0).numpy()\n",
    "        edge_scaler = StandardScaler()\n",
    "        edge_scaler.fit(all_edge_attributes_stacked)\n",
    "    else:\n",
    "        edge_scaler = None  # No edges to scale\n",
    "\n",
    "    # Apply the scaling to each graph\n",
    "    for graph in graph_list:\n",
    "        # Scale node features\n",
    "        graph_node_features = graph.x.numpy()\n",
    "        graph_node_features_scaled = node_scaler.transform(graph_node_features)\n",
    "        graph.x = torch.tensor(graph_node_features_scaled, dtype=torch.float)\n",
    "\n",
    "        # Scale edge attributes if they exist\n",
    "        if graph.edge_attr is not None and graph.edge_attr.shape[0] > 0 and edge_scaler is not None:\n",
    "            graph_edge_attributes = graph.edge_attr.numpy()\n",
    "            graph_edge_attributes_scaled = edge_scaler.transform(graph_edge_attributes)\n",
    "            graph.edge_attr = torch.tensor(graph_edge_attributes_scaled, dtype=torch.float)\n",
    "        else:\n",
    "            # If there are no edges, ensure edge_attr is a tensor of appropriate shape\n",
    "            graph.edge_attr = torch.tensor([], dtype=torch.float).reshape(0, 1)\n",
    "\n",
    "# Function to mask a percentage of node features and edge attributes in each graph\n",
    "def mask_graphs(graph_list, masking_percentage=0.15):\n",
    "    for graph in graph_list:\n",
    "        # Mask a percentage of node features\n",
    "        num_nodes = graph.x.shape[0]\n",
    "        num_node_mask = max(1, int(np.ceil(masking_percentage * num_nodes))) if num_nodes > 0 else 0\n",
    "        if num_node_mask > 0:\n",
    "            node_mask_indices = np.random.choice(num_nodes, num_node_mask, replace=False)\n",
    "            graph.x[node_mask_indices] = 0  # Zero out the node features for the selected nodes\n",
    "\n",
    "        # Mask a percentage of edge attributes\n",
    "        num_edges = graph.edge_attr.shape[0]\n",
    "        num_edge_mask = max(1, int(np.ceil(masking_percentage * num_edges))) if num_edges > 0 else 0\n",
    "        if num_edge_mask > 0:\n",
    "            edge_mask_indices = np.random.choice(num_edges, num_edge_mask, replace=False)\n",
    "            graph.edge_attr[edge_mask_indices] = 0  # Zero out the edge attributes for the selected edges\n",
    "\n",
    "# Path to the supercell files folder\n",
    "supercell_folder = 'supercells'\n",
    "\n",
    "# Lists to store the graph objects and the corresponding atoms\n",
    "graph_list_unperturbed = []\n",
    "atoms_list_unperturbed = []\n",
    "\n",
    "# Iterate over all XYZ files in the supercells folder\n",
    "for filename in os.listdir(supercell_folder):\n",
    "    if filename.endswith('.xyz'):\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(supercell_folder, filename)\n",
    "        atoms = read(filepath)\n",
    "        atoms.pbc = True  # Ensure PBCs are enabled\n",
    "\n",
    "        # Extract the number from the filename\n",
    "        match = re.search(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match.group())\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "\n",
    "        # Create graph with PBCs\n",
    "        graph = create_graph_from_structure(atoms, delta)\n",
    "        graph.label = label\n",
    "\n",
    "        # Append the graph and atoms to their respective lists\n",
    "        graph_list_unperturbed.append(graph)\n",
    "        atoms_list_unperturbed.append(atoms)\n",
    "\n",
    "        print(f\"Graph for {filename} created and added to the list with label {label}.\")\n",
    "\n",
    "print(\"Unperturbed graph list created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# First perturbed graph list\n",
    "graph_list_set_1 = perturb_graphs(graph_list_unperturbed, atoms_list_unperturbed, perturbation_size)\n",
    "\n",
    "# Second perturbed graph list\n",
    "graph_list_set_2 = perturb_graphs(graph_list_unperturbed, atoms_list_unperturbed, perturbation_size)\n",
    "\n",
    "# Apply scaling to each graph list\n",
    "scale_graphs(graph_list_unperturbed)\n",
    "scale_graphs(graph_list_set_1)\n",
    "scale_graphs(graph_list_set_2)\n",
    "\n",
    "# Apply masking to the perturbed graph lists\n",
    "mask_graphs(graph_list_set_1)\n",
    "mask_graphs(graph_list_set_2)\n",
    "\n",
    "print(\"Three graph lists created: unperturbed, perturbed set 1, and perturbed set 2 with scaling and masking applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator:  next nearest neighbour, perturbation after edge connection, masking and scaling applies\n",
    "\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from scipy.spatial import distance_matrix\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the tolerance delta for nearest neighbors\n",
    "delta = 0.1  # Adjust as needed\n",
    "\n",
    "# Function to compute edge_index based on positions and delta\n",
    "def compute_edge_index(positions, delta):\n",
    "    # Calculate the distance matrix between all atoms\n",
    "    dist_matrix = distance_matrix(positions, positions)\n",
    "    num_atoms = len(positions)\n",
    "    edge_index = set()  # Use a set to avoid duplicate edges\n",
    "\n",
    "    # For each node, find its nearest neighbors and next-nearest neighbors\n",
    "    for i in range(num_atoms):\n",
    "        # Exclude self-distance by setting diagonal to infinity\n",
    "        dist_matrix[i, i] = np.inf\n",
    "\n",
    "        # Get distances and sort them along with indices\n",
    "        distances = dist_matrix[i]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        sorted_distances = distances[sorted_indices]\n",
    "\n",
    "        # Nearest neighbor distance\n",
    "        d1 = sorted_distances[0]\n",
    "        nn_cutoff = d1 + delta\n",
    "\n",
    "        # Indices of nearest neighbors within d1 + delta\n",
    "        nn_indices = sorted_indices[sorted_distances <= nn_cutoff]\n",
    "\n",
    "        # Add edges from nearest neighbors to i\n",
    "        for j in nn_indices:\n",
    "            edge_index.add((j, i))\n",
    "\n",
    "        # Exclude nearest neighbors from consideration for next-nearest neighbors\n",
    "        remaining_indices = sorted_indices[sorted_distances > nn_cutoff]\n",
    "        remaining_distances = sorted_distances[sorted_distances > nn_cutoff]\n",
    "\n",
    "        if len(remaining_distances) > 0:\n",
    "            # Next nearest neighbor distance\n",
    "            d2 = remaining_distances[0]\n",
    "            nnn_cutoff = d2 + delta\n",
    "\n",
    "            # Indices of next-nearest neighbors within d2 + delta\n",
    "            nnn_indices = remaining_indices[remaining_distances <= nnn_cutoff]\n",
    "\n",
    "            # Add edges from next-nearest neighbors to i\n",
    "            for j in nnn_indices:\n",
    "                edge_index.add((j, i))\n",
    "\n",
    "    # Convert edge_index to a tensor\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(list(edge_index), dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "# Function to compute edge attributes based on positions and edge_index\n",
    "def compute_edge_attr(positions, edge_index):\n",
    "    # Compute distances between connected nodes\n",
    "    row, col = edge_index\n",
    "    pos_row = positions[row]\n",
    "    pos_col = positions[col]\n",
    "    edge_distances = np.linalg.norm(pos_row - pos_col, axis=1)\n",
    "    edge_attr = torch.tensor(edge_distances, dtype=torch.float).unsqueeze(1)\n",
    "    return edge_attr\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure with perturbation\n",
    "def create_graph_from_structure(atoms, perturbation_size, delta, edge_index=None):\n",
    "    # Get the positions of the atoms\n",
    "    positions = atoms.get_positions()\n",
    "\n",
    "    # If edge_index is not provided, compute it based on original positions\n",
    "    if edge_index is None:\n",
    "        edge_index = compute_edge_index(positions, delta)\n",
    "\n",
    "    # Apply random perturbation to the positions\n",
    "    if perturbation_size > 0:\n",
    "        perturbation = np.random.uniform(-perturbation_size, perturbation_size, positions.shape)\n",
    "        positions += perturbation  # Perturb the atomic positions\n",
    "\n",
    "    # Compute edge attributes (distances) based on the perturbed positions\n",
    "    edge_attr = compute_edge_attr(positions, edge_index)\n",
    "\n",
    "    # Create node features: atomic mass and atomic number\n",
    "    node_features = torch.tensor(\n",
    "        [[atom.number] for atom in atoms], dtype=torch.float\n",
    "    )  # Shape (num_atoms, 2)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "    )\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to scale node features and edge attributes in each graph list\n",
    "def scale_graphs(graph_list):\n",
    "    # Collect all node features and edge attributes from the graphs\n",
    "    all_node_features = []\n",
    "    all_edge_attributes = []\n",
    "\n",
    "    for graph in graph_list:\n",
    "        all_node_features.append(graph.x)\n",
    "        # Only append edge attributes if they are not empty\n",
    "        if graph.edge_attr is not None and graph.edge_attr.shape[0] > 0:\n",
    "            all_edge_attributes.append(graph.edge_attr)\n",
    "\n",
    "    # Stack all node features\n",
    "    all_node_features_stacked = torch.cat(all_node_features, dim=0).numpy()\n",
    "\n",
    "    # Initialize StandardScalers\n",
    "    node_scaler = StandardScaler()\n",
    "    node_scaler.fit(all_node_features_stacked)\n",
    "\n",
    "    # Fit edge scaler only if there are edge attributes\n",
    "    if len(all_edge_attributes) > 0:\n",
    "        all_edge_attributes_stacked = torch.cat(all_edge_attributes, dim=0).numpy()\n",
    "        edge_scaler = StandardScaler()\n",
    "        edge_scaler.fit(all_edge_attributes_stacked)\n",
    "    else:\n",
    "        edge_scaler = None  # No edges to scale\n",
    "\n",
    "    # Apply the scaling to each graph\n",
    "    for graph in graph_list:\n",
    "        # Scale node features\n",
    "        graph_node_features = graph.x.numpy()\n",
    "        graph_node_features_scaled = node_scaler.transform(graph_node_features)\n",
    "        graph.x = torch.tensor(graph_node_features_scaled, dtype=torch.float)\n",
    "\n",
    "        # Scale edge attributes if they exist\n",
    "        if graph.edge_attr is not None and graph.edge_attr.shape[0] > 0 and edge_scaler is not None:\n",
    "            graph_edge_attributes = graph.edge_attr.numpy()\n",
    "            graph_edge_attributes_scaled = edge_scaler.transform(graph_edge_attributes)\n",
    "            graph.edge_attr = torch.tensor(graph_edge_attributes_scaled, dtype=torch.float)\n",
    "        else:\n",
    "            # If there are no edges, ensure edge_attr is a tensor of appropriate shape\n",
    "            graph.edge_attr = torch.tensor([], dtype=torch.float).reshape(0, 1)\n",
    "\n",
    "# Function to mask a percentage of node features and edge attributes in each graph\n",
    "def mask_graphs(graph_list, masking_percentage=MASKING_PERCENTAGE):\n",
    "    for graph in graph_list:\n",
    "        # Mask a percentage of node features\n",
    "        num_nodes = graph.x.shape[0]\n",
    "        num_node_mask = max(1, int(np.ceil(masking_percentage * num_nodes))) if num_nodes > 0 else 0\n",
    "        if num_node_mask > 0:\n",
    "            node_mask_indices = np.random.choice(num_nodes, num_node_mask, replace=False)\n",
    "            graph.x[node_mask_indices] = 0  # Zero out the node features for the selected nodes\n",
    "\n",
    "        # Mask a percentage of edge attributes\n",
    "        num_edges = graph.edge_attr.shape[0]\n",
    "        num_edge_mask = max(1, int(np.ceil(masking_percentage * num_edges))) if num_edges > 0 else 0\n",
    "        if num_edge_mask > 0:\n",
    "            edge_mask_indices = np.random.choice(num_edges, num_edge_mask, replace=False)\n",
    "            graph.edge_attr[edge_mask_indices] = 0  # Zero out the edge attributes for the selected edges\n",
    "\n",
    "# Path to the supercell files folder\n",
    "supercell_folder = 'supercells'\n",
    "\n",
    "# Lists to store the graph objects\n",
    "graph_list_set_1 = []\n",
    "graph_list_set_2 = []\n",
    "graph_list_original = []\n",
    "\n",
    "# Iterate over all XYZ files in the supercells folder\n",
    "for filename in os.listdir(supercell_folder):\n",
    "    if filename.endswith('.xyz'):\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(supercell_folder, filename)\n",
    "        atoms = read(filepath)\n",
    "\n",
    "        # Extract the number from the filename\n",
    "        match = re.search(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match.group())\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "\n",
    "        # Get positions (unperturbed)\n",
    "        positions = atoms.get_positions()\n",
    "\n",
    "        # Compute edge_index based on original positions\n",
    "        edge_index = compute_edge_index(positions, delta)\n",
    "\n",
    "        # Create graph_original with no perturbation\n",
    "        graph_original = create_graph_from_structure(atoms, 0, delta, edge_index=edge_index)\n",
    "        graph_original.label = label\n",
    "\n",
    "        # Create two graphs with different perturbations\n",
    "        graph_1 = create_graph_from_structure(atoms, 0.05, delta, edge_index=edge_index)\n",
    "        graph_2 = create_graph_from_structure(atoms, 0.05, delta, edge_index=edge_index)\n",
    "        graph_1.label = label\n",
    "        graph_2.label = label\n",
    "\n",
    "        # Append the graphs to the respective lists\n",
    "        graph_list_set_1.append(graph_1)\n",
    "        graph_list_set_2.append(graph_2)\n",
    "        graph_list_original.append(graph_original)\n",
    "\n",
    "        print(f\"Graphs for {filename} created and added to the lists with label {label}.\")\n",
    "\n",
    "# Apply scaling to each graph list\n",
    "scale_graphs(graph_list_set_1)\n",
    "scale_graphs(graph_list_set_2)\n",
    "scale_graphs(graph_list_original)\n",
    "\n",
    "# Apply masking to each graph list\n",
    "mask_graphs(graph_list_set_1)\n",
    "mask_graphs(graph_list_set_2)\n",
    "\n",
    "print(\"Two graph sets created with different random perturbations, scaling, and masking applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator: lattice vector and intra unit cell and PBC, perturbation, scaling and masking applied\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Define the tolerance delta for nearest neighbors\n",
    "delta = 0.1  # Adjust as needed\n",
    "\n",
    "# Perturbation size\n",
    "perturbation_size = 0.05  # Adjust as needed\n",
    "\n",
    "# Function to compute edge_index based on positions and delta, considering PBCs\n",
    "def compute_edge_index(atoms, delta, N):\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "    num_atoms = len(scaled_positions)\n",
    "    cell = atoms.get_cell()\n",
    "\n",
    "    # Build a KDTree of the scaled positions\n",
    "    tree = cKDTree(scaled_positions)\n",
    "\n",
    "    # Define shifts in scaled coordinates (a and b)\n",
    "    shifts_scaled = np.array([\n",
    "        [1/N, 0, 0],\n",
    "        [-1/N, 0, 0],\n",
    "        [0, 1/N, 0],\n",
    "        [0, -1/N, 0],\n",
    "    ])\n",
    "\n",
    "    edge_index = set()\n",
    "\n",
    "    # Existing lattice vector connections\n",
    "    for i in range(num_atoms):\n",
    "        s_i = scaled_positions[i]\n",
    "        for shift_scaled in shifts_scaled:\n",
    "            s_j_candidate = s_i + shift_scaled\n",
    "            s_j_candidate = np.mod(s_j_candidate, 1.0)  # Apply PBCs\n",
    "            # Query KDTree to find atoms near s_j_candidate\n",
    "            idxs = tree.query_ball_point(s_j_candidate, r=delta)\n",
    "            for idx in idxs:\n",
    "                if idx != i:  # Exclude self-loops\n",
    "                    edge_index.add((i, idx))\n",
    "                    edge_index.add((idx, i))  # Add reverse edge\n",
    "\n",
    "    # Determine the number of atoms per unit cell\n",
    "    total_unit_cells = N * N  # For a 2D lattice\n",
    "    atoms_per_unit_cell = num_atoms // total_unit_cells\n",
    "\n",
    "    # Check for consistency\n",
    "    if atoms_per_unit_cell * total_unit_cells != num_atoms:\n",
    "        raise ValueError(\"Number of atoms per unit cell is not consistent with total atoms and supercell dimensions.\")\n",
    "\n",
    "    # Group atoms by unit cell based on their order in the .xyz file\n",
    "    for i in range(0, num_atoms, atoms_per_unit_cell):\n",
    "        group = list(range(i, i + atoms_per_unit_cell))\n",
    "        # Add edges within each unit cell\n",
    "        for idx1 in group:\n",
    "            for idx2 in group:\n",
    "                if idx1 != idx2:\n",
    "                    edge_index.add((idx1, idx2))\n",
    "                    edge_index.add((idx2, idx1))  # Ensure symmetry\n",
    "\n",
    "    # Convert edge_index to tensor\n",
    "    if edge_index:\n",
    "        edge_index = torch.tensor(list(edge_index), dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "# Function to compute edge attributes based on positions and edge_index, considering PBCs\n",
    "def compute_edge_attr(atoms, edge_index):\n",
    "    row, col = edge_index\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "\n",
    "    # Compute displacement vectors considering PBCs\n",
    "    delta_scaled = scaled_positions[row.numpy()] - scaled_positions[col.numpy()]\n",
    "    delta_scaled -= np.round(delta_scaled)\n",
    "    displacement_vectors = delta_scaled @ cell\n",
    "    edge_distances = np.linalg.norm(displacement_vectors, axis=1)\n",
    "    edge_attr = torch.tensor(edge_distances, dtype=torch.float).unsqueeze(1)\n",
    "    return edge_attr\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure\n",
    "def create_graph_from_structure(atoms, delta, N):\n",
    "    # Compute edge_index\n",
    "    edge_index = compute_edge_index(atoms, delta, N)\n",
    "\n",
    "    # Compute edge attributes\n",
    "    edge_attr = compute_edge_attr(atoms, edge_index)\n",
    "\n",
    "    # Create dummy node features (ones)\n",
    "    num_nodes = len(atoms)\n",
    "    node_features = torch.ones((num_nodes, 1), dtype=torch.float)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "    )\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to apply perturbations to a graph list\n",
    "def perturb_graphs(graph_list, atoms_list, perturbation_size):\n",
    "    perturbed_graph_list = []\n",
    "    for graph, atoms in zip(graph_list, atoms_list):\n",
    "        # Clone the graph to avoid modifying the original\n",
    "        perturbed_graph = graph.clone()\n",
    "\n",
    "        # Get the positions of the atoms from the atoms object\n",
    "        positions = atoms.get_positions().copy()  # Original positions\n",
    "\n",
    "        # Apply random perturbation to the positions\n",
    "        if perturbation_size > 0:\n",
    "            perturbation = np.random.uniform(-perturbation_size, perturbation_size, positions.shape)\n",
    "            positions += perturbation  # Perturb the atomic positions\n",
    "\n",
    "        # Update edge attributes based on perturbed positions\n",
    "        # Since edge_index remains the same, we recompute edge_attr\n",
    "        perturbed_atoms = atoms.copy()\n",
    "        perturbed_atoms.set_positions(positions)\n",
    "        perturbed_atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        perturbed_edge_attr = compute_edge_attr(perturbed_atoms, graph.edge_index)\n",
    "        perturbed_graph.edge_attr = perturbed_edge_attr\n",
    "\n",
    "        perturbed_graph_list.append(perturbed_graph)\n",
    "\n",
    "    return perturbed_graph_list\n",
    "\n",
    "# Function to scale edge attributes in each graph list\n",
    "def scale_graphs(graph_list):\n",
    "    # Collect all edge attributes from the graphs\n",
    "    all_edge_attributes = []\n",
    "\n",
    "    for graph in graph_list:\n",
    "        # Only append edge attributes if they are not empty\n",
    "        if graph.edge_attr is not None and graph.edge_attr.shape[0] > 0:\n",
    "            all_edge_attributes.append(graph.edge_attr)\n",
    "\n",
    "    # Fit edge scaler only if there are edge attributes\n",
    "    if len(all_edge_attributes) > 0:\n",
    "        all_edge_attributes_stacked = torch.cat(all_edge_attributes, dim=0).numpy()\n",
    "        edge_scaler = StandardScaler()\n",
    "        edge_scaler.fit(all_edge_attributes_stacked)\n",
    "    else:\n",
    "        edge_scaler = None  # No edges to scale\n",
    "\n",
    "    # Apply the scaling to each graph\n",
    "    for graph in graph_list:\n",
    "        # Scale edge attributes if they exist\n",
    "        if graph.edge_attr is not None and graph.edge_attr.shape[0] > 0 and edge_scaler is not None:\n",
    "            graph_edge_attributes = graph.edge_attr.numpy()\n",
    "            graph_edge_attributes_scaled = edge_scaler.transform(graph_edge_attributes)\n",
    "            graph.edge_attr = torch.tensor(graph_edge_attributes_scaled, dtype=torch.float)\n",
    "        else:\n",
    "            # If there are no edges, ensure edge_attr is a tensor of appropriate shape\n",
    "            graph.edge_attr = torch.tensor([], dtype=torch.float).reshape(0, 1)\n",
    "\n",
    "# Function to mask a percentage of edge attributes in each graph\n",
    "def mask_graphs(graph_list, masking_percentage=MASKING_PERCENTAGE):\n",
    "    for graph in graph_list:\n",
    "        # Mask a percentage of edge attributes\n",
    "        num_edges = graph.edge_attr.shape[0]\n",
    "        num_edge_mask = max(1, int(np.ceil(masking_percentage * num_edges))) if num_edges > 0 else 0\n",
    "        if num_edge_mask > 0:\n",
    "            edge_mask_indices = np.random.choice(num_edges, num_edge_mask, replace=False)\n",
    "            graph.edge_attr[edge_mask_indices] = 0  # Zero out the edge attributes for the selected edges\n",
    "\n",
    "# Path to the supercell files folder\n",
    "supercell_folder = 'supercells_flatband'\n",
    "\n",
    "# Lists to store the graph objects and the corresponding atoms\n",
    "graph_list_unperturbed = []\n",
    "atoms_list_unperturbed = []\n",
    "\n",
    "# Iterate over all XYZ files in the supercells folder\n",
    "for filename in os.listdir(supercell_folder):\n",
    "    if filename.endswith('.xyz'):\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(supercell_folder, filename)\n",
    "        atoms = read(filepath)\n",
    "        atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Extract the number from the filename\n",
    "        match = re.search(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match.group())\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "\n",
    "        # Create graph with PBCs\n",
    "        graph = create_graph_from_structure(atoms, delta, N=SUPERCELL_SIZE)\n",
    "        graph.label = label\n",
    "\n",
    "        # Append the graph and atoms to their respective lists\n",
    "        graph_list_unperturbed.append(graph)\n",
    "        atoms_list_unperturbed.append(atoms)\n",
    "\n",
    "        print(f\"Graph for {filename} created and added to the list with label {label}.\")\n",
    "\n",
    "print(\"Unperturbed graph list created with periodic boundary conditions accounted for.\")\n",
    "\n",
    "# First perturbed graph list\n",
    "graph_list_set_1 = perturb_graphs(graph_list_unperturbed, atoms_list_unperturbed, perturbation_size)\n",
    "\n",
    "# Second perturbed graph list\n",
    "graph_list_set_2 = perturb_graphs(graph_list_unperturbed, atoms_list_unperturbed, perturbation_size)\n",
    "\n",
    "# Apply scaling to each graph list\n",
    "scale_graphs(graph_list_unperturbed)\n",
    "scale_graphs(graph_list_set_1)\n",
    "scale_graphs(graph_list_set_2)\n",
    "\n",
    "# Apply masking to the perturbed graph lists\n",
    "mask_graphs(graph_list_set_1)\n",
    "mask_graphs(graph_list_set_2)\n",
    "\n",
    "print(\"Three graph lists created: unperturbed, perturbed set 1, and perturbed set 2 with scaling and masking applied.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator: nearest neighbour and boundary overlap, perturbation after edge connection, masking and scaling applied\n",
    "# Global variables should be defined before they are used in function defaults\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from scipy.spatial import distance_matrix, cKDTree\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to compute edge_index and edge_type based on positions, delta, N, and supercell boundary edges\n",
    "def compute_edge_index(positions, delta, atoms, N=SUPERCELL_SIZE):\n",
    "    num_atoms = len(positions)\n",
    "    edge_index = []\n",
    "    edge_types = []  # 0 for internal edges, 1 for supercell boundary edges\n",
    "\n",
    "    # Get the lattice vectors a and b\n",
    "    if atoms.cell is None or len(atoms.cell) < 2:\n",
    "        raise ValueError(\"Lattice vectors a and b are not defined in the atoms object.\")\n",
    "    a = atoms.cell[0] / N\n",
    "    b = atoms.cell[1] / N\n",
    "\n",
    "    # Calculate the distance matrix between all atoms\n",
    "    dist_matrix = distance_matrix(positions, positions)\n",
    "\n",
    "    # For each node, find its nearest neighbor(s) within a tolerance\n",
    "    for i in range(num_atoms):\n",
    "        # Exclude self-distance by setting diagonal to infinity\n",
    "        dist_matrix[i, i] = np.inf\n",
    "        # Find the minimum distance for node i\n",
    "        min_dist = np.min(dist_matrix[i])\n",
    "        # Define a cutoff distance as min_dist + delta\n",
    "        cutoff_dist = min_dist + delta\n",
    "        # Find indices (j) where distance is less than or equal to cutoff_dist\n",
    "        nearest_neighbors = np.where(dist_matrix[i] <= cutoff_dist)[0]\n",
    "        for j in nearest_neighbors:\n",
    "            edge_index.append([j, i])\n",
    "            edge_types.append(0)  # Internal edge\n",
    "\n",
    "    # Now connect edge atoms across the supercell boundaries\n",
    "    # Define the shifts\n",
    "    shifts = [(N - 1) * a, -(N - 1) * a, (N - 1) * b, -(N - 1) * b]\n",
    "    tolerance = 0.1  # 0.2 angstroms tolerance for matching positions\n",
    "\n",
    "    # Build a KDTree for efficient nearest-neighbor search\n",
    "    tree = cKDTree(positions)\n",
    "\n",
    "    for shift in shifts:\n",
    "        # Shift all positions by the current lattice vector\n",
    "        shifted_positions = positions + shift\n",
    "        # Find atoms in the original positions that are within the tolerance of the shifted positions\n",
    "        indices_list = tree.query_ball_point(shifted_positions, tolerance)\n",
    "        for i, indices in enumerate(indices_list):\n",
    "            for j in indices:\n",
    "                if i != j:\n",
    "                    edge_index.append([j, i])\n",
    "                    edge_types.append(1)  # Supercell boundary edge\n",
    "\n",
    "    # Convert edge_index and edge_types to tensors\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_types = torch.tensor(edge_types, dtype=torch.long)\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "        edge_types = torch.empty((0,), dtype=torch.long)\n",
    "    return edge_index, edge_types\n",
    "\n",
    "# Function to compute edge attributes based on positions, edge_index, and edge_types\n",
    "def compute_edge_attr(positions, edge_index, edge_types):\n",
    "    # Compute distances between connected nodes\n",
    "    row, col = edge_index\n",
    "    pos_row = positions[row]\n",
    "    pos_col = positions[col]\n",
    "    edge_distances = np.linalg.norm(pos_row - pos_col, axis=1)\n",
    "\n",
    "    # Set edge distances to zero for supercell boundary edges\n",
    "    edge_distances[edge_types == 1] = 0.0\n",
    "\n",
    "    edge_attr = torch.tensor(edge_distances, dtype=torch.float).unsqueeze(1)\n",
    "    return edge_attr\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure with perturbation and fixed edge_index\n",
    "def create_graph_from_structure(atoms, perturbation_size, delta, N=SUPERCELL_SIZE, edge_index=None, edge_types=None):\n",
    "    # Get the positions of the atoms\n",
    "    positions = atoms.get_positions()\n",
    "\n",
    "    # If edge_index is not provided, compute it based on original positions\n",
    "    if edge_index is None or edge_types is None:\n",
    "        edge_index, edge_types = compute_edge_index(positions, delta, atoms, N)\n",
    "\n",
    "    # Apply random perturbation to the positions\n",
    "    if perturbation_size > 0:\n",
    "        perturbation = np.random.uniform(-perturbation_size, perturbation_size, positions.shape)\n",
    "        positions += perturbation  # Perturb the atomic positions\n",
    "\n",
    "    # Compute edge attributes (distances) based on the perturbed positions\n",
    "    edge_attr = compute_edge_attr(positions, edge_index, edge_types)\n",
    "\n",
    "    # Create node features: only atomic number\n",
    "    node_features = torch.tensor(\n",
    "        [[atom.number] for atom in atoms], dtype=torch.float\n",
    "    )  # Shape (num_atoms, 1)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "    )\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to scale node features and edge attributes in each graph list\n",
    "def scale_graphs(graph_list):\n",
    "    # Collect all node features and edge attributes from the graphs\n",
    "    all_node_features = []\n",
    "    all_edge_attributes = []\n",
    "\n",
    "    for graph in graph_list:\n",
    "        all_node_features.append(graph.x)\n",
    "        # Only append edge attributes if they are not empty\n",
    "        if graph.edge_attr is not None and graph.edge_attr.shape[0] > 0:\n",
    "            all_edge_attributes.append(graph.edge_attr)\n",
    "\n",
    "    # Stack all node features\n",
    "    all_node_features_stacked = torch.cat(all_node_features, dim=0).numpy()\n",
    "\n",
    "    # Initialize StandardScalers\n",
    "    node_scaler = StandardScaler()\n",
    "    node_scaler.fit(all_node_features_stacked)\n",
    "\n",
    "    # Fit edge scaler only if there are edge attributes\n",
    "    if len(all_edge_attributes) > 0:\n",
    "        all_edge_attributes_stacked = torch.cat(all_edge_attributes, dim=0).numpy()\n",
    "        edge_scaler = StandardScaler()\n",
    "        edge_scaler.fit(all_edge_attributes_stacked)\n",
    "    else:\n",
    "        edge_scaler = None  # No edges to scale\n",
    "\n",
    "    # Apply the scaling to each graph\n",
    "    for graph in graph_list:\n",
    "        # Scale node features\n",
    "        graph_node_features = graph.x.numpy()\n",
    "        graph_node_features_scaled = node_scaler.transform(graph_node_features)\n",
    "        graph.x = torch.tensor(graph_node_features_scaled, dtype=torch.float)\n",
    "\n",
    "        # Scale edge attributes if they exist\n",
    "        if graph.edge_attr is not None and graph.edge_attr.shape[0] > 0 and edge_scaler is not None:\n",
    "            graph_edge_attributes = graph.edge_attr.numpy()\n",
    "            graph_edge_attributes_scaled = edge_scaler.transform(graph_edge_attributes)\n",
    "            graph.edge_attr = torch.tensor(graph_edge_attributes_scaled, dtype=torch.float)\n",
    "        else:\n",
    "            # If there are no edges, ensure edge_attr is a tensor of appropriate shape\n",
    "            graph.edge_attr = torch.tensor([], dtype=torch.float).reshape(0, 1)\n",
    "\n",
    "# Function to mask a percentage of node features and edge attributes in each graph\n",
    "def mask_graphs(graph_list, masking_percentage=MASKING_PERCENTAGE):\n",
    "    for graph in graph_list:\n",
    "        # Mask a percentage of node features\n",
    "        num_nodes = graph.x.shape[0]\n",
    "        num_node_mask = max(1, int(np.ceil(masking_percentage * num_nodes))) if num_nodes > 0 else 0\n",
    "        if num_node_mask > 0:\n",
    "            node_mask_indices = np.random.choice(num_nodes, num_node_mask, replace=False)\n",
    "            graph.x[node_mask_indices] = 0  # Zero out the node features for the selected nodes\n",
    "\n",
    "        # Mask a percentage of edge attributes\n",
    "        num_edges = graph.edge_attr.shape[0]\n",
    "        num_edge_mask = max(1, int(np.ceil(masking_percentage * num_edges))) if num_edges > 0 else 0\n",
    "        if num_edge_mask > 0:\n",
    "            edge_mask_indices = np.random.choice(num_edges, num_edge_mask, replace=False)\n",
    "            graph.edge_attr[edge_mask_indices] = 0  # Zero out the edge attributes for the selected edges\n",
    "\n",
    "# Path to the supercell files folder\n",
    "supercell_folder = 'supercells'\n",
    "\n",
    "# Lists to store the graph objects\n",
    "graph_list_set_1 = []\n",
    "graph_list_set_2 = []\n",
    "graph_list_original = []\n",
    "\n",
    "# Tolerance delta for including nearest neighbors\n",
    "delta = 0.1  # Adjust this value as needed\n",
    "\n",
    "# Iterate over all XYZ files in the supercells folder\n",
    "for filename in os.listdir(supercell_folder):\n",
    "    if filename.endswith('.xyz'):\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(supercell_folder, filename)\n",
    "        atoms = read(filepath)\n",
    "\n",
    "        # Extract the number from the filename\n",
    "        match = re.search(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match.group())\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "\n",
    "        # Get positions (unperturbed)\n",
    "        positions = atoms.get_positions()\n",
    "\n",
    "        # Compute edge_index and edge_types based on original positions\n",
    "        edge_index, edge_types = compute_edge_index(positions, delta, atoms, N=SUPERCELL_SIZE)\n",
    "\n",
    "        # Create graph_original with no perturbation\n",
    "        graph_original = create_graph_from_structure(atoms, 0, delta, N=SUPERCELL_SIZE, edge_index=edge_index, edge_types=edge_types)\n",
    "        graph_original.label = label\n",
    "\n",
    "        # Create two graphs with different perturbations and fixed edge_index and edge_types\n",
    "        graph_1 = create_graph_from_structure(atoms, 0.05, delta, N=SUPERCELL_SIZE, edge_index=edge_index, edge_types=edge_types)\n",
    "        graph_2 = create_graph_from_structure(atoms, 0.05, delta, N=SUPERCELL_SIZE, edge_index=edge_index, edge_types=edge_types)\n",
    "        graph_1.label = label\n",
    "        graph_2.label = label\n",
    "\n",
    "        # Append the graphs to the respective lists\n",
    "        graph_list_set_1.append(graph_1)\n",
    "        graph_list_set_2.append(graph_2)\n",
    "        graph_list_original.append(graph_original)\n",
    "\n",
    "        print(f\"Graphs for {filename} created and added to the lists with label {label}.\")\n",
    "\n",
    "# Apply scaling to each graph list\n",
    "scale_graphs(graph_list_set_1)\n",
    "scale_graphs(graph_list_set_2)\n",
    "scale_graphs(graph_list_original)\n",
    "\n",
    "# Apply masking to each graph list (except the original graphs)\n",
    "mask_graphs(graph_list_set_1)\n",
    "mask_graphs(graph_list_set_2)\n",
    "\n",
    "print(\"Two graph sets created with different random perturbations, supercell boundary edges, scaling, and masking applied.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator: nearest neighbour and boundary overlap, no masking, perturbation or scaling\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from scipy.spatial import distance_matrix, cKDTree\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure\n",
    "def create_graph_from_structure(atoms, delta=0.1, N=4):\n",
    "    # Get the positions of the atoms\n",
    "    positions = atoms.get_positions()\n",
    "    num_atoms = len(positions)\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    \n",
    "    # Get the lattice vectors a and b\n",
    "    if atoms.cell is None or len(atoms.cell) < 2:\n",
    "        raise ValueError(\"Lattice vectors a and b are not defined in the atoms object.\")\n",
    "    a = (atoms.cell[0])/N\n",
    "    b = (atoms.cell[1])/N\n",
    "    \n",
    "    # Calculate the distance matrix between all atoms\n",
    "    dist_matrix = distance_matrix(positions, positions)\n",
    "    \n",
    "    # For each node, find its nearest neighbor(s) within a tolerance\n",
    "    for i in range(num_atoms):\n",
    "        # Exclude self-distance by setting diagonal to infinity\n",
    "        dist_matrix[i, i] = np.inf\n",
    "        # Find the minimum distance for node i\n",
    "        min_dist = np.min(dist_matrix[i])\n",
    "        # Define a cutoff distance as min_dist + delta\n",
    "        cutoff_dist = min_dist + delta\n",
    "        # Find indices (j) where distance is less than or equal to cutoff_dist\n",
    "        nearest_neighbors = np.where(dist_matrix[i] <= cutoff_dist)[0]\n",
    "        for j in nearest_neighbors:\n",
    "            # Add edges in both directions since it's an undirected graph\n",
    "            edge_index.append([i, j])\n",
    "            edge_index.append([j, i])\n",
    "            # Add the corresponding distance as the edge attribute\n",
    "            edge_attr.append(dist_matrix[i, j])\n",
    "            edge_attr.append(dist_matrix[i, j])  # Same distance in undirected graph\n",
    "    \n",
    "    # Now connect edge atoms across the supercell boundaries\n",
    "    # Define the shifts\n",
    "    shifts = [(N - 1) * a, -(N - 1) * a, (N - 1) * b, -(N - 1) * b]\n",
    "    tolerance = 0.1  # 0.1 angstroms tolerance for matching positions\n",
    "    \n",
    "    # Build a KDTree for efficient nearest-neighbor search\n",
    "    tree = cKDTree(positions)\n",
    "    \n",
    "    for shift in shifts:\n",
    "        # Shift all positions by the current lattice vector\n",
    "        shifted_positions = positions + shift\n",
    "        # Find atoms in the original positions that are within the tolerance of the shifted positions\n",
    "        indices_list = tree.query_ball_point(shifted_positions, tolerance)\n",
    "        for i, indices in enumerate(indices_list):\n",
    "            for j in indices:\n",
    "                if i != j:\n",
    "                    # Add edges in both directions\n",
    "                    edge_index.append([i, j])\n",
    "                    edge_index.append([j, i])\n",
    "                    # Edge attribute is zero since they are connected across the boundary\n",
    "                    edge_attr.append(0.0)\n",
    "                    edge_attr.append(0.0)\n",
    "    \n",
    "    # Convert edge_index and edge_attr to tensors\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float).unsqueeze(1)\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "        edge_attr = torch.empty((0, 1), dtype=torch.float)\n",
    "    \n",
    "    # Create node features: atomic mass and atomic number\n",
    "    node_features = torch.tensor(\n",
    "        [[atom.mass, atom.number] for atom in atoms], dtype=torch.float\n",
    "    )\n",
    "    \n",
    "    # Create PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "    )\n",
    "    \n",
    "    return graph\n",
    "\n",
    "# Path to the supercell files folder\n",
    "supercell_folder = 'supercells'\n",
    "\n",
    "# List to store the graph objects\n",
    "graph_list = []\n",
    "\n",
    "# Tolerance delta for including nearest neighbors\n",
    "delta = 0.1  # Adjust this value as needed\n",
    "\n",
    "# Supercell dimension N\n",
    "N = 4  # Adjust this value as needed\n",
    "\n",
    "# Iterate over all XYZ files in the supercells folder\n",
    "for filename in os.listdir(supercell_folder):\n",
    "    if filename.endswith('.xyz'):\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(supercell_folder, filename)\n",
    "        atoms = read(filepath)\n",
    "        \n",
    "        # Extract the number from the filename to use as a label\n",
    "        match = re.search(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match.group())\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "        \n",
    "        # Create the graph with the specified delta and N\n",
    "        graph = create_graph_from_structure(atoms, delta=delta, N=N)\n",
    "        \n",
    "        # Add the label to the graph\n",
    "        graph.label = label\n",
    "        \n",
    "        # Append the graph to the list\n",
    "        graph_list.append(graph)\n",
    "        \n",
    "        print(f\"Graph for {filename} created and added to the list with label {label}.\")\n",
    "\n",
    "print(\"Graph generation complete. Each node is connected to its nearest neighbor(s) within the specified tolerance, including periodic connections across supercell boundaries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator: nearest neighbour, perturbation after edge connection, masking and scaling applies\n",
    "\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from scipy.spatial import distance_matrix\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the tolerance delta for nearest neighbors\n",
    "delta = 0.1  # Adjust as needed\n",
    "\n",
    "# Function to compute edge_index based on positions and delta\n",
    "def compute_edge_index(positions, delta):\n",
    "    # Calculate the distance matrix between all atoms\n",
    "    dist_matrix = distance_matrix(positions, positions)\n",
    "    num_atoms = len(positions)\n",
    "    edge_index = []\n",
    "\n",
    "    # For each node, find its nearest neighbor(s) within a tolerance\n",
    "    for i in range(num_atoms):\n",
    "        # Exclude self-distance by setting diagonal to infinity\n",
    "        dist_matrix[i, i] = np.inf\n",
    "        # Find the minimum distance for node i\n",
    "        min_dist = np.min(dist_matrix[i])\n",
    "        # Define a cutoff distance as min_dist + delta\n",
    "        cutoff_dist = min_dist + delta\n",
    "        # Find indices (j) where distance is less than or equal to cutoff_dist\n",
    "        nearest_neighbors = np.where(dist_matrix[i] <= cutoff_dist)[0]\n",
    "        for j in nearest_neighbors:\n",
    "            # Add edges in both directions since it's an undirected graph\n",
    "            #edge_index.append([i, j])\n",
    "            edge_index.append([j, i])\n",
    "\n",
    "    # Convert edge_index to a tensor if there are edges\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "    return edge_index\n",
    "\n",
    "# Function to compute edge attributes based on positions and edge_index\n",
    "def compute_edge_attr(positions, edge_index):\n",
    "    # Compute distances between connected nodes\n",
    "    row, col = edge_index\n",
    "    pos_row = positions[row]\n",
    "    pos_col = positions[col]\n",
    "    edge_distances = np.linalg.norm(pos_row - pos_col, axis=1)\n",
    "    edge_attr = torch.tensor(edge_distances, dtype=torch.float).unsqueeze(1)\n",
    "    return edge_attr\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure with perturbation\n",
    "def create_graph_from_structure(atoms, perturbation_size, delta, edge_index=None):\n",
    "    # Get the positions of the atoms\n",
    "    positions = atoms.get_positions()\n",
    "\n",
    "    # If edge_index is not provided, compute it based on original positions\n",
    "    if edge_index is None:\n",
    "        edge_index = compute_edge_index(positions, delta)\n",
    "\n",
    "    # Apply random perturbation to the positions\n",
    "    if perturbation_size > 0:\n",
    "        perturbation = np.random.uniform(-perturbation_size, perturbation_size, positions.shape)\n",
    "        positions += perturbation  # Perturb the atomic positions\n",
    "\n",
    "    # Compute edge attributes (distances) based on the perturbed positions\n",
    "    edge_attr = compute_edge_attr(positions, edge_index)\n",
    "\n",
    "    # Create node features: atomic mass and atomic number\n",
    "    node_features = torch.tensor(\n",
    "        [[atom.number] for atom in atoms], dtype=torch.float\n",
    "    )  # Shape (num_atoms, 2)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "    )\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to scale node features and edge attributes in each graph list\n",
    "def scale_graphs(graph_list):\n",
    "    # Collect all node features and edge attributes from the graphs\n",
    "    all_node_features = []\n",
    "    all_edge_attributes = []\n",
    "\n",
    "    for graph in graph_list:\n",
    "        all_node_features.append(graph.x)\n",
    "        # Only append edge attributes if they are not empty\n",
    "        if graph.edge_attr is not None and graph.edge_attr.shape[0] > 0:\n",
    "            all_edge_attributes.append(graph.edge_attr)\n",
    "\n",
    "    # Stack all node features\n",
    "    all_node_features_stacked = torch.cat(all_node_features, dim=0).numpy()\n",
    "\n",
    "    # Initialize StandardScalers\n",
    "    node_scaler = StandardScaler()\n",
    "    node_scaler.fit(all_node_features_stacked)\n",
    "\n",
    "    # Fit edge scaler only if there are edge attributes\n",
    "    if len(all_edge_attributes) > 0:\n",
    "        all_edge_attributes_stacked = torch.cat(all_edge_attributes, dim=0).numpy()\n",
    "        edge_scaler = StandardScaler()\n",
    "        edge_scaler.fit(all_edge_attributes_stacked)\n",
    "    else:\n",
    "        edge_scaler = None  # No edges to scale\n",
    "\n",
    "    # Apply the scaling to each graph\n",
    "    for graph in graph_list:\n",
    "        # Scale node features\n",
    "        graph_node_features = graph.x.numpy()\n",
    "        graph_node_features_scaled = node_scaler.transform(graph_node_features)\n",
    "        graph.x = torch.tensor(graph_node_features_scaled, dtype=torch.float)\n",
    "\n",
    "        # Scale edge attributes if they exist\n",
    "        if graph.edge_attr is not None and graph.edge_attr.shape[0] > 0 and edge_scaler is not None:\n",
    "            graph_edge_attributes = graph.edge_attr.numpy()\n",
    "            graph_edge_attributes_scaled = edge_scaler.transform(graph_edge_attributes)\n",
    "            graph.edge_attr = torch.tensor(graph_edge_attributes_scaled, dtype=torch.float)\n",
    "        else:\n",
    "            # If there are no edges, ensure edge_attr is a tensor of appropriate shape\n",
    "            graph.edge_attr = torch.tensor([], dtype=torch.float).reshape(0, 1)\n",
    "\n",
    "# Function to mask a percentage of node features and edge attributes in each graph\n",
    "def mask_graphs(graph_list, masking_percentage=MASKING_PERCENTAGE):\n",
    "    for graph in graph_list:\n",
    "        # Mask a percentage of node features\n",
    "        num_nodes = graph.x.shape[0]\n",
    "        num_node_mask = max(1, int(np.ceil(masking_percentage * num_nodes))) if num_nodes > 0 else 0\n",
    "        if num_node_mask > 0:\n",
    "            node_mask_indices = np.random.choice(num_nodes, num_node_mask, replace=False)\n",
    "            graph.x[node_mask_indices] = 0  # Zero out the node features for the selected nodes\n",
    "\n",
    "        # Mask a percentage of edge attributes\n",
    "        num_edges = graph.edge_attr.shape[0]\n",
    "        num_edge_mask = max(1, int(np.ceil(masking_percentage * num_edges))) if num_edges > 0 else 0\n",
    "        if num_edge_mask > 0:\n",
    "            edge_mask_indices = np.random.choice(num_edges, num_edge_mask, replace=False)\n",
    "            graph.edge_attr[edge_mask_indices] = 0  # Zero out the edge attributes for the selected edges\n",
    "\n",
    "# Path to the supercell files folder\n",
    "supercell_folder = 'supercells'\n",
    "\n",
    "# Lists to store the graph objects\n",
    "graph_list_set_1 = []\n",
    "graph_list_set_2 = []\n",
    "graph_list_original = []\n",
    "\n",
    "# Iterate over all XYZ files in the supercells folder\n",
    "for filename in os.listdir(supercell_folder):\n",
    "    if filename.endswith('.xyz'):\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(supercell_folder, filename)\n",
    "        atoms = read(filepath)\n",
    "\n",
    "        # Extract the number from the filename\n",
    "        match = re.search(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match.group())\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "\n",
    "        # Get positions (unperturbed)\n",
    "        positions = atoms.get_positions()\n",
    "\n",
    "        # Compute edge_index based on original positions\n",
    "        edge_index = compute_edge_index(positions, delta)\n",
    "\n",
    "        # Create graph_original with no perturbation\n",
    "        graph_original = create_graph_from_structure(atoms, 0, delta, edge_index=edge_index)\n",
    "        graph_original.label = label\n",
    "\n",
    "        # Create two graphs with different perturbations\n",
    "        graph_1 = create_graph_from_structure(atoms, 0.05, delta, edge_index=edge_index)\n",
    "        graph_2 = create_graph_from_structure(atoms, 0.05, delta, edge_index=edge_index)\n",
    "        graph_1.label = label\n",
    "        graph_2.label = label\n",
    "\n",
    "        # Append the graphs to the respective lists\n",
    "        graph_list_set_1.append(graph_1)\n",
    "        graph_list_set_2.append(graph_2)\n",
    "        graph_list_original.append(graph_original)\n",
    "\n",
    "        print(f\"Graphs for {filename} created and added to the lists with label {label}.\")\n",
    "\n",
    "# Apply scaling to each graph list\n",
    "scale_graphs(graph_list_set_1)\n",
    "scale_graphs(graph_list_set_2)\n",
    "scale_graphs(graph_list_original)\n",
    "\n",
    "# Apply masking to each graph list\n",
    "mask_graphs(graph_list_set_1)\n",
    "mask_graphs(graph_list_set_2)\n",
    "\n",
    "print(\"Two graph sets created with different random perturbations, scaling, and masking applied.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator: nearest neighbour, perturbation, masking and scaling applied\n",
    "# Graph set generator: Converts the supercells into undirected graphs connecting them based on nearest neighbors within a tolerance.\n",
    "# Then, creates 2 versions of each graph both with independently random perturbations and masked nodes/features applied to the graphs.\n",
    "# The graphs are scaled then stored in two lists.\n",
    "\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from scipy.spatial import distance_matrix\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the masking percentage\n",
    "MASKING_PERCENTAGE = 0.1  # Mask 10% of nodes and edges\n",
    "\n",
    "# Define the tolerance delta for nearest neighbors\n",
    "delta = 0.1  # Adjust as needed\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure with perturbation\n",
    "def create_graph_from_structure(atoms, perturbation_size, delta):\n",
    "    # Get the positions of the atoms\n",
    "    positions = atoms.get_positions()\n",
    "    \n",
    "    # Apply random perturbation to the positions\n",
    "    perturbation = np.random.uniform(-perturbation_size, perturbation_size, positions.shape)\n",
    "    positions += perturbation  # Perturb the atomic positions\n",
    "    \n",
    "    # Calculate the distance matrix between all atoms\n",
    "    dist_matrix = distance_matrix(positions, positions)\n",
    "    num_atoms = len(positions)\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    \n",
    "    # For each node, find its nearest neighbor(s) within a tolerance\n",
    "    for i in range(num_atoms):\n",
    "        # Exclude self-distance by setting diagonal to infinity\n",
    "        dist_matrix[i, i] = np.inf\n",
    "        # Find the minimum distance for node i\n",
    "        min_dist = np.min(dist_matrix[i])\n",
    "        # Define a cutoff distance as min_dist + delta\n",
    "        cutoff_dist = min_dist + delta\n",
    "        # Find indices (j) where distance is less than or equal to cutoff_dist\n",
    "        nearest_neighbors = np.where(dist_matrix[i] <= cutoff_dist)[0]\n",
    "        for j in nearest_neighbors:\n",
    "            # Add edges in both directions since it's an undirected graph\n",
    "            edge_index.append([i, j])\n",
    "            edge_index.append([j, i])\n",
    "            # Add the corresponding distance as the edge attribute\n",
    "            edge_attr.append(dist_matrix[i, j])\n",
    "            edge_attr.append(dist_matrix[i, j])  # Same distance in undirected graph\n",
    "\n",
    "    # Convert edge_index to a tensor if there are edges\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float).unsqueeze(1)\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "        edge_attr = torch.empty((0, 1), dtype=torch.float)\n",
    "    \n",
    "    # Create node features: atomic mass and atomic number\n",
    "    node_features = torch.tensor(\n",
    "        [[atom.mass, atom.number] for atom in atoms], dtype=torch.float\n",
    "    )  # Shape (num_atoms, 2)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "    )\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to scale node features and edge attributes in each graph list\n",
    "def scale_graphs(graph_list):\n",
    "    # Collect all node features and edge attributes from the graphs\n",
    "    all_node_features = []\n",
    "    all_edge_attributes = []\n",
    "    \n",
    "    for graph in graph_list:\n",
    "        all_node_features.append(graph.x)\n",
    "        # Only append edge attributes if they are not empty\n",
    "        if graph.edge_attr is not None and graph.edge_attr.shape[0] > 0:\n",
    "            all_edge_attributes.append(graph.edge_attr)\n",
    "    \n",
    "    # Stack all node features\n",
    "    all_node_features_stacked = torch.cat(all_node_features, dim=0).numpy()\n",
    "    \n",
    "    # Initialize StandardScalers\n",
    "    node_scaler = StandardScaler()\n",
    "    node_scaler.fit(all_node_features_stacked)\n",
    "    \n",
    "    # Fit edge scaler only if there are edge attributes\n",
    "    if len(all_edge_attributes) > 0:\n",
    "        all_edge_attributes_stacked = torch.cat(all_edge_attributes, dim=0).numpy()\n",
    "        edge_scaler = StandardScaler()\n",
    "        edge_scaler.fit(all_edge_attributes_stacked)\n",
    "    else:\n",
    "        edge_scaler = None  # No edges to scale\n",
    "    \n",
    "    # Apply the scaling to each graph\n",
    "    for graph in graph_list:\n",
    "        # Scale node features\n",
    "        graph_node_features = graph.x.numpy()\n",
    "        graph_node_features_scaled = node_scaler.transform(graph_node_features)\n",
    "        graph.x = torch.tensor(graph_node_features_scaled, dtype=torch.float)\n",
    "        \n",
    "        # Scale edge attributes if they exist\n",
    "        if graph.edge_attr is not None and graph.edge_attr.shape[0] > 0 and edge_scaler is not None:\n",
    "            graph_edge_attributes = graph.edge_attr.numpy()\n",
    "            graph_edge_attributes_scaled = edge_scaler.transform(graph_edge_attributes)\n",
    "            graph.edge_attr = torch.tensor(graph_edge_attributes_scaled, dtype=torch.float)\n",
    "        else:\n",
    "            # If there are no edges, ensure edge_attr is a tensor of appropriate shape\n",
    "            graph.edge_attr = torch.tensor([], dtype=torch.float).reshape(0, 1)\n",
    "\n",
    "# Function to mask a percentage of node features and edge attributes in each graph\n",
    "def mask_graphs(graph_list, masking_percentage=MASKING_PERCENTAGE):\n",
    "    for graph in graph_list:\n",
    "        # Mask a percentage of node features\n",
    "        num_nodes = graph.x.shape[0]\n",
    "        num_node_mask = max(1, int(np.ceil(masking_percentage * num_nodes))) if num_nodes > 0 else 0\n",
    "        if num_node_mask > 0:\n",
    "            node_mask_indices = np.random.choice(num_nodes, num_node_mask, replace=False)\n",
    "            graph.x[node_mask_indices] = 0  # Zero out the node features for the selected nodes\n",
    "\n",
    "        # Mask a percentage of edge attributes\n",
    "        num_edges = graph.edge_attr.shape[0]\n",
    "        num_edge_mask = max(1, int(np.ceil(masking_percentage * num_edges))) if num_edges > 0 else 0\n",
    "        if num_edge_mask > 0:\n",
    "            edge_mask_indices = np.random.choice(num_edges, num_edge_mask, replace=False)\n",
    "            graph.edge_attr[edge_mask_indices] = 0  # Zero out the edge attributes for the selected edges\n",
    "\n",
    "# Path to the supercell files folder\n",
    "supercell_folder = 'supercells'\n",
    "\n",
    "# Lists to store the graph objects\n",
    "graph_list_set_1 = []\n",
    "graph_list_set_2 = []\n",
    "graph_list_original = []\n",
    "\n",
    "# Iterate over all XYZ files in the supercells folder\n",
    "for filename in os.listdir(supercell_folder):\n",
    "    if filename.endswith('.xyz'):\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(supercell_folder, filename)\n",
    "        atoms = read(filepath)\n",
    "        \n",
    "        # Extract the number from the filename\n",
    "        match = re.search(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match.group())\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "        \n",
    "        # Create two graphs with different perturbations\n",
    "        graph_1 = create_graph_from_structure(atoms, 0.05, delta)\n",
    "        graph_2 = create_graph_from_structure(atoms, 0.05, delta)\n",
    "        graph_original = create_graph_from_structure(atoms, 0, delta)\n",
    "        \n",
    "        # Add the label to each graph\n",
    "        graph_1.label = label\n",
    "        graph_2.label = label\n",
    "        graph_original.label = label\n",
    "        \n",
    "        # Append the graphs to the respective lists\n",
    "        graph_list_set_1.append(graph_1)\n",
    "        graph_list_set_2.append(graph_2)\n",
    "        graph_list_original.append(graph_original)\n",
    "        \n",
    "        print(f\"Graphs for {filename} created and added to the lists with label {label}.\")\n",
    "\n",
    "# Apply scaling to each graph list\n",
    "scale_graphs(graph_list_set_1)\n",
    "scale_graphs(graph_list_set_2)\n",
    "scale_graphs(graph_list_original)\n",
    "\n",
    "# Apply masking to each graph list\n",
    "mask_graphs(graph_list_set_1)\n",
    "mask_graphs(graph_list_set_2)\n",
    "\n",
    "print(\"Two graph sets created with different random perturbations, scaling, and masking applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator: nearest neighbour, no masking, perturbation or scaling\n",
    "# Graph generator: Converts supercell structures into undirected graphs by connecting each node to its nearest neighbor(s) within a tolerance.\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from scipy.spatial import distance_matrix\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure\n",
    "def create_graph_from_structure(atoms, delta=0.1):\n",
    "    # Get the positions of the atoms\n",
    "    positions = atoms.get_positions()\n",
    "    \n",
    "    # Calculate the distance matrix between all atoms\n",
    "    dist_matrix = distance_matrix(positions, positions)\n",
    "    num_atoms = len(positions)\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    \n",
    "    # For each node, find its nearest neighbor(s) within a tolerance\n",
    "    for i in range(num_atoms):\n",
    "        # Exclude self-distance by setting diagonal to infinity\n",
    "        dist_matrix[i, i] = np.inf\n",
    "        # Find the minimum distance for node i\n",
    "        min_dist = np.min(dist_matrix[i])\n",
    "        # Define a cutoff distance as min_dist + delta\n",
    "        cutoff_dist = min_dist + delta\n",
    "        # Find indices (j) where distance is less than or equal to cutoff_dist\n",
    "        nearest_neighbors = np.where(dist_matrix[i] <= cutoff_dist)[0]\n",
    "        for j in nearest_neighbors:\n",
    "            # Add edges in both directions since it's an undirected graph\n",
    "            edge_index.append([i, j])\n",
    "            edge_index.append([j, i])\n",
    "            # Add the corresponding distance as the edge attribute\n",
    "            edge_attr.append(dist_matrix[i, j])\n",
    "            edge_attr.append(dist_matrix[i, j])  # Same distance in undirected graph\n",
    "    \n",
    "    # Convert edge_index and edge_attr to tensors\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float).unsqueeze(1)\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "        edge_attr = torch.empty((0, 1), dtype=torch.float)\n",
    "    \n",
    "    # Create node features: atomic mass and atomic number\n",
    "    node_features = torch.tensor(\n",
    "        [[atom.mass, atom.number] for atom in atoms], dtype=torch.float\n",
    "    )\n",
    "    \n",
    "    # Create PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "    )\n",
    "    \n",
    "    return graph\n",
    "\n",
    "# Path to the supercell files folder\n",
    "supercell_folder = 'supercells'\n",
    "\n",
    "# List to store the graph objects\n",
    "graph_list = []\n",
    "\n",
    "# Tolerance delta for including nearest neighbors\n",
    "delta = 0.1  # Adjust this value as needed\n",
    "\n",
    "# Iterate over all XYZ files in the supercells folder\n",
    "for filename in os.listdir(supercell_folder):\n",
    "    if filename.endswith('.xyz'):\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(supercell_folder, filename)\n",
    "        atoms = read(filepath)\n",
    "        \n",
    "        # Extract the number from the filename to use as a label\n",
    "        match = re.search(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match.group())\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "        \n",
    "        # Create the graph with the specified delta\n",
    "        graph = create_graph_from_structure(atoms, delta=delta)\n",
    "        \n",
    "        # Add the label to the graph\n",
    "        graph.label = label\n",
    "        \n",
    "        # Append the graph to the list\n",
    "        graph_list.append(graph)\n",
    "        \n",
    "        print(f\"Graph for {filename} created and added to the list with label {label}.\")\n",
    "\n",
    "print(\"Graph generation complete. Each node is connected to its nearest neighbor(s) within the specified tolerance.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph generator: hard cutoff, perturbation, masking and scaling applied\n",
    "# Graph set generator: takes the supercells and turns them into undirected graphs connecting them based on a fixed cutoff.\n",
    "# Then, creates 2 versions of each graph both with independently random perturbations and masked nodes/features applied to the graphs\n",
    "# The graphs are scaled then Stored in two lists\n",
    "import re\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from scipy.spatial import distance_matrix\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure with perturbation\n",
    "def create_graph_from_structure(atoms, CUT_OFF_DISTANCE, pertubation_size):\n",
    "    # Get the positions of the atoms\n",
    "    positions = atoms.get_positions()\n",
    "    \n",
    "    # Apply random perturbation to the positions\n",
    "    perturbation = np.random.uniform(-pertubation_size, pertubation_size, positions.shape)\n",
    "    positions += perturbation  # Perturb the atomic positions\n",
    "    \n",
    "    # Calculate the distance matrix between all atoms\n",
    "    dist_matrix = distance_matrix(positions, positions)\n",
    "    \n",
    "    # Collect the edges and the edge distances based on the cutoff distance\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    num_atoms = len(positions)\n",
    "    for i in range(num_atoms):\n",
    "        for j in range(i+1, num_atoms):  # Only check each pair once\n",
    "            if dist_matrix[i, j] <= CUT_OFF_DISTANCE:\n",
    "                # Add edges in both directions since it's an undirected graph\n",
    "                edge_index.append([i, j])\n",
    "                edge_index.append([j, i])\n",
    "                # Add the corresponding distance as the edge attribute\n",
    "                edge_attr.append(dist_matrix[i, j])\n",
    "                edge_attr.append(dist_matrix[i, j])\n",
    "\n",
    "    # Convert edge_index to a tensor if there are edges\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()  # Transpose and make contiguous\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float).unsqueeze(1)\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "        edge_attr = torch.empty((0, 1), dtype=torch.float)\n",
    "    \n",
    "    # Create node features: atomic mass and atomic number\n",
    "    node_features = torch.tensor(\n",
    "        [[atom.mass, atom.number] for atom in atoms], dtype=torch.float\n",
    "    )  # Shape (num_atoms, 2)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "    )\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to scale node features and edge attributes in each graph list\n",
    "def scale_graphs(graph_list):\n",
    "    # Collect all node features and edge attributes from the graphs\n",
    "    all_node_features = []\n",
    "    all_edge_attributes = []\n",
    "    \n",
    "    for graph in graph_list:\n",
    "        all_node_features.append(graph.x)\n",
    "        # Only append edge attributes if they are not empty\n",
    "        if graph.edge_attr is not None and graph.edge_attr.shape[0] > 0:\n",
    "            all_edge_attributes.append(graph.edge_attr)\n",
    "    \n",
    "    # Stack all node features\n",
    "    all_node_features_stacked = torch.cat(all_node_features, dim=0).numpy()\n",
    "    \n",
    "    # Initialize StandardScalers\n",
    "    node_scaler = StandardScaler()\n",
    "    node_scaler.fit(all_node_features_stacked)\n",
    "    \n",
    "    # Fit edge scaler only if there are edge attributes\n",
    "    if len(all_edge_attributes) > 0:\n",
    "        all_edge_attributes_stacked = torch.cat(all_edge_attributes, dim=0).numpy()\n",
    "        edge_scaler = StandardScaler()\n",
    "        edge_scaler.fit(all_edge_attributes_stacked)\n",
    "    else:\n",
    "        edge_scaler = None  # No edges to scale\n",
    "    \n",
    "    # Apply the scaling to each graph\n",
    "    for graph in graph_list:\n",
    "        # Scale node features\n",
    "        graph_node_features = graph.x.numpy()\n",
    "        graph_node_features_scaled = node_scaler.transform(graph_node_features)\n",
    "        graph.x = torch.tensor(graph_node_features_scaled, dtype=torch.float)\n",
    "        \n",
    "        # Scale edge attributes if they exist\n",
    "        if graph.edge_attr is not None and graph.edge_attr.shape[0] > 0 and edge_scaler is not None:\n",
    "            graph_edge_attributes = graph.edge_attr.numpy()\n",
    "            graph_edge_attributes_scaled = edge_scaler.transform(graph_edge_attributes)\n",
    "            graph.edge_attr = torch.tensor(graph_edge_attributes_scaled, dtype=torch.float)\n",
    "        else:\n",
    "            # If there are no edges, ensure edge_attr is a tensor of appropriate shape\n",
    "            graph.edge_attr = torch.tensor([], dtype=torch.float).reshape(0, 1)\n",
    "\n",
    "# Function to mask 10% of node features and edge attributes in each graph\n",
    "def mask_graphs(graph_list, masking_percentage=MASKING_PERCENTAGE):\n",
    "    for graph in graph_list:\n",
    "        # Mask 10% of node features\n",
    "        num_nodes = graph.x.shape[0]\n",
    "        num_node_mask = max(1, int(np.ceil(masking_percentage * num_nodes))) if num_nodes > 0 else 0\n",
    "        if num_node_mask > 0:\n",
    "            node_mask_indices = np.random.choice(num_nodes, num_node_mask, replace=False)\n",
    "            graph.x[node_mask_indices] = 0  # Zero out the node features for the selected nodes\n",
    "\n",
    "        # Mask 10% of edge attributes\n",
    "        num_edges = graph.edge_attr.shape[0]\n",
    "        num_edge_mask = max(1, int(np.ceil(masking_percentage * num_edges))) if num_edges > 0 else 0\n",
    "        if num_edge_mask > 0:\n",
    "            edge_mask_indices = np.random.choice(num_edges, num_edge_mask, replace=False)\n",
    "            graph.edge_attr[edge_mask_indices] = 0  # Zero out the edge attributes for the selected edges\n",
    "\n",
    "\n",
    "# Path to the supercell files folder\n",
    "supercell_folder = 'supercells'\n",
    "\n",
    "# Lists to store the graph objects\n",
    "graph_list_set_1 = []\n",
    "graph_list_set_2 = []\n",
    "graph_list_original = []\n",
    "\n",
    "# Iterate over all XYZ files in the supercells folder\n",
    "for filename in os.listdir(supercell_folder):\n",
    "    if filename.endswith('.xyz'):\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(supercell_folder, filename)\n",
    "        atoms = read(filepath)\n",
    "        \n",
    "        # Extract the number from the filename\n",
    "        match = re.search(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match.group())\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "        \n",
    "        # Create two graphs with different perturbations\n",
    "        graph_1 = create_graph_from_structure(atoms, CUT_OFF_DISTANCE, 0.05)\n",
    "        graph_2 = create_graph_from_structure(atoms, CUT_OFF_DISTANCE, 0.05)\n",
    "        graph_original = create_graph_from_structure(atoms, CUT_OFF_DISTANCE, 0)\n",
    "        \n",
    "        # Add the label to each graph\n",
    "        graph_1.label = label\n",
    "        graph_2.label = label\n",
    "        graph_original.label = label\n",
    "        \n",
    "        # Append the graphs to the respective lists\n",
    "        graph_list_set_1.append(graph_1)\n",
    "        graph_list_set_2.append(graph_2)\n",
    "        graph_list_original.append(graph_original)\n",
    "        \n",
    "        print(f\"Graphs for {filename} created and added to the lists with label {label}.\")\n",
    "\n",
    "# Apply scaling to each graph list\n",
    "scale_graphs(graph_list_set_1)\n",
    "scale_graphs(graph_list_set_2)\n",
    "scale_graphs(graph_list_original)\n",
    "\n",
    "# Apply masking to each graph list\n",
    "mask_graphs(graph_list_set_1)\n",
    "mask_graphs(graph_list_set_2)\n",
    "\n",
    "print(\"Two graph sets created with different random perturbations, scaling, and masking applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph Generator: hard cutoff, no masking, perturbation or scaling\n",
    "# Graph generator: Converts supercell structures into undirected graphs based on a fixed cutoff distance.\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from scipy.spatial import distance_matrix\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Function to create a PyTorch Geometric Data object from an atomic structure\n",
    "def create_graph_from_structure(atoms, CUT_OFF_DISTANCE):\n",
    "    # Get the positions of the atoms\n",
    "    positions = atoms.get_positions()\n",
    "    \n",
    "    # Calculate the distance matrix between all atoms\n",
    "    dist_matrix = distance_matrix(positions, positions)\n",
    "    \n",
    "    # Collect the edges and the edge distances based on the cutoff distance\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "    num_atoms = len(positions)\n",
    "    for i in range(num_atoms):\n",
    "        for j in range(i + 1, num_atoms):  # Only check each pair once\n",
    "            if dist_matrix[i, j] <= CUT_OFF_DISTANCE:\n",
    "                # Add edges in both directions since it's an undirected graph\n",
    "                edge_index.append([i, j])\n",
    "                edge_index.append([j, i])\n",
    "                # Add the corresponding distance as the edge attribute\n",
    "                edge_attr.append(dist_matrix[i, j])\n",
    "                edge_attr.append(dist_matrix[i, j])\n",
    "\n",
    "    # Convert edge_index to a tensor if there are edges\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()  # Transpose and make contiguous\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float).unsqueeze(1)\n",
    "    else:\n",
    "        # Handle graphs with no edges\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "        edge_attr = torch.empty((0, 1), dtype=torch.float)\n",
    "    \n",
    "    # Create node features: atomic mass and atomic number\n",
    "    node_features = torch.tensor(\n",
    "        [[atom.mass, atom.number] for atom in atoms], dtype=torch.float\n",
    "    )  # Shape (num_atoms, 2)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr,\n",
    "    )\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Path to the supercell files folder\n",
    "supercell_folder = 'supercells'\n",
    "\n",
    "# List to store the graph objects\n",
    "graph_list = []\n",
    "\n",
    "# Define the cutoff distance (adjust as needed)\n",
    "CUT_OFF_DISTANCE = 5.0  # Example value; set according to your requirements\n",
    "\n",
    "# Iterate over all XYZ files in the supercells folder\n",
    "for filename in os.listdir(supercell_folder):\n",
    "    if filename.endswith('.xyz'):\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(supercell_folder, filename)\n",
    "        atoms = read(filepath)\n",
    "        \n",
    "        # Extract the number from the filename to use as a label\n",
    "        match = re.search(r'\\d+', filename)\n",
    "        if match:\n",
    "            label = int(match.group())\n",
    "        else:\n",
    "            label = None  # Handle cases where no number is found\n",
    "        \n",
    "        # Create the graph without any perturbations\n",
    "        graph = create_graph_from_structure(atoms, CUT_OFF_DISTANCE)\n",
    "        \n",
    "        # Add the label to the graph\n",
    "        graph.label = label\n",
    "        \n",
    "        # Append the graph to the list\n",
    "        graph_list.append(graph)\n",
    "        \n",
    "        print(f\"Graph for {filename} created and added to the list with label {label}.\")\n",
    "\n",
    "print(\"Graph generation complete. All graphs are connected using the hard cutoff distance without perturbations, masking, or scaling.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the average number of nodes and edges in a list of graphs\n",
    "def calculate_average_nodes_edges(graph_list):\n",
    "    total_nodes = 0\n",
    "    total_edges = 0\n",
    "    num_graphs = len(graph_list)\n",
    "    \n",
    "    # Loop through each graph in the list\n",
    "    for graph in graph_list:\n",
    "        num_nodes = graph.x.shape[0]  # Number of nodes (atoms)\n",
    "        num_edges = graph.edge_index.shape[1] // 2  # Number of edges (since it's undirected, divide by 2)\n",
    "        \n",
    "        total_nodes += num_nodes\n",
    "        total_edges += num_edges\n",
    "    \n",
    "    # Calculate averages\n",
    "    average_nodes = total_nodes / num_graphs if num_graphs > 0 else 0\n",
    "    average_edges = total_edges / num_graphs if num_graphs > 0 else 0\n",
    "    \n",
    "    return average_nodes, average_edges\n",
    "\n",
    "# Function to check if every node is connected to at least one edge in each graph\n",
    "def check_node_connections(graph_list):\n",
    "    graphs_with_isolated_nodes = []\n",
    "    \n",
    "    for graph_idx, graph in enumerate(graph_list):\n",
    "        num_nodes = graph.x.shape[0]  # Number of nodes (atoms)\n",
    "        \n",
    "        # Extract the edge index tensor (shape [2, num_edges])\n",
    "        edge_index = graph.edge_index\n",
    "        \n",
    "        # Create a set to track nodes that have at least one connection\n",
    "        connected_nodes = set(edge_index[0].tolist()) | set(edge_index[1].tolist())  # Combine both directions\n",
    "        \n",
    "        # Check if all nodes are connected\n",
    "        isolated_nodes = [node for node in range(num_nodes) if node not in connected_nodes]\n",
    "        \n",
    "        if isolated_nodes:\n",
    "            graphs_with_isolated_nodes.append((graph_idx, isolated_nodes))\n",
    "    \n",
    "    return graphs_with_isolated_nodes\n",
    "\n",
    "# Calculate the average number of nodes and edges\n",
    "average_nodes, average_edges = calculate_average_nodes_edges(graph_list)\n",
    "\n",
    "# Output the average results\n",
    "print(f\"Average number of nodes per graph: {average_nodes}\")\n",
    "print(f\"Average number of edges per graph: {average_edges}\")\n",
    "\n",
    "# Check for graphs with isolated nodes\n",
    "graphs_with_isolated_nodes = check_node_connections(graph_list)\n",
    "\n",
    "if graphs_with_isolated_nodes:\n",
    "    print(f\"Graphs with isolated nodes (graph index, isolated node indices): {graphs_with_isolated_nodes}\")\n",
    "    print(f\"Number of graphs with isolated nodes: {len(graphs_with_isolated_nodes)}\")\n",
    "else:\n",
    "    print(\"All graphs have every node connected with at least one edge.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list_set_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through graph_list_set_1 and print the edge attributes for each graph\n",
    "for i, graph in enumerate(graph_list_set_1):\n",
    "    print(f\"Graph {i + 1}:\")\n",
    "    \n",
    "    # Check if there are edge attributes\n",
    "    edge_attributes = graph.edge_attr.numpy()  # Convert to numpy array for easier printing\n",
    "    print(edge_attributes)\n",
    "    \n",
    "    print(\"-\" * 40)  # Separator for readability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
