{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Generator: takes two folders of supercells (each of a different supercell size) to create 4 graph lists (2 unperturbed and 2 perturbed)\n",
    "# Representation: next_nearest edges - scalar Cartesian attributes, nearest hyperedges - scalar attributes, \n",
    "# relative unit cell position node features - vector Cartesian features, cross supercell boundary connections\n",
    "# Note: this code takes two different folders generated using 2) containing the same materials but with different supercell sizes\n",
    "# Naming: the graphs are saved in three lists ('graph_list_unperturbed_1.pt','graph_list_set_1.pt','graph_list_set_2.pt')\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from ase.io import read\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Defines the two supercell sizes used for creating the two perturbations of each material's graph\n",
    "SUPERCELL_SIZE_1 = 3\n",
    "SUPERCELL_SIZE_2 = 4\n",
    "\n",
    "# Paths to the supercell files folders\n",
    "SUPERCELL_FOLDER_1 = 'Supercells/2DMatpedia Sublattices 3x3'\n",
    "SUPERCELL_FOLDER_2 = 'Supercells/2DMatpedia Sublattices 4x4'\n",
    "\n",
    "# Folder that the three lists of graphs will be saved to\n",
    "OUTPUT_FOLDER = 'Graphs/2DMatpedia Sublattices'\n",
    "\n",
    "# Define the tolerance delta for nearest neighbors in Angstroms\n",
    "DELTA = 0.1\n",
    "\n",
    "# Define the perturbation size in Angtroms\n",
    "PERTURBATION_SIZE = 0.05\n",
    "\n",
    "# ensures output folder is made\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# 1. Function to compute separate nearest and next-nearest neighbor edge connections\n",
    "def compute_nn_nnn_edge_index(atoms, delta):\n",
    "    \"\"\"\n",
    "    Returns two edge_index tensors:\n",
    "      - edge_index_nn: containing only nearest-neighbor edges\n",
    "      - edge_index_full: containing nearest- + next-nearest neighbors\n",
    "    \"\"\"\n",
    "    positions = atoms.get_positions()\n",
    "    num_atoms = len(positions)\n",
    "\n",
    "    # Compute distance matrix considering PBCs\n",
    "    dist_matrix = atoms.get_all_distances(mic=True)\n",
    "\n",
    "    # Sets for edges\n",
    "    edge_index_nn_set = set()\n",
    "    edge_index_full_set = set()\n",
    "\n",
    "    # For each node, find its nearest neighbors and next-nearest neighbors\n",
    "    for i in range(num_atoms):\n",
    "        # Exclude self-distance by setting diagonal to infinity\n",
    "        dist_matrix[i, i] = np.inf\n",
    "\n",
    "        # Get distances and sort them along with indices\n",
    "        distances = dist_matrix[i]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        sorted_distances = distances[sorted_indices]\n",
    "\n",
    "        # Nearest neighbor distance\n",
    "        d1 = sorted_distances[0]\n",
    "        nn_cutoff = d1 + delta\n",
    "\n",
    "        # Indices of nearest neighbors within d1 + delta\n",
    "        nn_indices = sorted_indices[sorted_distances <= nn_cutoff]\n",
    "\n",
    "        # Add edges for nearest neighbors to both sets\n",
    "        for j in nn_indices:\n",
    "            edge_index_nn_set.add((i, j))\n",
    "            edge_index_full_set.add((i, j))\n",
    "\n",
    "        # Exclude nearest neighbors for next-nearest neighbor determination\n",
    "        remaining_indices = sorted_indices[sorted_distances > nn_cutoff]\n",
    "        remaining_distances = sorted_distances[sorted_distances > nn_cutoff]\n",
    "\n",
    "        if len(remaining_distances) > 0:\n",
    "            # Next-nearest neighbor distance\n",
    "            d2 = remaining_distances[0]\n",
    "            nnn_cutoff = d2 + delta\n",
    "\n",
    "            # Indices of next-nearest neighbors within d2 + delta\n",
    "            nnn_indices = remaining_indices[remaining_distances <= nnn_cutoff]\n",
    "\n",
    "            # Add edges only to the 'full' set\n",
    "            for j in nnn_indices:\n",
    "                edge_index_full_set.add((i, j))\n",
    "\n",
    "    # Convert sets to tensors\n",
    "    def set_to_undirected_tensor(edge_set):\n",
    "        if not edge_set:\n",
    "            # Handle no edges\n",
    "            return torch.empty((2, 0), dtype=torch.long)\n",
    "        edge_index = torch.tensor(list(edge_set), dtype=torch.long).t().contiguous()\n",
    "        # Make undirected by adding reverse edges\n",
    "        edge_index_rev = edge_index.flip(0)\n",
    "        edge_index = torch.cat([edge_index, edge_index_rev], dim=1)\n",
    "        return edge_index\n",
    "\n",
    "    edge_index_nn = set_to_undirected_tensor(edge_index_nn_set)\n",
    "    edge_index_full = set_to_undirected_tensor(edge_index_full_set)\n",
    "\n",
    "    return edge_index_nn, edge_index_full\n",
    "\n",
    "# 2. Function to compute edge attributes as scalar distances between atoms (for a given edge_index)\n",
    "def compute_edge_attr(atoms, edge_index):\n",
    "    row, col = edge_index\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "    # Compute displacement vectors considering PBCs\n",
    "    delta_scaled = scaled_positions[row.numpy()] - scaled_positions[col.numpy()]\n",
    "    delta_scaled -= np.round(delta_scaled)\n",
    "    displacement_vectors = delta_scaled @ cell\n",
    "    edge_distances = np.linalg.norm(displacement_vectors, axis=1)\n",
    "    edge_attr = torch.tensor(edge_distances, dtype=torch.float).unsqueeze(1)\n",
    "    return edge_attr\n",
    "\n",
    "# 3. Function to compute node features as relative cartesian positions within each unit cell\n",
    "def compute_node_features(atoms, SUPERCELL_SIZE):\n",
    "    num_atoms = len(atoms)\n",
    "    N = SUPERCELL_SIZE\n",
    "    total_unit_cells = N * N  # For a 2D lattice\n",
    "\n",
    "    # Compute the number of atoms per unit cell\n",
    "    atoms_per_unit_cell = num_atoms // total_unit_cells\n",
    "\n",
    "    # Check for consistency\n",
    "    if atoms_per_unit_cell * total_unit_cells != num_atoms:\n",
    "        raise ValueError(\n",
    "            \"Number of atoms per unit cell is not consistent with \"\n",
    "            \"total atoms and supercell dimensions.\"\n",
    "        )\n",
    "\n",
    "    # Group atoms by unit cell based on their order in the .xyz file\n",
    "    unit_cell_indices = []\n",
    "    for i in range(0, num_atoms, atoms_per_unit_cell):\n",
    "        group = list(range(i, i + atoms_per_unit_cell))\n",
    "        unit_cell_indices.append(group)\n",
    "\n",
    "    # Compute relative positions\n",
    "    positions = atoms.get_positions()\n",
    "    relative_positions = np.zeros_like(positions)\n",
    "\n",
    "    for group in unit_cell_indices:\n",
    "        indices = group\n",
    "        positions_in_cell = positions[indices]\n",
    "        reference_position = positions_in_cell[0]  # First atom in the unit cell\n",
    "        relative_positions_in_cell = positions_in_cell - reference_position\n",
    "        relative_positions[indices] = relative_positions_in_cell\n",
    "\n",
    "    # Create node features as torch tensor\n",
    "    node_features = torch.tensor(relative_positions, dtype=torch.float)\n",
    "    return node_features\n",
    "\n",
    "# 4. Function to compute hyperedges using only nearest-neighbor edge connections\n",
    "def compute_hyperedges(edge_index_nn, num_nodes):\n",
    "    \"\"\"\n",
    "    Computes hyperedges from a given edge_index tensor (intended for NN edges only).\n",
    "    Hyperedges are triplets [i, j, k] where j is a common neighbor of i and k.\n",
    "    \"\"\"\n",
    "    row, col = edge_index_nn\n",
    "    # Build adjacency list from nearest-neighbor edges only\n",
    "    adj_list = [[] for _ in range(num_nodes)]\n",
    "    for idx in range(edge_index_nn.size(1)):\n",
    "        src = row[idx].item()\n",
    "        tgt = col[idx].item()\n",
    "        adj_list[src].append(tgt)\n",
    "\n",
    "    # Remove duplicates in adjacency lists\n",
    "    for neighbors in adj_list:\n",
    "        neighbors[:] = list(set(neighbors))\n",
    "\n",
    "    # Create hyperedges\n",
    "    hyperedges = []\n",
    "    for j in range(num_nodes):\n",
    "        neighbors = adj_list[j]\n",
    "        # For all pairs of neighbors of node j\n",
    "        for idx1 in range(len(neighbors)):\n",
    "            for idx2 in range(idx1 + 1, len(neighbors)):\n",
    "                i = neighbors[idx1]\n",
    "                k = neighbors[idx2]\n",
    "                hyperedges.append([i, j, k])\n",
    "\n",
    "    if len(hyperedges) > 0:\n",
    "        hyperedge_index = torch.tensor(hyperedges, dtype=torch.long).t().contiguous()  # [3, num_hyperedges]\n",
    "    else:\n",
    "        hyperedge_index = torch.empty((3, 0), dtype=torch.long)\n",
    "\n",
    "    return hyperedge_index\n",
    "\n",
    "# 5. Function to compute hyperedge attributes as angle between two edges from a given hyperedge index\n",
    "def compute_hyperedge_attr(atoms, hyperedge_index):\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "    scaled_positions = atoms.get_scaled_positions()\n",
    "    num_hyperedges = hyperedge_index.size(1)\n",
    "    hyperedge_attr = []\n",
    "\n",
    "    for idx in range(num_hyperedges):\n",
    "        i = hyperedge_index[0, idx].item()\n",
    "        j = hyperedge_index[1, idx].item()\n",
    "        k = hyperedge_index[2, idx].item()\n",
    "\n",
    "        # Scaled positions\n",
    "        pos_i = scaled_positions[i]\n",
    "        pos_j = scaled_positions[j]\n",
    "        pos_k = scaled_positions[k]\n",
    "\n",
    "        # Displacement vectors considering PBCs\n",
    "        delta_ji_scaled = pos_i - pos_j\n",
    "        delta_ji_scaled -= np.round(delta_ji_scaled)\n",
    "        d_ji = delta_ji_scaled @ cell\n",
    "\n",
    "        delta_jk_scaled = pos_k - pos_j\n",
    "        delta_jk_scaled -= np.round(delta_jk_scaled)\n",
    "        d_jk = delta_jk_scaled @ cell\n",
    "\n",
    "        # Compute angle between d_ji and d_jk\n",
    "        cos_theta = np.dot(d_ji, d_jk) / (np.linalg.norm(d_ji) * np.linalg.norm(d_jk) + 1e-8)\n",
    "        angle = np.arccos(np.clip(cos_theta, -1.0, 1.0))  # Angle in radians\n",
    "\n",
    "        hyperedge_attr.append([angle])\n",
    "\n",
    "    hyperedge_attr = torch.tensor(hyperedge_attr, dtype=torch.float)  # [num_hyperedges, 1]\n",
    "    return hyperedge_attr\n",
    "\n",
    "# 6. Function to create a PyTorch Geometric Data object from an atomic structure\n",
    "def create_graph_from_structure(atoms, delta, SUPERCELL_SIZE):\n",
    "    \"\"\"\n",
    "    - edge_index: contains nearest + next-nearest neighbors\n",
    "    - hyperedges: computed only from nearest-neighbor edges\n",
    "    \"\"\"\n",
    "    num_atoms = len(atoms)\n",
    "\n",
    "    # 1. Compute separate NN and full (NN + NNN) edge indices\n",
    "    edge_index_nn, edge_index_full = compute_nn_nnn_edge_index(atoms, delta)\n",
    "\n",
    "    # 2. Compute edge attributes for the full connectivity\n",
    "    edge_attr_full = compute_edge_attr(atoms, edge_index_full)\n",
    "\n",
    "    # 3. Compute node features\n",
    "    node_features = compute_node_features(atoms, SUPERCELL_SIZE)\n",
    "\n",
    "    # 4. Compute hyperedges using only nearest-neighbor edges\n",
    "    hyperedge_index = compute_hyperedges(edge_index_nn, num_atoms)\n",
    "\n",
    "    # 5. Compute hyperedge attributes\n",
    "    hyperedge_attr = compute_hyperedge_attr(atoms, hyperedge_index)\n",
    "\n",
    "    # Create a PyTorch Geometric Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index_full,    # Full connectivity (NN + NNN)\n",
    "        edge_attr=edge_attr_full,      # Attributes for full edges\n",
    "        hyperedge_index=hyperedge_index,\n",
    "        hyperedge_attr=hyperedge_attr,\n",
    "    )\n",
    "\n",
    "    graph.supercell_size = SUPERCELL_SIZE  # Store supercell size in graph\n",
    "\n",
    "    return graph\n",
    "\n",
    "# 7. Apply perturbations to a list of graphs as a random movement of each atom in each Cartesian axis\n",
    "def perturb_graphs(graph_list, atoms_list, perturbation_size, delta):\n",
    "    \"\"\"\n",
    "    Note: Here, we keep the same connectivity (edge_index) as the original\n",
    "    graphs. If you want to recompute the connectivity after perturbation,\n",
    "    you'll need to call `create_graph_from_structure` again.\n",
    "    \"\"\"\n",
    "    perturbed_graph_list = []\n",
    "    for graph, atoms in zip(graph_list, atoms_list):\n",
    "        # Clone the graph to avoid modifying the original\n",
    "        perturbed_graph = graph.clone()\n",
    "\n",
    "        # Get the positions of the atoms from the atoms object\n",
    "        positions = atoms.get_positions().copy()\n",
    "\n",
    "        # Apply random perturbation to the positions\n",
    "        if perturbation_size > 0:\n",
    "            perturbation = np.random.uniform(-perturbation_size, perturbation_size, positions.shape)\n",
    "            positions += perturbation  # Perturb the atomic positions\n",
    "\n",
    "        # Update atoms object with perturbed positions\n",
    "        perturbed_atoms = atoms.copy()\n",
    "        perturbed_atoms.set_positions(positions)\n",
    "        perturbed_atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # The connectivity is not recomputed here; we reuse graph.edge_index\n",
    "        edge_index_full = graph.edge_index\n",
    "        perturbed_edge_attr = compute_edge_attr(perturbed_atoms, edge_index_full)\n",
    "        perturbed_graph.edge_attr = perturbed_edge_attr\n",
    "\n",
    "        # Recompute node features based on perturbed positions\n",
    "        perturbed_node_features = compute_node_features(perturbed_atoms, graph.supercell_size)\n",
    "        perturbed_graph.x = perturbed_node_features\n",
    "\n",
    "        # Recompute hyperedge attributes\n",
    "        hyperedge_index = graph.hyperedge_index\n",
    "        perturbed_hyperedge_attr = compute_hyperedge_attr(perturbed_atoms, hyperedge_index)\n",
    "        perturbed_graph.hyperedge_attr = perturbed_hyperedge_attr\n",
    "\n",
    "        perturbed_graph_list.append(perturbed_graph)\n",
    "\n",
    "    return perturbed_graph_list\n",
    "\n",
    "\n",
    "# 8. Read graphs and atoms from a folder\n",
    "def read_graphs_from_folder(folder_path, delta, SUPERCELL_SIZE):\n",
    "    graph_list = []\n",
    "    atoms_list = []\n",
    "    \n",
    "    # Function to extract numeric and text parts for sorting\n",
    "    def natural_sort_key(filename):\n",
    "        return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', filename)]\n",
    "\n",
    "    # Apply natural sorting\n",
    "    filenames = sorted(\n",
    "        [f for f in os.listdir(folder_path) if f.endswith('.xyz')],\n",
    "        key=natural_sort_key\n",
    "    )\n",
    "    \n",
    "    for filename in filenames:\n",
    "        # Read the structure file\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        atoms = read(filepath)\n",
    "        atoms.pbc = [True, True, False]  # Ensure PBCs are enabled\n",
    "\n",
    "        # Remove file extension for cleaner parsing\n",
    "        filename_no_ext = os.path.splitext(filename)[0]\n",
    "\n",
    "        # Use a regex to capture the numeric ID and element\n",
    "        # This pattern expects something like ..._1234_Ta (or similar) before .xyz\n",
    "        match = re.match(r'^.*?(\\d+)_(\\w+)$', filename_no_ext)\n",
    "        if match:\n",
    "            id_part = match.group(1)\n",
    "            element_part = match.group(2)\n",
    "            label = f\"{id_part}_{element_part}\"\n",
    "        else:\n",
    "            # Fallback if no match (can modify as needed)\n",
    "            label = filename_no_ext  \n",
    "\n",
    "        # Create graph with nearest + next-nearest edges\n",
    "        graph = create_graph_from_structure(atoms, delta, SUPERCELL_SIZE)\n",
    "        graph.label = label  # Store the combined label\n",
    "\n",
    "        graph_list.append(graph)\n",
    "        atoms_list.append(atoms)\n",
    "\n",
    "        print(f\"Graph for {filename} created with label {label}.\")\n",
    "\n",
    "    return graph_list, atoms_list\n",
    "\n",
    "# 9. Generates the graphs, perturbs them and stores them in 4 separate lists (2 unperturbed lists and their corresponding perturbed lists)\n",
    "\n",
    "# Read graphs and atoms from the 3x3 folder\n",
    "graph_list_unperturbed_1, atoms_list_unperturbed_1 = read_graphs_from_folder(\n",
    "    SUPERCELL_FOLDER_1, DELTA, SUPERCELL_SIZE_1\n",
    ")\n",
    "print(\"Unperturbed graph list for 3x3 supercells created.\")\n",
    "\n",
    "# Read graphs and atoms from the 4x4 folder\n",
    "graph_list_unperturbed_2, atoms_list_unperturbed_2 = read_graphs_from_folder(\n",
    "    SUPERCELL_FOLDER_2, DELTA, SUPERCELL_SIZE_2\n",
    ")\n",
    "print(\"Unperturbed graph list for 4x4 supercells created.\")\n",
    "\n",
    "# Perturb the unperturbed 3x3 graphs\n",
    "graph_list_set_1 = perturb_graphs(\n",
    "    graph_list_unperturbed_1, atoms_list_unperturbed_1, PERTURBATION_SIZE, DELTA\n",
    ")\n",
    "\n",
    "# Perturb the unperturbed 4x4 graphs\n",
    "graph_list_set_2 = perturb_graphs(\n",
    "    graph_list_unperturbed_2, atoms_list_unperturbed_2, PERTURBATION_SIZE, DELTA\n",
    ")\n",
    "\n",
    "print(\"Two perturbed graph lists created from 3x3 and 4x4 supercells respectively.\")\n",
    "\n",
    "# 1. Saves 3 of the graph lists (only 1 unperturbed list is saved which can be used to generate final embeddings)\n",
    "\n",
    "# Save unperturbed graph list 1\n",
    "torch.save(graph_list_unperturbed_1, f\"{OUTPUT_FOLDER}\\graph_list_unperturbed_1.pt\")\n",
    "\n",
    "# Save the first perturbed graph list (3x3)\n",
    "torch.save(graph_list_set_1, f\"{OUTPUT_FOLDER}\\graph_list_set_1.pt\")\n",
    "\n",
    "# Save the second perturbed graph list (4x4)\n",
    "torch.save(graph_list_set_2, f\"{OUTPUT_FOLDER}\\graph_list_set_2.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
