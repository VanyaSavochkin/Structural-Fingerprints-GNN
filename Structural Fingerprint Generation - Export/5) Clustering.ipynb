{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering: takes the final embeddings generated in 4) and clusters them using hdbscan. The clusters are then visualised\n",
    "# in 2D using UMAP and t-SNE (allows for separation of validation and training datasets)\n",
    "# Features lots of code cells each helping to analyse the quality of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decides which dimensionality reduction algorithm to use for making the plots\n",
    "DIMENSIONALITY_REDUCTION_ALGORITHM = 't-SNE' #'t-SNE', 'UMAP' or 'both'\n",
    "# Decides which split of the data to use for making the plots\n",
    "DATA_SPLIT = 'validation' #'training', 'validation' or 'full'\n",
    "\n",
    "# The supercell folder used to make the final embeddings. Used to visualise the structures of each material\n",
    "INPUT_FOLDER = 'Supercells/2DMatpedia Sublattices 3x3'\n",
    "\n",
    "# The name of your model used throughout the pipeline\n",
    "MODEL_NAME = 'Test'\n",
    "\n",
    "# Global parameter for the supercell size for graph visualisations. This should match your input folder and model\n",
    "SUPERCELL_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Loader: loads the final embeddings and labels generated in 4) and splits them into their training and validation sets\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "embeddings_path = f'Embeddings/embeddings_{MODEL_NAME}.pt'\n",
    "labels_path = f'Labels/labels_{MODEL_NAME}.pt'\n",
    "\n",
    "embeddings = torch.load(embeddings_path, map_location=torch.device('cpu')).numpy()\n",
    "labels = torch.load(labels_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Calculates training and validation set sizes\n",
    "NUM_TRAINING = int(len(embeddings) * 0.8)\n",
    "NUM_VALIDATE = len(embeddings) - NUM_TRAINING \n",
    "\n",
    "# Set random seed for reproducibility\n",
    "fixed_seed = 42\n",
    "np.random.seed(fixed_seed)\n",
    "indices = np.random.permutation(len(embeddings))\n",
    "\n",
    "shuffled_embeddings = [embeddings[i] for i in indices]\n",
    "shuffled_labels = [labels[i] for i in indices]\n",
    "\n",
    "training_embeddings = shuffled_embeddings[:NUM_TRAINING]\n",
    "training_labels = shuffled_labels[:NUM_TRAINING]\n",
    "validation_embeddings = shuffled_embeddings[NUM_TRAINING:]\n",
    "validation_labels = shuffled_labels[NUM_TRAINING:]\n",
    "\n",
    "training_embeddings = np.array(training_embeddings)\n",
    "validation_embeddings = np.array(validation_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering Workflow: takes the loaded embeddings and uses hdbscan to cluster them. Then, displays these clusters\n",
    "# in a 2D plot using dimensionality reduction algorithms (either t-SNE or UMAP)\n",
    "# Also provides some stats inlcuding average outlier score and numbers of clustered points\n",
    "# Naming: saves the clustering labels as 'clustered_labels.npy' and the plots as 't-SNE Clusters.png' and 'UMAP Clusters.png'\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import hdbscan\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import umap.umap_ as umap\n",
    "\n",
    "def hdbscan_clustering(data):\n",
    "    # Initialize and fit HDBSCAN\n",
    "    hdb = hdbscan.HDBSCAN(min_samples=3, min_cluster_size=4, prediction_data=True)\n",
    "    cluster_labels = hdb.fit_predict(data)\n",
    "    \n",
    "    # Retrieve outlier scores\n",
    "    outlier_scores = hdb.outlier_scores_\n",
    "    \n",
    "    return hdb, cluster_labels, outlier_scores\n",
    "\n",
    "def tsne_plot(data, cluster_labels):\n",
    "    tsne = TSNE(n_components=2, perplexity=20, random_state=42, init='pca')\n",
    "    data_tsne_2d = tsne.fit_transform(data)\n",
    "\n",
    "    np.save(\"data_tsne_2d.npy\", data_tsne_2d)\n",
    "\n",
    "    unique_labels = np.unique(cluster_labels)\n",
    "    background_points = (cluster_labels == -1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(data_tsne_2d[background_points, 0], data_tsne_2d[background_points, 1],\n",
    "                c='lightgray', s=10, alpha=0.5, label='Noise')\n",
    "    \n",
    "    plt.scatter(data_tsne_2d[~background_points, 0], data_tsne_2d[~background_points, 1],\n",
    "                c=cluster_labels[~background_points], cmap='tab20', s=10, alpha=0.7)\n",
    "    \n",
    "    # Annotate centroids for each cluster (excluding noise)\n",
    "    for label in unique_labels:\n",
    "        if label != -1:\n",
    "            label_points = data_tsne_2d[cluster_labels == label]\n",
    "            centroid = np.mean(label_points, axis=0)\n",
    "            plt.text(centroid[0], centroid[1], str(label), fontsize=8, fontweight='bold', \n",
    "                     color='black', ha='center', va='center')\n",
    "    \n",
    "    plt.title('t-SNE Visualization of HDBSCAN Clusters in 2D')\n",
    "    plt.xlabel('t-SNE 1')\n",
    "    plt.ylabel('t-SNE 2')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'Plots and Visualisations/Clustering Plots/t-SNE Clusters - {MODEL_NAME}.png')\n",
    "    plt.show()\n",
    "\n",
    "def umap_plot(data, cluster_labels):\n",
    "    umap_reducer = umap.UMAP(n_neighbors=20, n_components=2, min_dist=0.5, random_state=42, init='pca')\n",
    "    data_umap_2d = umap_reducer.fit_transform(data)\n",
    "\n",
    "    np.save(\"data_umap_2d.npy\", data_umap_2d)\n",
    "\n",
    "    unique_labels = np.unique(cluster_labels)\n",
    "    background_points = (cluster_labels == -1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(data_umap_2d[background_points, 0], data_umap_2d[background_points, 1],\n",
    "                c='lightgray', s=10, alpha=0.5, label='Noise')\n",
    "    \n",
    "    plt.scatter(data_umap_2d[~background_points, 0], data_umap_2d[~background_points, 1],\n",
    "                c=cluster_labels[~background_points], cmap='tab20', s=10, alpha=0.7)\n",
    "    \n",
    "    # Annotate centroids for each cluster (excluding noise)\n",
    "    for label in unique_labels:\n",
    "        if label != -1:\n",
    "            label_points = data_umap_2d[cluster_labels == label]\n",
    "            centroid = np.mean(label_points, axis=0)\n",
    "            plt.text(centroid[0], centroid[1], str(label), fontsize=8, fontweight='bold', \n",
    "                     color='black', ha='center', va='center')\n",
    "    \n",
    "    plt.title('UMAP Visualization of HDBSCAN Clusters in 2D')\n",
    "    plt.xlabel('UMAP 1')\n",
    "    plt.ylabel('UMAP 2')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'Plots and Visualisations/Clustering Plots/UMAP Clusters - {MODEL_NAME}.png')\n",
    "    plt.show()\n",
    "\n",
    "def save_clusters_with_labels(cluster_labels, embedding_labels, filename='clustered_labels.npy'):\n",
    "    combined_array = np.column_stack((embedding_labels, cluster_labels))\n",
    "    np.save(filename, combined_array)\n",
    "    print(f\"Clusters and labels saved to {filename}\")\n",
    "\n",
    "def full_clustering_workflow(data, embedding_labels, dimensionality_reduction='both'):\n",
    "    print(\"Clustering with HDBSCAN...\")\n",
    "    hdb, cluster_labels, outlier_scores = hdbscan_clustering(data)\n",
    "    \n",
    "    # Save the combined result of embedding labels + cluster labels\n",
    "    save_clusters_with_labels(cluster_labels, embedding_labels)\n",
    "\n",
    "    # Depending on user choice, run t-SNE and/or UMAP\n",
    "    if dimensionality_reduction in ['t-SNE', 'both']:\n",
    "        print(\"Visualizing with t-SNE...\")\n",
    "        tsne_plot(data, cluster_labels)\n",
    "    if dimensionality_reduction in ['UMAP', 'both']:\n",
    "        print(\"Visualizing with UMAP...\")\n",
    "        umap_plot(data, cluster_labels)\n",
    "    \n",
    "    # Masks\n",
    "    clustered_mask = (cluster_labels != -1)\n",
    "    noise_mask = (cluster_labels == -1)\n",
    "    \n",
    "    print(\"Total number of data points:\", len(cluster_labels))\n",
    "    print(\"Number of clustered points:\", np.sum(clustered_mask))\n",
    "    print(\"Number of noise points:\", np.sum(noise_mask))\n",
    "    \n",
    "    # Filter out NaN values from outlier scores\n",
    "    valid_indices = ~np.isnan(outlier_scores)\n",
    "    clustered_mask = clustered_mask & valid_indices\n",
    "    noise_mask = noise_mask & valid_indices\n",
    "    \n",
    "    clustered_outlier_scores = outlier_scores[clustered_mask]\n",
    "    noise_outlier_scores = outlier_scores[noise_mask]\n",
    "    \n",
    "    # Print average outlier scores\n",
    "    if clustered_outlier_scores.size > 0:\n",
    "        avg_clustered_outlier_score = np.mean(clustered_outlier_scores)\n",
    "        print(f\"Average Outlier Score for Clustered Points: {avg_clustered_outlier_score:.4f}\")\n",
    "    else:\n",
    "        print(\"No valid outlier scores for clustered points.\")\n",
    "    \n",
    "    if noise_outlier_scores.size > 0:\n",
    "        avg_noise_outlier_score = np.mean(noise_outlier_scores)\n",
    "        print(f\"Average Outlier Score for Noise Points: {avg_noise_outlier_score:.4f}\")\n",
    "    else:\n",
    "        print(\"No valid outlier scores for noise points.\")\n",
    "    \n",
    "    return hdb, cluster_labels\n",
    "\n",
    "def load_clusters_with_labels(filename='clustered_labels.npy'):\n",
    "    loaded_array = np.load(filename)\n",
    "    embedding_labels = loaded_array[:, 0]  \n",
    "    cluster_labels = loaded_array[:, 1]    \n",
    "    print(f\"Clusters and labels loaded from {filename}\")\n",
    "    return embedding_labels, cluster_labels\n",
    "\n",
    "\n",
    "# Decide which split to use based on DATA_SPLIT\n",
    "if DATA_SPLIT == 'training':\n",
    "    data_for_clustering = training_embeddings\n",
    "    labels_for_clustering = training_labels\n",
    "elif DATA_SPLIT == 'validation':\n",
    "    data_for_clustering = validation_embeddings\n",
    "    labels_for_clustering = validation_labels\n",
    "else:\n",
    "    # 'full' or any other unexpected value uses the entire dataset\n",
    "    data_for_clustering = embeddings\n",
    "    labels_for_clustering = labels\n",
    "\n",
    "# Now run the clustering workflow using the user's choice of dimensionality reduction\n",
    "hdb, cluster_labels = full_clustering_workflow(\n",
    "    data_for_clustering,\n",
    "    labels_for_clustering,\n",
    "    dimensionality_reduction=DIMENSIONALITY_REDUCTION_ALGORITHM\n",
    ")\n",
    "\n",
    "# Optionally load the saved cluster labels + embedding labels\n",
    "embedding_labels, loaded_cluster_labels = load_clusters_with_labels('clustered_labels.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D visualisation plot: Average bond length\n",
    "# Computes the average magnitude of the lattice a and b vectors and plots them as a colobar on the original t-SNE axes\n",
    "# Note: only works with t-SNE\n",
    "\n",
    "import os\n",
    "from ase.io import read\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "lattice_lengths = np.zeros(len(validation_labels))\n",
    "\n",
    "for i, label in enumerate(validation_labels):\n",
    "    file_path = os.path.join(INPUT_FOLDER, f\"supercell_2dm-{label}.xyz\")\n",
    "    atoms = read(file_path)\n",
    "    \n",
    "    a_val, b_val, c_val, alpha, beta, gamma = atoms.cell.cellpar()\n",
    "    \n",
    "    a_scaled = a_val / SUPERCELL_SIZE\n",
    "    b_scaled = b_val / SUPERCELL_SIZE\n",
    "    c_scaled = c_val / SUPERCELL_SIZE\n",
    "\n",
    "    avg_lattice_length = 0.5 * (a_scaled + b_scaled)\n",
    "    \n",
    "    lattice_lengths[i] = avg_lattice_length\n",
    "\n",
    "\n",
    "def plot_tsne_by_lattice_length(coords_2d, lattice_lengths,\n",
    "                               cmap='turbo',\n",
    "                               title='2D Projection'):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    #norm=mcolors.Normalize(vmin=0, vmax=40)\n",
    "    #norm = mcolors.PowerNorm(gamma=0.5, vmin=0, vmax=40)\n",
    "    norm=mcolors.LogNorm(vmin=1, vmax=15)\n",
    "\n",
    "    plt.scatter(coords_2d[:, 0], coords_2d[:, 1],\n",
    "                c=lattice_lengths,\n",
    "                cmap=cmap,\n",
    "                norm=norm,\n",
    "                s=10)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Dim 1')\n",
    "    plt.ylabel('Dim 2')\n",
    "    plt.savefig(f\"Plots and Visualisations/Property Plots/Lattice Length/{MODEL_NAME}_lattice_length.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Load the saved 2D coords\n",
    "data_tsne_2d = np.load(\"data_tsne_2d.npy\")\n",
    "\n",
    "plot_tsne_by_lattice_length(data_tsne_2d, lattice_lengths, \n",
    "                      title=\"t-SNE colored by Average Lattice Vector Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D visualisation plot: Number of atoms in unit cell\n",
    "# Note: only works with t-SNE\n",
    "\n",
    "import os\n",
    "from ase.io import read\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "num_atoms_in_unitcell = np.zeros(len(validation_labels))\n",
    "\n",
    "for i, label in enumerate(validation_labels):\n",
    "    file_path = os.path.join(INPUT_FOLDER, f\"supercell_2dm-{label}.xyz\")\n",
    "    \n",
    "    atoms = read(file_path)\n",
    "    \n",
    "    num_atoms_in_unitcell[i] = len(atoms) // (SUPERCELL_SIZE**2)\n",
    "\n",
    "def plot_tsne_by_unitcell_atoms(coords_2d, num_atoms_in_unitcell,\n",
    "                               cmap='turbo',\n",
    "                               title='t-SNE colored by # of Atoms in Unit Cell'):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    norm = mcolors.LogNorm(vmin=1, vmax=num_atoms_in_unitcell.max()) \n",
    "    \n",
    "    plt.scatter(coords_2d[:, 0], coords_2d[:, 1],\n",
    "                c=num_atoms_in_unitcell,\n",
    "                cmap=cmap,\n",
    "                norm=norm,\n",
    "                s=10)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('t-SNE 1')\n",
    "    plt.ylabel('t-SNE 2')\n",
    "    plt.savefig(f\"Plots and Visualisations/Property Plots/Atoms in Unit Cell/{MODEL_NAME}_unitcell_atoms.png\")\n",
    "    plt.show()\n",
    "\n",
    "data_tsne_2d = np.load(\"data_tsne_2d.npy\")\n",
    "\n",
    "plot_tsne_by_unitcell_atoms(\n",
    "    data_tsne_2d, \n",
    "    num_atoms_in_unitcell,\n",
    "    title=\"t-SNE colored by # of Atoms in Single Unit Cell\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D visualisation plot: Lattice types (work in progress)\n",
    "# Note: only works with t-SNE\n",
    "\n",
    "import os\n",
    "from ase.io import read\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "# 1. Classification Function\n",
    "def classify_2D_lattice(a, b, angle_deg, tol=1e-1):\n",
    "    \"\"\"\n",
    "    Given the lengths a, b (the first two cell vectors) and the angle between them (in degrees),\n",
    "    return a string representing the 2D Bravais lattice type.\n",
    "    \n",
    "    Tolerances are used to handle floating-point rounding. You can tweak them as needed.\n",
    "    \"\"\"\n",
    "    same_lengths   = abs(a - b) < tol\n",
    "    angle_diff_90  = abs(angle_deg - 90)\n",
    "    angle_diff_120 = abs(angle_deg - 120)\n",
    "\n",
    "    if same_lengths and angle_diff_90 < 1.0:\n",
    "        return \"Square\"\n",
    "    elif not same_lengths and angle_diff_90 < 1.0:\n",
    "        return \"Rectangular\"\n",
    "    elif same_lengths and angle_diff_120 < 2.0:\n",
    "        return \"Hexagonal\"\n",
    "    else:\n",
    "        return \"Oblique\"\n",
    "\n",
    "# 2. Read Structures & Assign Lattice Types\n",
    "lattice_types = []\n",
    "\n",
    "for label in validation_labels:\n",
    "    file_path = os.path.join(INPUT_FOLDER, f\"supercell_2dm-{label}.xyz\")\n",
    "    atoms = read(file_path)\n",
    "    \n",
    "    a_val, b_val, c_val, alpha, beta, gamma = atoms.cell.cellpar()\n",
    "\n",
    "    a_scaled = a_val / SUPERCELL_SIZE\n",
    "    b_scaled = b_val / SUPERCELL_SIZE\n",
    "    c_scaled = c_val / SUPERCELL_SIZE\n",
    "\n",
    "    lat_type = classify_2D_lattice(a_scaled, b_scaled, gamma)\n",
    "    lattice_types.append(lat_type)\n",
    "\n",
    "lattice_types = np.array(lattice_types)\n",
    "\n",
    "\n",
    "# 3. Plot t-SNE by Lattice Type\n",
    "def plot_tsne_by_lattice_type(coords_2d, lattice_types, title='t-SNE Colored by 2D Lattice Type'):\n",
    "    \"\"\"\n",
    "    Create a scatter plot, coloring each point based on its 2D lattice type.\n",
    "    We'll create a discrete legend rather than a continuous colorbar.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    unique_types = np.unique(lattice_types)\n",
    "    \n",
    "    color_map = plt.get_cmap('tab10')\n",
    "    \n",
    "    for i, lat_type in enumerate(unique_types):\n",
    "        mask = (lattice_types == lat_type)\n",
    "        \n",
    "        plt.scatter(coords_2d[mask, 0],\n",
    "                    coords_2d[mask, 1],\n",
    "                    c=[color_map(i)], \n",
    "                    s=10,\n",
    "                    label=lat_type)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"t-SNE 1\")\n",
    "    plt.ylabel(\"t-SNE 2\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"Plots and Visualisations/Property Plots/Lattice Type/{MODEL_NAME}_lattice_types.png\")\n",
    "    plt.show()\n",
    "\n",
    "# 4. Load t-SNE coordinates & Plot\n",
    "data_tsne_2d = np.load(\"data_tsne_2d.npy\")\n",
    "plot_tsne_by_lattice_type(data_tsne_2d, lattice_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D visualisation plot: Aspect ratios\n",
    "# Note: only works with t-SNE\n",
    "\n",
    "import os\n",
    "from ase.io import read\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "aspect_ratios = np.zeros(len(validation_labels))\n",
    "\n",
    "for i, label in enumerate(validation_labels):\n",
    "    file_path = os.path.join(INPUT_FOLDER, f\"supercell_2dm-{label}.xyz\")\n",
    "    atoms = read(file_path)\n",
    "    \n",
    "    a_val, b_val, c_val, alpha, beta, gamma = atoms.cell.cellpar()\n",
    "    \n",
    "    a_scaled = a_val / SUPERCELL_SIZE\n",
    "    b_scaled = b_val / SUPERCELL_SIZE\n",
    "    \n",
    "    if b_scaled == 0:\n",
    "        ratio = 1.0\n",
    "    else:\n",
    "        ratio = max(a_scaled, b_scaled) / min(a_scaled, b_scaled)\n",
    "    \n",
    "    aspect_ratios[i] = ratio\n",
    "\n",
    "def plot_tsne_by_aspect_ratio(coords_2d, aspect_ratios,\n",
    "                              cmap='turbo',\n",
    "                              title='t-SNE colored by Aspect Ratio'):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    norm = mcolors.LogNorm(vmin=1, vmax=10)\n",
    "\n",
    "    plt.scatter(coords_2d[:, 0], coords_2d[:, 1],\n",
    "                c=aspect_ratios,\n",
    "                cmap=cmap,\n",
    "                norm=norm,\n",
    "                s=10)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('t-SNE 1')\n",
    "    plt.ylabel('t-SNE 2')\n",
    "    plt.savefig(f\"Plots and Visualisations/Property Plots/Aspect Ratio/{MODEL_NAME}_aspect_ratio.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Load the saved 2D t-SNE coords\n",
    "data_tsne_2d = np.load(\"data_tsne_2d.npy\")\n",
    "\n",
    "# Plot with aspect ratio\n",
    "plot_tsne_by_aspect_ratio(\n",
    "    data_tsne_2d, \n",
    "    aspect_ratios,\n",
    "    title=\"t-SNE colored by Lattice Aspect Ratio\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D visualisation plot: Buckling Heights\n",
    "# Note: only works with t-SNE\n",
    "\n",
    "import os\n",
    "from ase.io import read\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "buckling_heights = np.zeros(len(validation_labels))\n",
    "\n",
    "for i, label in enumerate(validation_labels):\n",
    "    file_path = os.path.join(INPUT_FOLDER, f\"supercell_2dm-{label}.xyz\")\n",
    "    atoms = read(file_path)\n",
    "    \n",
    "    z_coords = atoms.positions[:, 2]\n",
    "    \n",
    "    buckling_heights[i] = z_coords.max() - z_coords.min()\n",
    "\n",
    "def plot_tsne_by_buckling_height(coords_2d, buckling_heights,\n",
    "                                 cmap='viridis',\n",
    "                                 title='t-SNE colored by Buckling Height'):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    norm = mcolors.Normalize(vmin=0, vmax=10)\n",
    "\n",
    "    plt.scatter(coords_2d[:, 0], coords_2d[:, 1],\n",
    "                c=buckling_heights,\n",
    "                cmap=cmap,\n",
    "                norm=norm,\n",
    "                s=10)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('t-SNE 1')\n",
    "    plt.ylabel('t-SNE 2')\n",
    "    plt.savefig(f\"Plots and Visualisations/Property Plots/Buckling Height/{MODEL_NAME}_buckling_height.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Load your saved t-SNE coordinates\n",
    "data_tsne_2d = np.load(\"data_tsne_2d.npy\")\n",
    "\n",
    "# Plot using the computed buckling heights\n",
    "plot_tsne_by_buckling_height(data_tsne_2d, buckling_heights,\n",
    "                             title=\"t-SNE colored by Buckling Height (Z-Coords)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D visualisation plot: Average coordination number\n",
    "# Note: only works with t-SNE\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from ase.io import read\n",
    "\n",
    "# 1) Load the graph list from PyTorch Geometric\n",
    "graph_list_path = os.path.join('Graphs/sublattice_test', \"graph_list_unperturbed_1.pt\")\n",
    "graph_list = torch.load(graph_list_path)\n",
    "\n",
    "# 2) Build a dict: { graph_label : average_coordination_number }\n",
    "label_to_avgcoord = {}\n",
    "for data in graph_list:\n",
    "    # data.x.shape[0] = number of nodes (atoms)\n",
    "    num_nodes = data.x.shape[0]\n",
    "    # data.edge_index.shape[1] = number of edges (pairs)\n",
    "    num_edges = data.edge_index.shape[1]\n",
    "    \n",
    "    # Average coordination number = E / N\n",
    "    avg_cnum = num_edges / (num_nodes*2.0)\n",
    "    \n",
    "    # data.label is the label string, e.g. '1_F'\n",
    "    label_str = data.label\n",
    "    label_to_avgcoord[label_str] = avg_cnum\n",
    "\n",
    "# 3) For each structure in validation_labels, retrieve the average CN\n",
    "coordination_values = np.zeros(len(validation_labels))\n",
    "for i, lbl in enumerate(validation_labels):\n",
    "    coordination_values[i] = label_to_avgcoord[lbl]\n",
    "\n",
    "# 4) Plot the t-SNE embedding, colored by average coordination number\n",
    "def plot_tsne_by_coordination(coords_2d, coordination_vals,\n",
    "                              cmap='viridis',\n",
    "                              title='t-SNE colored by Avg Coordination Number'):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "\n",
    "    norm = mcolors.LogNorm(vmin=1, vmax=max(coordination_values)) \n",
    "    \n",
    "    plt.scatter(coords_2d[:, 0], coords_2d[:, 1],\n",
    "                c=coordination_vals,\n",
    "                cmap=cmap,\n",
    "                norm=norm,\n",
    "                s=10)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('t-SNE 1')\n",
    "    plt.ylabel('t-SNE 2')\n",
    "    \n",
    "\n",
    "    plt.savefig(f\"Plots and Visualisations/Property Plots/Coordination Number/{MODEL_NAME}_coordination_number.png\")\n",
    "    plt.show()\n",
    "\n",
    "data_tsne_2d = np.load(\"data_tsne_2d.npy\")\n",
    "\n",
    "plot_tsne_by_coordination(\n",
    "    data_tsne_2d,\n",
    "    coordination_values,\n",
    "    title=\"t-SNE colored by Avg Coordination Number\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Finder: returns the cluster number of a given material and then views the material in an interactive window\n",
    "\n",
    "from ase.io import read\n",
    "from ase.visualize import view\n",
    "\n",
    "# Material you want to find\n",
    "MATERIAL_LABEL = '1_Ru'\n",
    "\n",
    "# Find the indices where embedding_labels match the MATERIAL_LABEL\n",
    "indices = np.where(embedding_labels == MATERIAL_LABEL)[0]\n",
    "\n",
    "if len(indices) == 0:\n",
    "    print(f\"Material with label {MATERIAL_LABEL} is not found in the dataset.\")\n",
    "else:\n",
    "    index = indices[0]  # Assuming each material label is unique\n",
    "    cluster = cluster_labels[index]\n",
    "    if cluster == -1:\n",
    "        print(f\"Material with label {MATERIAL_LABEL} is considered noise (not assigned to any cluster).\")\n",
    "    else:\n",
    "        print(f\"Material with label {MATERIAL_LABEL} is in cluster {int(cluster)}.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Read the structure from the XYZ file\n",
    "atoms = read(f'{INPUT_FOLDER}\\supercell_2dm-{MATERIAL_LABEL}.xyz')\n",
    "# View the structure (opens an interactive window)\n",
    "view(atoms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the cluster you want to analyse and returns the labels of the materials within it\n",
    "\n",
    "CLUSTER_NUM = 32\n",
    "cluster = embedding_labels[cluster_labels==CLUSTER_NUM]\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Analyser: Provides the properties of and visualizes every node in the specified cluster\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from ase.io import read\n",
    "from torch_geometric.data import Data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Define the tolerance delta for nearest neighbors\n",
    "delta = 0.1  # Adjust as needed\n",
    "\n",
    "# Define the folder to save plots\n",
    "plot_folder = 'Plots and Visualisations\\Temp\\Cluster Node Plots'\n",
    "\n",
    "# Ensure the plot folder exists (and clear it)\n",
    "if not os.path.exists(plot_folder):\n",
    "    os.makedirs(plot_folder)\n",
    "else:\n",
    "    for filename in os.listdir(plot_folder):\n",
    "        file_path = os.path.join(plot_folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # Remove the file\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)  # Remove the directory\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "\n",
    "# 1. Compute edges (nearest and next-nearest neighbors) with PBC\n",
    "def compute_edge_index(atoms, delta):\n",
    "    positions = atoms.get_positions()\n",
    "    num_atoms = len(positions)\n",
    "\n",
    "    # Compute distance matrix considering PBCs\n",
    "    dist_matrix = atoms.get_all_distances(mic=True)\n",
    "    edge_index = set()\n",
    "\n",
    "    for i in range(num_atoms):\n",
    "        dist_matrix[i, i] = np.inf\n",
    "\n",
    "        distances = dist_matrix[i]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        sorted_distances = distances[sorted_indices]\n",
    "\n",
    "        # Nearest-neighbor cutoff\n",
    "        d1 = sorted_distances[0]\n",
    "        nn_cutoff = d1 + delta\n",
    "        nn_indices = sorted_indices[sorted_distances <= nn_cutoff]\n",
    "        for j in nn_indices:\n",
    "            edge_index.add((j, i))\n",
    "\n",
    "        # Next-nearest neighbor\n",
    "        remaining_indices = sorted_indices[sorted_distances > nn_cutoff]\n",
    "        remaining_distances = sorted_distances[sorted_distances > nn_cutoff]\n",
    "        if len(remaining_distances) > 0:\n",
    "            d2 = remaining_distances[0]\n",
    "            nnn_cutoff = d2 + delta\n",
    "            nnn_indices = remaining_indices[remaining_distances <= nnn_cutoff]\n",
    "            for j in nnn_indices:\n",
    "                edge_index.add((j, i))\n",
    "\n",
    "    # Convert edge_index to tensor\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(list(edge_index), dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "# 2. Create a PyTorch Geometric Data object (no edge_attr used)\n",
    "def create_graph_from_structure(atoms, delta):\n",
    "    edge_index = compute_edge_index(atoms, delta)\n",
    "    \n",
    "    # No node features for now\n",
    "    num_nodes = len(atoms)\n",
    "    node_features = torch.empty((num_nodes, 0), dtype=torch.float)\n",
    "\n",
    "    # Build the Data object\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index\n",
    "        # Note: no edge_attr here\n",
    "    )\n",
    "\n",
    "    return graph\n",
    "\n",
    "# 3. Plotting function\n",
    "def plot_graph(atoms, graph, margin=0.1, tolerance=0.1, y_size=6, filename=None):\n",
    "    \"\"\"\n",
    "    Plots the graph of an atomic structure with consistent y-direction size.\n",
    "    \"\"\"\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "\n",
    "    x = positions[:, 0]\n",
    "    y = positions[:, 1]\n",
    "    z = positions[:, 2]\n",
    "\n",
    "    # Group z positions into layers using the tolerance\n",
    "    z_grouped = np.round(z / tolerance) * tolerance\n",
    "    z_unique, indices = np.unique(z_grouped, return_inverse=True)\n",
    "    N_layers = len(z_unique)\n",
    "\n",
    "    # Define colormap\n",
    "    cmap = plt.cm.get_cmap('viridis', N_layers)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Shift supercell boundary by 0.5*c\n",
    "    c_shift = 0.5 * cell[2]\n",
    "    corner_positions = np.array([\n",
    "        [0, 0, 0],\n",
    "        cell[0],\n",
    "        cell[0] + cell[1],\n",
    "        cell[1],\n",
    "        [0, 0, 0]\n",
    "    ]) + c_shift\n",
    "\n",
    "    # Determine plot boundaries\n",
    "    x_min, x_max = corner_positions[:, 0].min(), corner_positions[:, 0].max()\n",
    "    y_min, y_max = corner_positions[:, 1].min(), corner_positions[:, 1].max()\n",
    "\n",
    "    x_margin = (x_max - x_min) * margin\n",
    "    y_margin = (y_max - y_min) * margin\n",
    "\n",
    "    x_min -= x_margin\n",
    "    x_max += x_margin\n",
    "    y_min -= y_margin\n",
    "    y_max += y_margin\n",
    "\n",
    "    # Keep y-axis size consistent\n",
    "    y_range = y_max - y_min\n",
    "    x_range = x_max - x_min\n",
    "    aspect_ratio = x_range / y_range\n",
    "    fig.set_size_inches(y_size * aspect_ratio, y_size)\n",
    "\n",
    "    # Plot boundary\n",
    "    ax.plot(corner_positions[:, 0], corner_positions[:, 1], 'k--', linewidth=1)\n",
    "    # Plot atoms\n",
    "    ax.scatter(x, y, c=indices, s=50, cmap=cmap, zorder=2)\n",
    "\n",
    "    # Build line segments for edges\n",
    "    lines = []\n",
    "    for idx in range(graph.edge_index.shape[1]):\n",
    "        i = graph.edge_index[0, idx].item()\n",
    "        j = graph.edge_index[1, idx].item()\n",
    "\n",
    "        pos_i = positions[i]\n",
    "        pos_j = positions[j]\n",
    "\n",
    "        # Consider minimal image convention for j\n",
    "        delta_scaled = atoms.get_scaled_positions()[j] - atoms.get_scaled_positions()[i]\n",
    "        delta_scaled -= np.round(delta_scaled)\n",
    "\n",
    "        # Adjust pos_j for drawing\n",
    "        delta = delta_scaled @ cell\n",
    "        pos_j_plot = pos_i + delta\n",
    "\n",
    "        lines.append([pos_i[:2], pos_j_plot[:2]])\n",
    "\n",
    "    lc = LineCollection(lines, colors='gray', linewidths=1, zorder=1)\n",
    "    ax.add_collection(lc)\n",
    "\n",
    "    # Final plot settings\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "\n",
    "    if filename:\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# 4. Process each material in the cluster\n",
    "def process_nodes_in_cluster(CLUSTER_NUM, cluster_labels, embedding_labels, input_folder):\n",
    "    \"\"\"\n",
    "    Processes structures for each material in a given cluster.\n",
    "\n",
    "    :param CLUSTER_NUM: int\n",
    "    :param cluster_labels: np.array of integers (one cluster label per material)\n",
    "    :param embedding_labels: np.array of strings or ints (identifiers for materials)\n",
    "    :param input_folder: Path to folder containing supercells, e.g. 'Supercells/supercells_sublattices_3x3'\n",
    "    \"\"\"\n",
    "    cluster_indices = np.where(cluster_labels == CLUSTER_NUM)[0]\n",
    "    if len(cluster_indices) == 0:\n",
    "        print(f\"No points found in cluster {CLUSTER_NUM}.\")\n",
    "        return None\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    for idx in cluster_indices:\n",
    "        # Use the label as a string (in case it's something like '1000_Eu')\n",
    "        material_label_str = str(embedding_labels[idx])\n",
    "\n",
    "        # Build the file path for that label\n",
    "        file_path = os.path.join(input_folder, f\"supercell_2dm-{material_label_str}.xyz\")\n",
    "\n",
    "        try:\n",
    "            atoms = read(file_path)\n",
    "            atoms.pbc = [True, True, False]  # 2D system\n",
    "\n",
    "            # Create graph\n",
    "            graph = create_graph_from_structure(atoms, delta)\n",
    "\n",
    "            # Save plot\n",
    "            plot_filename = f\"graph_cluster_{CLUSTER_NUM}_material_{material_label_str}.png\"\n",
    "            plot_filepath = os.path.join(plot_folder, plot_filename)\n",
    "            plot_graph(atoms, graph, margin=0.2, tolerance=0.1, y_size=6, filename=plot_filepath)\n",
    "            print(f\"Graph for material label {material_label_str} from cluster {CLUSTER_NUM} saved as {plot_filepath}.\")\n",
    "\n",
    "            # Additional properties\n",
    "            num_atoms = len(atoms)\n",
    "\n",
    "            # cellpar returns [a, b, c, alpha, beta, gamma]\n",
    "            a_val, b_val, c_val, alpha, beta, gamma = atoms.cell.cellpar()\n",
    "\n",
    "            # Scale the first two cell lengths by SUPERCELL_SIZE,\n",
    "            # keeping the third length unscaled\n",
    "            scaled_cell_lengths = [\n",
    "                f\"{a_val / SUPERCELL_SIZE:.3f}\",\n",
    "                f\"{b_val / SUPERCELL_SIZE:.3f}\",\n",
    "                f\"{c_val:.3f}\"  # unchanged\n",
    "            ]\n",
    "\n",
    "            # Extract just the angles (alpha, beta, gamma)\n",
    "            cell_angles = [alpha, beta, gamma]\n",
    "\n",
    "            # Format the lengths and angles\n",
    "            formatted_cell_lengths = [f\"{length}\" for length in scaled_cell_lengths]\n",
    "            formatted_cell_angles  = [f\"{angle:.3f}\" for angle in cell_angles]\n",
    "\n",
    "            # Number of atoms in the single unit cell\n",
    "            num_atoms_in_unit_cell = num_atoms // (SUPERCELL_SIZE ** 2)\n",
    "\n",
    "            # Simple approach: slice out the first 'num_atoms_in_unit_cell'\n",
    "            unit_cell_atoms = atoms[:num_atoms_in_unit_cell]\n",
    "            formula = unit_cell_atoms.get_chemical_formula()\n",
    "\n",
    "            data_list.append({\n",
    "                \"Cluster\": CLUSTER_NUM,\n",
    "                \"Material\": material_label_str,\n",
    "                \"Chemical Formula\": formula,\n",
    "                \"No. atoms per cell\": num_atoms_in_unit_cell,\n",
    "                \"Unitcell Lengths\": formatted_cell_lengths,\n",
    "                \"Cell Angles\": formatted_cell_angles,\n",
    "                \"Plot\": plot_filepath\n",
    "            })\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Structure file for material label {material_label_str} not found at {file_path}.\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing material {material_label_str}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return data_list\n",
    "\n",
    "\n",
    "# 5. Main script usage\n",
    "data_list = []\n",
    "cluster_data = process_nodes_in_cluster(\n",
    "    CLUSTER_NUM, \n",
    "    cluster_labels, \n",
    "    embedding_labels, \n",
    "    input_folder = INPUT_FOLDER\n",
    ")\n",
    "\n",
    "if cluster_data is not None:\n",
    "    data_list.extend(cluster_data)\n",
    "else:\n",
    "    print(f\"No data collected for cluster {CLUSTER_NUM}.\")\n",
    "\n",
    "# Define the column order\n",
    "column_order = [\n",
    "    \"Cluster\",\n",
    "    \"Material\",\n",
    "    \"Chemical Formula\",\n",
    "    \"No. atoms per cell\",\n",
    "    \"Unitcell Lengths\",\n",
    "    \"Cell Angles\",\n",
    "    \"Plot\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data_list, columns=column_order)\n",
    "\n",
    "def path_to_image_html(path):\n",
    "    return f'<img src=\"{path}\" height=\"200\">'\n",
    "\n",
    "HTML(df.to_html(index=False, escape=False, formatters={\"Plot\": path_to_image_html}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Node Visualiser: visualises the core node of every cluster\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from ase.io import read\n",
    "from torch_geometric.data import Data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from IPython.display import HTML\n",
    "\n",
    "plot_folder = 'Plots and Visualisations\\Temp\\Core Node Plots'\n",
    "delta = 0.1\n",
    "\n",
    "if not os.path.exists(plot_folder):\n",
    "    os.makedirs(plot_folder)\n",
    "else:\n",
    "    for filename in os.listdir(plot_folder):\n",
    "        file_path = os.path.join(plot_folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "\n",
    "# Helper functions to build graph and plot\n",
    "def compute_edge_index(atoms, delta):\n",
    "    positions = atoms.get_positions()\n",
    "    num_atoms = len(positions)\n",
    "    dist_matrix = atoms.get_all_distances(mic=True)\n",
    "    edge_index = set()\n",
    "\n",
    "    for i in range(num_atoms):\n",
    "        dist_matrix[i, i] = np.inf \n",
    "        distances = dist_matrix[i]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        sorted_distances = distances[sorted_indices]\n",
    "\n",
    "        # Nearest-neighbor cutoff\n",
    "        d1 = sorted_distances[0]\n",
    "        nn_cutoff = d1 + delta\n",
    "        nn_indices = sorted_indices[sorted_distances <= nn_cutoff]\n",
    "        for j in nn_indices:\n",
    "            edge_index.add((j, i))\n",
    "\n",
    "        # Next-nearest-neighbor cutoff\n",
    "        remaining_indices = sorted_indices[sorted_distances > nn_cutoff]\n",
    "        remaining_distances = sorted_distances[sorted_distances > nn_cutoff]\n",
    "        if len(remaining_distances) > 0:\n",
    "            d2 = remaining_distances[0]\n",
    "            nnn_cutoff = d2 + delta\n",
    "            nnn_indices = remaining_indices[remaining_distances <= nnn_cutoff]\n",
    "            for j in nnn_indices:\n",
    "                edge_index.add((j, i))\n",
    "\n",
    "    if len(edge_index) > 0:\n",
    "        edge_index = torch.tensor(list(edge_index), dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "\n",
    "def create_graph_from_structure(atoms, delta):\n",
    "    edge_index = compute_edge_index(atoms, delta)\n",
    "    num_nodes = len(atoms)\n",
    "\n",
    "    node_features = torch.empty((num_nodes, 0), dtype=torch.float)\n",
    "\n",
    "    graph = Data(\n",
    "        x=node_features,\n",
    "        edge_index=edge_index\n",
    "    )\n",
    "    return graph\n",
    "\n",
    "\n",
    "def plot_graph(atoms, graph, margin=0.1, tolerance=0.1, y_size=6, filename=None):\n",
    "    \"\"\"\n",
    "    Plots the graph of an atomic structure with consistent y-direction size.\n",
    "    \"\"\"\n",
    "    positions = atoms.get_positions()\n",
    "    cell = atoms.get_cell()\n",
    "\n",
    "    x = positions[:, 0]\n",
    "    y = positions[:, 1]\n",
    "    z = positions[:, 2]\n",
    "\n",
    "    z_grouped = np.round(z / tolerance) * tolerance\n",
    "    z_unique, indices = np.unique(z_grouped, return_inverse=True)\n",
    "    N_layers = len(z_unique)\n",
    "\n",
    "    cmap = plt.cm.get_cmap('viridis', N_layers)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    c_shift = 0.5 * cell[2]\n",
    "    corner_positions = np.array([\n",
    "        [0, 0, 0],\n",
    "        cell[0],\n",
    "        cell[0] + cell[1],\n",
    "        cell[1],\n",
    "        [0, 0, 0]\n",
    "    ]) + c_shift\n",
    "\n",
    "    x_min, x_max = corner_positions[:, 0].min(), corner_positions[:, 0].max()\n",
    "    y_min, y_max = corner_positions[:, 1].min(), corner_positions[:, 1].max()\n",
    "\n",
    "    x_margin = (x_max - x_min) * margin\n",
    "    y_margin = (y_max - y_min) * margin\n",
    "\n",
    "    x_min -= x_margin\n",
    "    x_max += x_margin\n",
    "    y_min -= y_margin\n",
    "    y_max += y_margin\n",
    "\n",
    "    y_range = y_max - y_min\n",
    "    x_range = x_max - x_min\n",
    "    aspect_ratio = x_range / y_range\n",
    "    min_aspect_ratio = 1 / 3\n",
    "    if aspect_ratio < min_aspect_ratio:\n",
    "        aspect_ratio = min_aspect_ratio\n",
    "\n",
    "    x_size = y_size * aspect_ratio\n",
    "    fig.set_size_inches(x_size, y_size)\n",
    "\n",
    "    # Plot the supercell boundary\n",
    "    ax.plot(corner_positions[:, 0], corner_positions[:, 1], 'k--', linewidth=1)\n",
    "    ax.scatter(x, y, c=indices, s=50, cmap=cmap, zorder=2)\n",
    "\n",
    "    lines = []\n",
    "    for idx_edge in range(graph.edge_index.shape[1]):\n",
    "        i = graph.edge_index[0, idx_edge].item()\n",
    "        j = graph.edge_index[1, idx_edge].item()\n",
    "\n",
    "        pos_i = positions[i]\n",
    "        pos_j = positions[j]\n",
    "\n",
    "        # Compute delta with PBCs\n",
    "        delta_scaled = atoms.get_scaled_positions()[j] - atoms.get_scaled_positions()[i]\n",
    "        delta_scaled -= np.round(delta_scaled)\n",
    "        pos_j_plot = pos_i + (delta_scaled @ cell)\n",
    "\n",
    "        lines.append([pos_i[:2], pos_j_plot[:2]])\n",
    "\n",
    "    lc = LineCollection(lines, colors='gray', linewidths=1, zorder=1)\n",
    "    ax.add_collection(lc)\n",
    "\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "\n",
    "    if filename:\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Core-node processing\n",
    "def process_core_node_in_cluster(cluster_num, cluster_labels, embedding_labels, hdb, input_folder):\n",
    "    \"\"\"\n",
    "    Identifies the single most \"core\" node (highest probability) within a cluster,\n",
    "    reads its structure, plots it, and returns a dict with plot info.\n",
    "    \"\"\"\n",
    "    # Get indices belonging to this cluster\n",
    "    cluster_indices = np.where(cluster_labels == cluster_num)[0]\n",
    "    if len(cluster_indices) == 0:\n",
    "        return None\n",
    "\n",
    "    # Extract HDBSCAN probabilities for these points and find the best\n",
    "    cluster_probabilities = hdb.probabilities_[cluster_indices]\n",
    "    max_prob_index_in_cluster = cluster_indices[np.argmax(cluster_probabilities)]\n",
    "\n",
    "    # Convert material label to a string (if needed to build a filename)\n",
    "    material_label_str = str(embedding_labels[max_prob_index_in_cluster])\n",
    "\n",
    "    # Try to read the relevant file from your input folder\n",
    "    file_path = os.path.join(input_folder, f\"supercell_2dm-{material_label_str}.xyz\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        atoms = read(file_path)\n",
    "        num_atoms = len(atoms)\n",
    "        # For 2D materials, assume periodic in x and y only\n",
    "        atoms.pbc = [True, True, False]\n",
    "\n",
    "        # Create the graph\n",
    "        graph = create_graph_from_structure(atoms, delta)\n",
    "\n",
    "        # Prepare output filename for the plot\n",
    "        plot_filename = f\"cluster_{cluster_num}_core_{material_label_str}.png\"\n",
    "        plot_filepath = os.path.join(plot_folder, plot_filename)\n",
    "\n",
    "        # Plot and save\n",
    "        plot_graph(\n",
    "            atoms,\n",
    "            graph,\n",
    "            margin=0.1,\n",
    "            tolerance=0.1,\n",
    "            y_size=6,\n",
    "            filename=plot_filepath\n",
    "        )\n",
    "\n",
    "        num_atoms_in_unit_cell = num_atoms // (SUPERCELL_SIZE ** 2)\n",
    "\n",
    "        # slice out the first 'num_atoms_in_unit_cell'\n",
    "        unit_cell_atoms = atoms[:num_atoms_in_unit_cell]\n",
    "        formula = unit_cell_atoms.get_chemical_formula()\n",
    "\n",
    "        # Prepare a dictionary with info for HTML grid\n",
    "        return {\n",
    "            \"Cluster\": cluster_num,\n",
    "            \"Chemical Formula\": formula,\n",
    "            \"Plot\": plot_filepath\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_all_core_nodes(cluster_labels, embedding_labels, hdb, input_folder, skip_noise=True):\n",
    "    \"\"\"\n",
    "    Iterates over each cluster, finds the single highest-probability core node,\n",
    "    processes it, and returns one row per cluster in a list of dicts.\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "\n",
    "    for cluster_num in unique_clusters:\n",
    "        if skip_noise and cluster_num == -1:\n",
    "            continue\n",
    "\n",
    "        core_data = process_core_node_in_cluster(\n",
    "            cluster_num,\n",
    "            cluster_labels,\n",
    "            embedding_labels,\n",
    "            hdb,\n",
    "            input_folder\n",
    "        )\n",
    "        if core_data is not None:\n",
    "            data_list.append(core_data)\n",
    "\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def generate_aligned_html_grid(data_list, images_per_row=3):\n",
    "    \"\"\"\n",
    "    Generates an HTML grid with aligned tops and captions below each image.\n",
    "    Expects data_list to be a list of dictionaries where each dictionary\n",
    "    has at least 'Plot', 'Cluster', and 'Chemical Formula'.\n",
    "    \"\"\"\n",
    "    html = '<div style=\"display: flex; flex-wrap: wrap; align-items: flex-start;\">'\n",
    "    for idx, item in enumerate(data_list):\n",
    "        width_percent = 100 // images_per_row\n",
    "        html += f'''\n",
    "        <div style=\"flex: 1 0 {width_percent}%; box-sizing: border-box; padding: 10px; text-align: center;\">\n",
    "            <div style=\"position: relative; width: 100%; padding-top: 100%; overflow: hidden;\">\n",
    "                <img src=\"{item['Plot']}\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: contain;\">\n",
    "            </div>\n",
    "            <div style=\"margin-top: 5px; font-size: 14px;\">\n",
    "                Cluster {item.get('Cluster','?')}: {item.get('Chemical Formula','Unknown')}\n",
    "            </div>\n",
    "        </div>\n",
    "        '''\n",
    "    html += '</div>'\n",
    "    return html\n",
    "\n",
    "\n",
    "data_list = process_all_core_nodes(\n",
    "    cluster_labels=cluster_labels,\n",
    "    embedding_labels=embedding_labels,\n",
    "    hdb=hdb,\n",
    "    input_folder=INPUT_FOLDER,\n",
    "    skip_noise=True\n",
    ")\n",
    "html_code = generate_aligned_html_grid(data_list, images_per_row=5)\n",
    "display(HTML(html_code))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
